<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      type="text/javascript"
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
    ></script>
    <!--It is a link for MathJax-->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <!--link for the font-->
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <!--link for the font-->
    <link
      href="https://fonts.googleapis.com/css2?family=Spectral:wght@200&display=swap"
      rel="stylesheet"
    />
    <!--link for the font-->
    <link rel="stylesheet" type="text/css" href="note_style.css" />
    <!--It is a link for css structure-->
    <script src="highlight.js"></script>
    <!--It is a link for highlight.js-->
    <title>Numerical Analysis</title>
  </head>
  <body>
    <div class="top-bar"></div>
    <input type="checkbox" id="nav-toggle" class="nav-toggle" />
    <label for="nav-toggle" class="icon-burger">
      <div class="line"></div>
      <div class="line"></div>
      <div class="line"></div>
      <span class="visually-hidden">Menu</span>
    </label>
    <nav class="navbar">
      <a href="#Definition">Definition</a>
      <a href="#Unit_Roundoff">Unit Roundoff</a>
      <a href="#Roundoff_Error">Roundoff Error</a>
      <a href="#Number_System_with_base_Beta">Number System with base \(\beta\)</a>
      <a href="#FLoating_point_error_analysis">FLoating point error analysis</a>
      <a href="#Error_Analysis_for_Newton's_Method">Error Analysis for Newton's Method</a>
      <a href="#Error_Analysis_for_Gaussian_Quadrature">Error Analysis for Gaussian Quadrature</a>
      <a href="#References">References</a>
    </nav>
    <script src="click.js"></script>
    <!--It is a link for click.js, which is clicking the link the hamburger menu will disappear-->
    <h1>Numerical Analysis</h1>

    <section id="binary">
      <h2>Definition</h2>
      <p>
        \[ x = \pm (0. a_1\cdots a_n\cdots)_2\times 2^m \] where \(a_1 = 1\)
      </p>
      <p>
        \(\textbf{Note. }\)For Marc-32, \(n = 24\), \(-126\leq m\leq 127\). For
        Marc-64, \(n = 53\), \(-1021\leq m\leq 1024\).
      </p>
    </section>

    <br />

    <section id="unit_roundoff">
      <h2>Unit Roundoff</h2>
      <p>
        \[ fl(1 + \varepsilon) > 1 \] \[ \varepsilon = 2^{-24} ~ 10^{-8} \] \[
        \varepsilon = 2^{-53} ~ 10^{-16} \]
      </p>
    </section>

    <br />

    <section id="roundoff_error">
      <h2>Roundoff Error</h2>
      <p>
        Let \(\delta = \frac{x - fl(x)}{x}\). define \[ \left|\delta\right|\leq
        \varepsilon \] Suppose that \(x = \pm (0. a_1\cdots a_n\cdots)_2\times
        2^m\), then we pick two points such that \(x_-\) is less than \(x\) and
        \(x_+\) is greater than \(x\). Then we have \[ x_- = (0, a_1\cdots
        a_n)_2\times 2^m \] \[ x_+ = (0, a_1\cdots a_n+0.000\dots 1_n)_2\times
        2^m \] \[ fl(x) = x_- \text{ if }a_{n+1} = 0 \text{(x is closer to x_-
        than x_+) and } fl(x) = x_+ \text{ if }a_{n+1} = 1\text{ (x is closer to
        x_+ than x_-)} \] \[ |fl(x) - x|\leq \frac{1}{2}\times (x_+ - x_-) =
        \frac{1}{2}\cdot 2^{-n}\cdot 2^m \] \[ \left|\frac{fl(x) -
        x}{x}\right|\leq \frac{\frac{1}{2}2^{-n}2^m}{(0,a_1\cdots a_n)_2\times
        2^m} = 2^{-n} \]
      </p>
    </section>

    <br />

    <section id="base">
      <h2>Number System with base \(\beta\)</h2>
      <p>
        The unit roundoff is \[ \varepsilon = \frac{1}{2}\beta^{1-t} \] where
        \(t\) is the number of digits in the mantissa.
      </p>
    </section>

    <br />

    <section id="floating_point_error_analysis">
      <h2>FLoating point error analysis</h2>
      <p>
        Let \(x, y\) be two machine numbers. Let \(\circ\) is a binary
        operation. \[ fl(x\circ y) = (x\circ y)(1 + \delta) \] where
        \(|\delta|\leq\varepsilon\) is the roundoff error. \[ fl(x) = x(1 +
        \delta) \]
      </p>
      <p>\(\textbf{Example.}\)</p>
    </section>


    <br>

    <section id = 'theorem_on_polynomial_interpolation'>
      <h2>Theorem on Polynomial Interpolation</h2>
      <p>
        \(\textbf{Theorem. }\)If \( x_0, x_1, \ldots, x_n \) are distinct real numbers, then for arbitrary values \( y_0, y_1, \ldots, y_n \), 
        there is a unique polynomial \( p_n \) of degree at most \( n \) such that
        \[ 
          p_n(x_i) = y_i \quad (0 \leq i \leq n) 
        \]
      </p>
    </section>

    <br>

    <section>
      <h2>Theorem on Polynomial Interpolation Error</h2>
      <p>
        \(\textbf{Theorem. }\)Let \( f \) be a function in \( C^{n+1}[a, b] \), and let \( p \) be the polynomial of degree at most \( n \) that interpolates the function \( f \) at \( n + 1 \) distinct points \( x_0, x_1, \ldots, x_n \) in the interval \([a, b]\). 
        To each \( x \) in \([a, b]\) there corresponds a point \( \xi_x \) in \((a, b)\) such that
        \[ 
          f(x) - p(x) = \frac{1}{(n + 1)!} f^{(n+1)}(\xi_x) \prod_{i=0}^{n} (x - x_i) .
        \]
      </p>
    </section>

    <section id = 'error_analysis_netwon'>
      <h2>Error Analysis for Newton's Method</h2>
      <p>
        Let \( r \) be a solution of \( f(x) = 0 \) (i.e. \( f(r) = 0 \)). 
        Suppose that we have already computed \( x_n \) and the error in \( x_n \) is \(e_n = |x_n - r| \). 
        We now derive a formula that relates the error after the next step, \( |x_{n+1} - r| \), to \( |x_n - r| \). 
        According to Taylor's theorem, there is a \( c \) between \( x_n \) and \( r \) such that        
        \[
         0 = f(r) = f(x_n) + f'(x_n)(r - x_n) + \frac{1}{2}f''(c)(r - x_n)^2 \quad (1)
        \]
        By the definition of Newton's method, we have 
        \[ 
        0 = f(x_n) + f'(x_n)(x_{n+1} - x_n) \quad (2) 
        \]
        Subtracting (2) from (1).
        \[
        \begin{align}
         0 &= f'(x_n)(r - x_{n+1}) + \frac{1}{2}f''(c)(r - x_n)^2\\
        x_{n+1} - r &= \frac{f''(c)}{2f'(x_n)}(x_n - r)^2 \\
        e_{n+1} &= |x_{n+1} - r| = \left| \frac{f''(c)}{2f'(x_n)} \right||x_n - r|^2 \\
        \end{align}
        \]
        If \( x_n \) is close to \( r \), then \( c \), which must be between \( x_n \) and \( r \), is also close to \( r \) and
        \[ e_{n+1} = |x_{n+1} - r| \approx \left| \frac{f''(r)}{2f'(r)} \right||x_n - r|^2. \]
        Even if \( x_n \) is not close to \( r \), by the hypotheses (H1) and (H2) on the behavior of \( f \)
        \[ |x_{n+1} - r| \leq M|x_n - r|^2 \quad (3) \]         
      </p>
    </section>

    <br>

    <section id = 'gaussian_quadrature_error_analysis'>
      <h2>Error Analysis for Gaussian Quadrature</h2>
      <p>
        Given the Gaussian quadrature formula
        \[
         \int_a^b f(x) dx = \sum_{i=1}^{n} w_i f(x_i) + R_n(f),
        \]
        where 
        \[
          R_n(f) = \frac{(b-a)^{2n+1}(n!)^4}{(2n+1)[(2n)!]^3} f^{(2n)}(c).
        \]
      </p>
    </section>

    <section id = 'practice'>
      <h2>Qual Problems (January 2022)</h2>
      <p>
      1. Consider the iteration 
      \[
        x_{n+1} = \frac{1}{2} x_n + \frac{5}{2x_n}, \quad n = 0, 1, \ldots
      \]
      <ul>
        <li>
          1. Show that if \(x_0 > 0\), then \(x_n \geq \sqrt{5}\) for \(n = 1,2,\ldots\).
        </li>
        <li>
          2. Use the Contractive Mapping Theorem to show that the iteration is convergent.
        </li>
        <li>
          3. Show that the order of convergence of the iteration is quadratic.
        </li>
      </ul>
      </p>
      <h2>Solutions</h2>
      <p>
      \(\textbf{Proof of 1.}\) Let \(f(x) = \frac{1}{2}x + \frac{5}{2x}\). 
      Hence, we can calculate the derivative of \(f(x)\) as
      \[
        f'(x) = \frac{1}{2} - \frac{5}{2x^2} = \frac{1}{2}\left(1 - \frac{5}{x^2}\right)
      \]
      Since \(x_0 > 0\), we just assume that \(x>0\).
      When \( 0 \lt x \leq \sqrt{5} \), we have \( f'(x) \lt 0 \).
      When \( x \geq \sqrt{5} \), we have \( f'(x) \geq 0 \).
      Thus, we can know that when \( x = \sqrt{5} \), \( f(x) \) is at minimum for \( f(x) \) where \( x \geq 0 \).
      Then, 
      \[
       \min f(x) = f(\sqrt{5}) = \frac{1}{2} \sqrt{5} + \frac{5}{2\sqrt{5}} = \frac{1}{2} \sqrt{5} + \frac{1}{2} \sqrt{5} = \sqrt{5}.
      \]
      Therefore, we have \( f(x) \geq \sqrt{5} \).
      In other words, if \( x_0 > 0 \), then \( x_n \geq \sqrt{5} \). \[ \tag*{$\square$} \]
      </p>
    </section>

    <br>

    <h2>Qual Problems (August 2022)</h2>
    <section id = 'ku_2022_8_1'>
      <p>
        \(\textbf{Problem 1. }\)Consider the interpolation problem: Find a polynomial of degree less than or equal to three interpolating the table
        \[
          \begin{array}{c|cccc}
            x & 0 & 1 & 7 & 2 \\
            \hline
            f(x) & 51 & 3 & 201 & 1 \\
          \end{array} 
        \]
        <ul>
          <li>
            Prove that the solution to the interpolation problem exists and is unique.
          </li>
          <li>
            Find the interpolation polynomial in Newton's form.
          </li>
          <li>
            Derive the error for the interpolation polynomial provided that function \( f = f(x) \) is sufficiently smooth.
          </li>
        </ul>
      </p>
      <p>
        \(\textbf{Proof. }\)Firstly, we can observe that for all \(x\), they are distinct.
        Therefore, for arbitrary value of \(f(x)\), we can find a unique polynomial of degree less than or equal to \(3\) interpolating the table. \( \blacksquare \)
      </p>
      <p>
        \(\textbf{Solution.}\)Here we can use Newton's divided difference method to find the interpolation polynomial.
        \[
          \begin{align*}
            x_0 = 0: & f[x_0] = 51, & f[x_0, x_1] = \frac{3 - 51}{1 - 0} = -48, & f[x_0, x_1, x_2] = \frac{33 - (-48)}{7 - 0} = \frac{81}{7}, & f[x_0, x_1, x_2, x_3] = \frac{7 - 81/7}{2-0} = -\frac{16}{7},\\
            x_1 = 1: & f[x_1] = 3, & f[x_1, x_2] = \frac{201 - 3}{7 - 1} = 33, & f[x_1, x_2, x_3] = \frac{40 - 33}{1-0} = 7, & \\
            x_2 = 7: & f[x_2] = 201, & f[x_2, x_3] = \frac{1 - 201}{2 - 7} = 40, & & \\
            x_3 = 2: & f[x_3] = 1, & & & \\
          \end{align*}
        \]
        Therefore, we have
        \[
          p(x) = 51 + (-48)(x-0) + \frac{81}{7}(x-0)(x-1) - \frac{16}{7}(x-0)(x-1)(x-7).
        \]
      </p>
      <p>
        \(\textbf{Solution.}\)
      </p>
    </section>

    <section>
      <p>
\(\textbf{Problem. }\)Let \( A \in \mathbb{C}^{m \times m} \), and \( A = U\Sigma V^* \) being a singular value decomposition of \( A \), where \( U, V \in \mathbb{C}^{m \times m} \) are unitary and \( \Sigma \) is non-negative diagonal. Define
\[
W = \frac{1}{\sqrt{2}}
\begin{bmatrix}
U & U \\
V & -V
\end{bmatrix}
\in \mathbb{C}^{2m \times 2m}.
\]
<ul>
  <li>
  Prove \( W \) is unitary.
  </li>
  <li>
  Let
  \[
  B =
  \begin{bmatrix}
  0 & A \\
  A^* & 0
  \end{bmatrix}
  \in \mathbb{C}^{2m \times 2m}.
  \]
  Prove \( B \) is Hermitian and have the spectral decomposition
  \[
  B = W
  \begin{bmatrix}
  \Sigma & 0 \\
  0 & -\Sigma
  \end{bmatrix}
  W^*.
  \]
  </li>
  <li>
  Prove \( \|B\|_2 = \|A\|_2 \).
  </li>
</ul>
</p>
<p>
  \(\textbf{Proof(a). }\) Given \(W\), we have with Unitary Matrices \(U, V\), we can get 
    \[
        W^* = \frac{1}{\sqrt{2}}
        \begin{bmatrix}
            U^* & V^* \\
            U^* & -V^*
        \end{bmatrix}
        \in \mathbb{C}^{2m \times 2m}.
        \]
    Then we have
    \begin{align}
      W^* W &= \frac{1}{2}  
        \begin{bmatrix}
            U^*U + V^*V & U^*U - V^*V \\
            U^*U - V^*V & U^*U + V^*V
        \end{bmatrix}\\
        &= \frac{1}{2}
        \begin{bmatrix}
            I_m + I_m & I_m - I_m \\
            I_m - I_m & I_m + I_m
        \end{bmatrix}\\
        &= \frac{1}{2}
        \begin{bmatrix}
            2I_m & 0_m \\
            0_m & 2I_m
        \end{bmatrix}\\
        &= 
        \begin{bmatrix}
            I_m & 0_m \\
            0_m & I_m
        \end{bmatrix} \\
        &= I_{2m}.
    \end{align}
    By the similar process, we have 
    \begin{align}
        WW^* &= \frac{1}{2}
        \begin{bmatrix}
            UU^* + UU^* & UV^* - UV^* \\
            VU^* - VU^* & VV^* + VV^*
        \end{bmatrix}\\
        &= \frac{1}{2}
        \begin{bmatrix}
            I_m + I_m & 0_m \\
            0_m & I_m + I_m
        \end{bmatrix}\\
        &= I_{2m}.
    \end{align}
    Therefore, we show that \(W\) is unitary. \[ \tag*{$\square$} \]
</p>
<p>
\(\textbf{Proof(b). }\)Firstly, we have 
    \[
      B^* = \begin{bmatrix}
        0 & A^* \\
        (A^*)^* & 0
        \end{bmatrix} = \begin{bmatrix}
        0 & A^* \\
        A & 0
        \end{bmatrix} = B.
    \]
    Thus, we have \(B\) is Hermitian. 
    To show the spectral decomposition, we need to do calculation. 
    \begin{align}
        W
        \begin{bmatrix}
            \Sigma & 0 \\
            0 & -\Sigma
        \end{bmatrix}
        W^* &= \frac{1}{2}
        \begin{bmatrix}
            U & U \\
            V & -V
        \end{bmatrix}
        \begin{bmatrix}
            \Sigma & 0 \\
            0 & -\Sigma
        \end{bmatrix}
        \begin{bmatrix}
            U^* & V^* \\
            U^* & -V^*
        \end{bmatrix}\\
        &= \frac{1}{2}
        \begin{bmatrix}
            U\Sigma & -U\Sigma \\
            V\Sigma & V\Sigma
        \end{bmatrix}
        \begin{bmatrix}
            U^* & V^* \\
            U^* & -V^*
        \end{bmatrix}\\
        &= \frac{1}{2}
        \begin{bmatrix}
            U\Sigma U^* - U\Sigma U^* & U\Sigma V^* + U\Sigma V^* \\
            V\Sigma U^* + V\Sigma U^* & V\Sigma V^* - V\Sigma V^*
        \end{bmatrix}\\
        &= \begin{bmatrix}
            0 & U\Sigma V^*  \\
            V\Sigma U^*  & 0
        \end{bmatrix}\\
    \end{align}
    Since \(A = U\Sigma V^*\), which is SVD of \(A\), we know all entires of \(\Sigma\) are non-negative. 
    Thus, we have \(\Sigma = \Sigma^*\). In that case, we have
    \[
        W
        \begin{bmatrix}
            \Sigma & 0 \\
            0 & -\Sigma
        \end{bmatrix}
        W^* = \begin{bmatrix}
            0 & U\Sigma V^*  \\
            V\Sigma U^*  & 0
        \end{bmatrix}
        = \begin{bmatrix}
            0 & U\Sigma V^*  \\
            V\Sigma^* U^*  & 0
        \end{bmatrix}
        = \begin{bmatrix}
            0 & A  \\
            A^*  & 0
        \end{bmatrix} = B.
    \] \[ \tag*{$\square$} \]
</p>
<p>
    \(\textbf{Proof(c). }\)Since we just show that \(W\) is unitary, and we are given that \(U\) and \(V\) are unitary, we have
        \begin{align}
            \|A\|_2 &= \|U\Sigma V^*\|_2 = \|\Sigma\|_2 = \max\sigma_i  \\
            \|B\|_2 &= \left\|W \begin{bmatrix}
                \Sigma & 0 \\
                0 & -\Sigma
            \end{bmatrix} W^*\right\|_2 = \left\|\begin{bmatrix}
                \Sigma & 0 \\
                0 & -\Sigma
            \end{bmatrix}\right\|_2.
        \end{align}
        Since \(\begin{bmatrix} I_m & 0 \\ 0 & -I_m \end{bmatrix}\) is a unitary matrix, and 
        \[ \begin{bmatrix} I_m & 0 \\ 0 & -I_m \end{bmatrix}
            \begin{bmatrix}
                \Sigma & 0 \\
                0 & -\Sigma
            \end{bmatrix}
            = \begin{bmatrix} \Sigma_m & 0 \\ 0 & \Sigma_m \end{bmatrix},
        \]
        we have 
        \[
            \left\|\begin{bmatrix}
                \Sigma & 0 \\
                0 & -\Sigma
            \end{bmatrix}\right\|_2 = \left\|\begin{bmatrix} I_m & 0 \\ 0 & -I_m \end{bmatrix}
            \begin{bmatrix}
                \Sigma & 0 \\
                0 & -\Sigma
            \end{bmatrix}\right\|_2
            =
            \left\|\begin{bmatrix} \Sigma_m & 0 \\ 0 & \Sigma_m \end{bmatrix}\right\|_2 = \max\sigma_i.
        \]
        Therefore, we have \(\|B\|_2 = \|A\|_2\). \[ \tag*{$\square$} \]
</p>
</section>

    <section id="References">
      <h2>References</h2>
      <ul>
        <li>
          D. Kincard & W. Cheney "Numerical Analysis: Mathematics of Scientific Computing", AMS, Third Edition, 2009.
        </li>
      </ul>
    </section>

  </body>
</html>