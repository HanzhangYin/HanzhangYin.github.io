<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><!--It is a link for MathJax-->
    <link rel="preconnect" href="https://fonts.googleapis.com"> <!--link for the font-->
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> <!--link for the font-->
    <link href="https://fonts.googleapis.com/css2?family=Spectral:wght@200&display=swap" rel="stylesheet"> <!--link for the font-->
    <link rel="stylesheet" type="text/css" href="note_style.css"><!--It is a link for CSS structure-->
    <title>Algebra</title>
  </head>
  <body>
    <div class="top-bar"></div>
    <input type="checkbox" id="nav-toggle" class="nav-toggle">
    <label for="nav-toggle" class="icon-burger">
      <div class="line"></div>
      <div class="line"></div>
      <div class="line"></div>
      <span class="visually-hidden">Menu</span>
    </label>
    <nav class="navbar">
      <a href="#linear_transformation">Linear Transformation</a>
      <a href="#multiplicity">Multiplicity</a>
      <a href="#dual_space">Dual Space</a>
      <a href="#linear_minimal_polynomial">Minimal Polynomial</a>
      <a href="#t_complement">\(T\)-Complement</a>
      <a href="#cyclic_operator">Cyclic Operator</a>
      <a href="#indecomposable_operator">Indecomposable Operator</a>
      <a href="#characteristic_polynomial">Characteristic Polynomial</a>
      <a href="#diagonalizable">Diagonalizable</a>
      <a href="#smith_normal_form">Smith Normal Form</a>
      <a href="#normal_subgroup">Normal Subgroup</a>
      <a href="#isomorphism">Isomorphism</a>
      <a href="#center">Center</a>
      <a href="#centralizer">Centralizer</a>
      <a href="#normalizer">Normalizer</a>
      <a href="#stabilizer">Stabilizer</a>
      <a href="#orbit">Orbit</a>
      <a href="#p_group">\(p\)-group</a>
      <a href="#sylow_p_subgroup">Sylow \(p\)-Subgroup</a>
      <a href="#sylow_theorem">Sylow's Theorem</a>
      <a href="#simple_group">Simple Group</a>
      <a href="#solvable_group">Solvable Group</a>
      <a href="#field">Field</a>
      <a href="#integral_domain">Integral Domain</a>
      <a href="#ascending_chain_condition">Ascending Chain Condition</a>
      <a href="#principal_ideal_domain">Principal Ideal Domain</a>
      <a href="#unique_factorization_domain">Unique Factorization Domain</a>
      <a href="#polynomial_ring">Polynomial Ring</a>
      <a href="#division_algorithm_sagemath">Division Algorithm in SageMath</a>
      <a href="#prime_irreducible">Prime and Irreducible</a>
      <a href="#adjoining_element">Adjoining Element</a>
      <a href="#splitting_field">Splitting Field</a>
      <a href="#minimal_polynomial">Minimal Polynomial</a>
      <a href="#field_extension">Field Extension</a>
      <a href="#separable">Separable</a>
      <a href="#algebraic_closure">Algebraic Closure</a>
      <a href="#galois_group">Galois Group</a>
      <a href="#galois_theory">Galois Theory</a>
      <a href="#january_2015">KU 2015 (January)</a>
      <a href="#ku_2015_8_6">KU 2015 (August)</a>
      <a href="#ku_2016_1_5">KU 2016 (January)</a>
      <a href="#ku_2016_8_4">KU 2016 (August)</a>
      <a href="#january_2017">KU 2017 (January)</a>
      <a href='#ku_2017_8_6'>KU 2017 (August)</a>
      <a href='#january_2018'>KU 2018 (January)</a>
      <a href='#august_2018'>KU 2018 (August)</a>
      <a href='#january_2019'>KU 2019 (January)</a>
      <a href='#august_2019'>KU 2019 (August)</a>
      <a href='#ku_2020_1'>KU 2020 (January)</a>
      <a href='#august_2020'>KU 2020 (August)</a>
      <a href='#ku_2021_1_1'>KU 2021 (January) (1)</a>
      <a href='#august_2021'>KU 2021 (August)</a>
      <a href='#january_2022'>KU 2022 (January)</a>
      <a href='#ku_2022_1_1'>KU 2022 (January) (1)</a>
      <a href='#ku_2022_1_1'>KU 2022 (January) (2)</a>
      <a href='#8_2022'>KU 2022 (August)</a>
      <a href='#ku_2022_1_1'>KU 2023 (August) (1)</a>
      <a href="#ku_2023_8_1">KU 2023 (August) (1)</a>
      <a href="#ku_2023_8_2">KU 2023 (August) (2)</a>
      <a href="#ku_2023_8_3">KU 2023 (August) (3)</a>
      <a href="#ku_2023_8_4">KU 2023 (August) (4)</a>
      <a href="#ku_2023_8_5">KU 2023 (August) (5)</a>
      <a href="#k_state_2022_1">K-State 2022(1)</a>
      <a href="#References">References</a>
    </nav>
    <script src="click.js"></script><!--It is a link for click.js, which is clicking the link the hamburger menu will disappear-->
    <script src="highlight.js"></script><!--It is a link for highlight.js-->
    <script src = "mathjax_config.js"></script><!--It is a link for mathjax_configuration-->


    <section>
      <p>
        My name is Hanzhang Yin, and I have developed this website as a resource to facilitate the review of key concepts in abstract algebra, and it is not fully completed.
        Feel free to email me at <a href="mailto:hanyin@ku.edu">hanyin@ku.edu</a> if there are any errors or suggestions for improvement.
      </p>
    </section>

    <h1>Algebra</h1>

    <section id = 'linear_transformation'>
      <h2>Linear Transformation</h2>
      <p>
        <b>Example.</b> Let \( V = \mathbb{R}^3 \) with the standard basis \( B = \{(1, 0, 0), (0, 1, 0), (0, 0, 1)\} \) and let \( W = \mathbb{R}^2 \) with the standard basis \( \mathcal{E} = \{(1, 0), (0, 1)\} \). Let \( \varphi \) be the linear transformation \( \varphi(x, y, z) = (x + 2y, x + y + z) \). Since \( \varphi(1, 0, 0) = (1, 1) \), \( \varphi(0, 1, 0) = (2, 1) \), \( \varphi(0, 0, 1) = (0, 1) \), the matrix \( A = M_{\mathcal{E}, B}(\varphi) \) is the matrix
        \[
        \begin{pmatrix}
        1 & 2 & 0 \\
        1 & 1 & 1
        \end{pmatrix}.
        \]
      </p>
    </section>

    <br>

    <section id = 'dual_space'>
        <h2>Dual Space</h2>
      <p>
        <b>Definition 5.16</b> Let \( V \) be a finite-dimensional vector space over a field \( \mathbb{F} \). The dual space of \( V \), denoted by \( V' \), is \( \mathcal{L}(V, \mathbb{F}) \), that is, the vector space of all linear transformations from \( V \) to \( \mathbb{F} \), the latter regarded as a vector space of dimension one. Elements of \( V' \) are called <b>linear functions</b>.
      </p>
    </section>

    <section id = 'multiplicity'>
      <h2>Geometric Multiplicity</h2>
      <p>
        <b>Definition</b> Let \( A \) be a \( K \times K \) matrix. Let \( \lambda_k \) be one of the eigenvalues of \( A \) and denote its associated eigenspace by \( E_k \). The dimension of \( E_k \) is called the geometric multiplicity of the eigenvalue \( \lambda_k \).
      </p>
      <p>
        <a href="https://www.statlect.com/matrix-algebra/algebraic-and-geometric-multiplicity-of-eigenvalues">Source</a>
      </p>
      <p>
        <b>Remark.</b> For each eigenvalue \(\lambda\), compute \(\ker(A âˆ’ \lambda \cdot I)\). This is the
        \(\lambda\)-eigenspace, the vectors in the \(\lambda\)-eigenspace are the \(\lambda\)-eigenvectors.
      </p>
      <p>
        <a href = 'https://dept.math.lsa.umich.edu/~speyer/LinearAlgebraVideos/Lecture9c.pdf'>Source</a>
      </p>
      <p>
        <b>Remark.</b> Hence, we can know the geometric multiplicity of an eigenvalue is \(\dim(\ker(A - \lambda \cdot I)) \).
      </p>
      <h2>Algebraic multiplicity</h2>
      <p>
        The algebraic multiplicity of the eigenvalue is its multiplicity as a root of the characteristic polynomial.
      </p>
      <p>
        <b>Proposition</b> Let \( A \) be a \( K \times K \) matrix. Let \( \lambda_k \) be one of the eigenvalues of \( A \). Then, the geometric multiplicity of \( \lambda_k \) is less than or equal to its algebraic multiplicity.
      </p>
      <p>
        <a href="https://www.statlect.com/matrix-algebra/algebraic-and-geometric-multiplicity-of-eigenvalues">Source</a>
      </p>

    </section>

    <br>

    <section id = 'linear_minimal_polynomial'>
      <h2>Minimal Polynomial</h2>
      <p>
        <b>Definition.</b> Suppose \( V \) is finite-dimensional and \( T \in \mathcal{L}(V) \). Then the <b>minimal polynomial</b> of \( T \) is the unique monic polynomial \( p \in \mathcal{P}(F) \) of smallest degree such that \( p(T) = 0 \).
      </p>
      <p>
        <i><b>"Linear Algebra Done Right (Forth Edition)", Page 145</b></i>
      </p>
      <p>
        <b>Definition (Order Ideal).</b>
        Let \( T \in \mathcal{L}(V, V) \) and \( v \in V \). The <b>order ideal</b> of \( v \) with respect to \( T \), denoted by \(\text{Ann}(T, v)\), we mean the set of all polynomials \( f(x) \) such that \( v \in \text{Ker}(f(T)) \), that is, \( f(T)(v) = 0 \):
        \[
        \text{Ann}(T, v) = \{ f(x) \in \mathbb{F}[x] \mid f(T)(v) = 0 \}.
        \]
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 106</b></i>
      </p>
      <p>
        Note that \(\text{Ann}(T, v)\) contains a monic polynomial \(\mu(x)\) such that every polynomial in \(\text{Ann}(T, v)\) is a multiple of \(\mu(x)\). Recall such a polynomial is called a <b>generator</b> of \(\text{Ann}(T, v)\).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 107</b></i>
      </p>
      <p>
        <b>Definition(Minimal polynomial of \( T \) with respect to \( v \)).</b>
        Let \( V \) be a finite-dimensional vector space, \( T \) an operator on \( V \), and \( v \) a vector in \( V \). The unique monic generator of \(\text{Ann}(T, v)\) is called the <b>minimal polynomial</b> of \( T \) with respect to \( v \). It is also sometimes referred to as the order of \( v \) with respect to \( T \). It is denoted here by \( \mu_{T, v}(x) \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 107</b></i>
      </p>
      <p>
        <b>Remark.</b> Suppose \( g(x) \in \mathbb{F}[x] \) and \( g(T)(v) = 0 \). Then \( \mu_{T,v}(x) \) divides \( g(x) \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 107</b></i>
      </p>
      <p>
        <b>Definition (\(\langle T, v\rangle\)).</b> Let \( V \) be a finite-dimensional vector space, \( T \) an operator on \( V \), and \( v \) a vector from \( V \). Then the \( T \)-cyclic subspace generated by \( v \) is \(\{ f(T)(v) \mid f(x) \in \mathbb{F}[x] \} \). We will denote this by \( \langle T, v \rangle \). By the <b>order of the \( T \)-cyclic subspace</b> \( \langle T, v \rangle \) generated by \( v \), we will mean the polynomial \( \mu_{T,v}(x) \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 109</b></i>
      </p>
      <p>
        <b>Definition.</b> Let \( V \) be a finite-dimensional vector space, \( T \) an operator on \( V \). Then the <b>annihilator ideal</b> of \( T \) on \( V \), denoted by \(\text{Ann}(T, V)\) or just \(\text{Ann}(T)\), consists of all polynomials \( f(x) \) such that \( f(T) \) is the zero operator:
        \[ \text{Ann}(T) = \{ f(x) \in \mathbb{F}[x] \mid f(T)(v) = 0, \forall v \in V \} \]
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 111</b></i>
      </p>
      <p>
        <b>Definition (Minimal Polynomial).</b>
        Let \( V \) be a finite-dimensional vector space and \( T \) a linear operator on \( V \). The unique monic polynomial of least degree in \(\text{Ann}(T,V)\) is called the <b>minimal polynomial</b> of \( T \). This polynomial is denoted by \(\mu_T(x)\).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 111</b></i>
      </p>
      <p>
        <b>Theorem.</b> Let \( E/F \) be a field extension.
      </p>
      <ul>
        <li>
          For each \( A \in M_n(F) \), its minimal polynomial in \( F[T] \) is its minimal polynomial in \( E[T] \).
        </li>
        <li>
          Two matrices in \( M_n(F) \) are conjugate in \( M_n(F) \) if and only if they are conjugate in \( M_n(E) \).
        </li>
      </ul>
      <p>
        <a href = 'https://kconrad.math.uconn.edu/blurbs/linmultialg/potdiagonalizable.pdf'><i><b>"POTENTIAL DIAGONALIZABILITY", Keith Conrad</b></i></a>
      </p>
      <p>
        <b>Theorem.</b> Let \( A: V \rightarrow V \) be a linear operator. Then \( A \) is diagonalizable if and only if its minimal polynomial in \( F[T] \) splits in \( F[T] \) and has distinct roots.
      </p>
      <p>
        <a href = 'https://kconrad.math.uconn.edu/blurbs/linmultialg/minpolyandappns.pdf'><i><b>"THE MINIMAL POLYNOMIAL AND SOME APPLICATIONS," Keith Conrad</b></i></a>
      </p>
    </section>

    <br>

    <section id = "t_complement">
      <h2>\(T\)-Complement</h2>
      <p>
        <b>Definition.</b> Let \( V \) be a finite-dimensional vector space, \( T \) an operator on \( V \), and \( U \) a \( T \)-invariant subspace.
        By a <b>\( T \)-complement</b> to \( U \) in \( V \) we shall mean a \( T \)-invariant subspace \( W \) such that \( V = U \oplus W \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 123</b></i>
      </p>
    </section>

    <br>

    <section id = 'cyclic_operator'>
      <h2>Cyclic Operator</h2>
      <p>
        <b>Definition.</b>
        Let \( V \) be a finite-dimensional vector space and \( T \) an operator on \( V \). \( T \) is said to be a <b>cyclic operator</b> if there is a vector \( v \in V \) such that \( V = \langle T, v \rangle \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 114</b></i>
      </p>
    </section>

    <br>

    <section id = "indecomposable_operator">
      <h2>Indecomposable Operator</h2>
      <p>
        <b>Definition.</b> Let \( V \) be a finite-dimensional vector space and \( T \) an operator on \( V \). \( T \) is said to be an <b>indecomposable operator</b> if no non-trivial \( T \)-invariant subspace has a \( T \)-invariant complement.
        In the contrary situation, where there exists non-trivial \( T \)-invariant subspaces \( U \) and \( W \) such that \( V = U \oplus W \), we say \( T \) is decomposable.
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 123</b></i>
      </p>
      <p>
        <b>Definition.</b> Let \( V \) be a non-zero finite-dimensional vector space and \( T \) an operator on \( V \). \( T \) is said to be an <b>irreducible operator</b> if the only \( T \)-invariant subspaces are \( V \) and \( \{0\} \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 124</b></i>
      </p>
      <p>
        <b>Theorem.</b>
        Let \( V \) be an \( n \)-dimensional vector space and \( T \) an operator on \( V \). Then \( T \) is irreducible if and only if \( T \) is cyclic and \( \mu_T(x) \) is an irreducible polynomial.
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 124</b></i>
      </p>
      <p>
        <b>Theorem.</b> Let \( V \) be a finite-dimensional vector space and \( T \) an operator on \( V \). Assume \( T \) is cyclic and \( \mu_T(x) = p(x)^m \), where \( p(x) \) is an irreducible polynomial and \( m \) is a natural number. Then \( T \) is indecomposable.
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 125</b></i>
      </p>
    </section>

    <br>

    <section>
      <p>
        <b>Theorem.</b>
        Let \( V \) be a finite-dimensional vector space, \( T \) an operator on \( V \), and assume the minimal polynomial of \( T \) is \( \mu_T(x) = p_1(x)^{e_1} \cdots p_t(x)^{e_t} \), where the polynomials \( p_i(x) \) are irreducible and distinct.
        For each \( i \), let
        \[
        V_i = V(p_i) = \{ v \in V \mid p_i(T)^{e_i}(v) = 0 \} = \text{Ker}(p_i(T)^{e_i}).
        \]
        Then each of the spaces \( V_i \) is \( T \)-invariant and
        \[
        V = V_1 \oplus V_2 \oplus \cdots \oplus V_t.
        \]
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 132</b></i>
      </p>
      <p>
        <b>Theorem.</b> Let \( V \) be a finite-dimensional vector space and \( T \) a linear operator on \( V \) with minimal polynomial \( \mu_T(x) \). Let \( v \) be a vector such that \( \mu_{T,v}(x) = \mu_T(x) \). Then \( \langle T, v \rangle \) has a \( T \)-invariant complement in \( V \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 134</b></i>
      </p>
    </section>

    <br>

    <section id = 'characteristic_polynomial'>
        <h2>Characteristic Polynomial</h2>
      <p>
        <b>Theorem.</b> Let \( V \) be a finite-dimensional vector space and \( T \) a linear operator on \( V \). Then there are vectors \( \vec{w}_1, \vec{w}_2, \ldots, \vec{w}_r \) such that the following hold:
      </p>
      <p>
        i. \( V = \langle T, \mathbf{w}_1 \rangle \oplus \cdots \oplus \langle T, \mathbf{w}_r \rangle \).
        </p>
      <p>
        ii. If \( d_i(x) = \mu_{T, \mathbf{w}_i}(x) \) then \( d_r(x) \mid d_{r-1}(x) \mid \cdots \mid d_1(x) = \mu_T(x) \).
        </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 134</b></i>
      </p>
      <p>
        <b>Definition.</b> The polynomials \( d_1(x), d_2(x), \ldots, d_r(x) \) are called the invariant factors of \( T \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 135</b></i>
      </p>
      <p>
        <b>Definition.</b> Let \( V \) be an \( n \)-dimensional vector space and \( T \) be a linear operator on \( V \). The polynomial (of degree \( n \)) obtained by multiplying the invariant factors of \( T \) is called the <b>characteristic polynomial</b> of \( T \). It is denoted by \( \chi_T(x) \).
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 135</b></i>
      </p>
      <p>
        <b>Theorem.</b> Any eigenvalue of a linear operator is a root of its minimal polynomial in \( F[T] \), so the minimal polynomial and characteristic polynomial have the same roots.
      </p>
      <p>
        <a href = 'https://kconrad.math.uconn.edu/blurbs/linmultialg/minpolyandappns.pdf'><i><b>"THE MINIMAL POLYNOMIAL AND SOME APPLICATIONS", Keith Conrad</b></i></a>
      </p>
    </section>

    <br>

    <section id = 'diagonalizable'>
      <p>
        <b>Theorem.</b> Let \( V \) be a finite-dimensional vector space and \( T \) a linear operator on \( V \). Then \( T \) is diagonalizable if and only if \( T \) is completely reducible and \( \mu_T(x) \) factors into linear factors.
      </p>
      <p>
        <i><b>"Advanced Linear Algebra (2nd Edition)", Page 136</b></i>
      </p>
      <p>
        <b>Theorem.</b> A matrix in \( M_n(F) \) is diagonalizable over some extension field of \( F \) if and only if its minimal polynomial in \( F[T] \) is separable.
      </p>
      <p>
        <a href = 'https://kconrad.math.uconn.edu/blurbs/linmultialg/potdiagonalizable.pdf'>"POTENTIAL DIAGONALIZABILITY", Keith Conrad</a>
      </p>
    </section>

    <br>

    <section id = 'smith_normal_form'>
      <p>
        <b>Proposition.</b> Let \( K_A \) be the column space of an \( m \times n \) matrix \( A \) and let \( B = PAQ \) where \( P \) and \( Q \) are invertible matrices. Then \( K_A \cong K_B \). Moreover, \(\mathbb{Z}^m / K_A \cong \mathbb{Z}^m / K_B \).
      </p>
      <p>
        <b>Proof.</b> Given that \(K_A\) is the column space of an \(m \times n\) matrix \(A\) over \(\mathbb{Z}\).
        If \(y\in K_A\), then we can know that there exists \(x\in \mathbb{Z}^n\) such that \(y = Ax\).
        Given that \(Q\) is an invertible matrix, we can know that \(y = Ax = A(Q^{-1}Q)x = (AQ)(Q^{-1}x)\), where \(Q^{-1}x\in \mathbb{Z}^n\).
        Hence, we can know that \(y\in K_{AQ}\). Thus, we have \(K_A \subseteq K_{AQ}\).
        For the other direction, we can know that if \(y\in K_{AQ}\), there exists \(x\in \mathbb{Z}^n\) such that \(y = AQx\).
        Since \(Qx\in \mathbb{Z}^n\), we can know that \(y = AQx = A(Qx)\), which implies that \(y\in K_A\) and \(K_{AQ} \subseteq K_A\).
        Thus, we can know that \(K_A = K_{AQ}\).
        Now, we want to show that \(K_A \cong K_{PA}\).
        We define a map \( \phi: K_A \to K_{PA} \) by \( \phi(x) = Px \). Since \(P\) is invertible, we can know that \( \phi \) is a bijection.
        Hence, we can know that \( K_A \cong K_{PA} \). Thus, we can know that \(K_A\cong K_{PA} = K_{PAQ} = K_B\).
        Given that \(K_A \cong K_B\), we can know that \(\mathbb{Z}^m/K_A \cong \mathbb{Z}^m/K_B\). \(\blacksquare\)
      </p>
    </section>

    <section id = 'normal_subgroup'>
      <h2>Normal Subgroup</h2>
      <p>
        $\textbf{Definition. }$ Let \(G\) be a group and \(H\) be a subgroup of \(G\).
        We say that \(H\) is a \(\textit{normal subgroup}\) of \(G\) if \(gH = Hg\) for all \(g\in G\).
      </p>
      <p>
        \(\textbf{Proposition. }\) Let \(\phi : G_1 \to G_2\) be a group homomorphism, with kernel \(K\). Then \(K\) is a normal subgroup of \(G_1\). Conversely, any normal subgroup of \(G_1\) is the kernel of a group homomorphism whose domain is \(G_1\). Thus, normal subgroups are exactly kernels of group homomorphisms.
      </p>
      <p>
        \(\textbf{Theorem. }\)Let \(\phi : G_1 \to G_2\) be a surjective group homomorphism with kernel \(K\). Then there is a one-to-one, and onto correspondence between the subgroups of \(G_1\) containing \(K\) and the subgroups of \(G_2\) given by \(H \mapsto \phi(H)\), for \(H \subseteq G_1\) containing \(K\), and \(L \mapsto \phi^{-1}(L)\), for \(L \subseteq G_2\). Under this correspondence, \(\phi(H)\) is normal in \(G_2\), if \(H\) is normal in \(G_1\) and \(\phi^{-1}(L)\) is normal in \(G_1\), if \(L\) is normal in \(G_2\).
      </p>
      <p>
        \(\textbf{Corollary. }\) Let \( G \) be a group and \( N \) a normal subgroup. Then there is a one-to-one, onto correspondence between the subgroups of \( G \) containing \( N \) and the subgroups of \( G/N \). Under this correspondence, the normal subgroups of \( G \) containing \( N \) correspond to the normal subgroups of \( G/N \).
      </p>
      <p>
        \(\textbf{Theorem. }\) Let \(G\) be a group and \(H \subseteq G\) a subgroup. Assume that \([G : H]\) is the smallest prime dividing the order of \(|G|\). Then \(H\) is normal in \(G\).
      </p>
      <p>
        \(\textbf{Theorem. }\) Let \(G\) be a group and \(H \subset G\) a subgroup. Assume that \([G : H]\) is the smallest prime dividing the order of \(|G|\). Then \(H\) is normal in \(G\).
      </p>
      <p>
        \(\textbf{LaGrange's Theorem.}\) Let \(G\) be a finite group and \(H \subseteq G\) a subgroup. Then
        \[
        |G| = |H| \cdot (\text{number of distinct left cosets of } H)\\
        = |H| \cdot (\text{number of distinct right cosets of } H).
        \]
      </p>
    </section>

    <br>

    <section id="isomorphism">
      <h2>Isomorphism</h2>
      <p>
        \(\textbf{Definition. }\) Let \(G_1\) and \(G_2\) be groups. A bijective function \(\phi: G_1\to G_2\) is called an isomorphism if for all \(a, b\in G_1\), we have
        \[
        \phi(ab) = \phi(a)\phi(b).
        \]
      </p>
      <p>
        \(\textbf{First Isomorphism Theorem. }\)Let \(\phi : G_1 \to G_2\) be a surjective group homomorphism with kernel \(K\). Then \(G_1/K \cong G_2\).
      </p>
      <p>
        \(\textbf{Second Isomorphism Theorem. }\)
        Let \(K \subseteq N \subseteq G\) be groups such that \(K\) and \(N\) are normal in \(G\). Then \(N/K\) is a normal subgroup of \(G/K\) and \((G/K)/(N/K) \cong G/N\).
      </p>
      </section>

    <section id = 'sage_subgroup'>
      <h2>Sage Subgroup</h2>
      <p>
        Now, we try to define some subgroups in SageMath:
      </p>
      <p>
       For example: \(S_3, \mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}_2\).
      </p>
      <div class="code-box-container">
      <div class="code-box">
        <pre><code class="language-python">
        <span class="comment"># Define the group S3 using AbelianGroup</span>
        <span class="keyword">sage:</span> <span class="variable">S3</span> = <span class="function">SymmetricGroup</span>(<span class="number">3</span>)

        <span class="comment"># Define the group Z2 x Z2 x Z2 using AbelianGroup</span>
        <span class="keyword">sage:</span> <span class="variable">Z2xZ2xZ2</span> = <span class="function">AbelianGroup</span>(<span class="bracket">[</span><span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span><span class="bracket">]</span>)
            </code>
        </pre>
        </div>
      </div>
    </section>

    <br>


    <section id = "center">
      <h2>Center</h2>
      <p>
        \(\textbf{Definition. }\)Let \(G\) be a group.
        The set of all elements of \(G\) that commute with every element of \(G\) such that
        \[
        Z(G) = \{g\in G\mid gx=xg\text{ for all }x\in G\},
        \]
        is called the center of \(G\).
      </p>
    </section>

    <br>


    <section id = "centralizer">
    <h2>Centralizer</h2>
      <p>
        \(\textbf{Definition. }\)Let \(A\) be any subset of a group \(G\). A subset of a\(G\) such that
        \[
        C_G(A) = \{g\in G\mid gag^{-1}=a\text{ for all }a\in A\},
        \]
        is called the centralizer of \(A\) in \(G\).
      </p>
      <P>
        \(\textbf{Proposition. }\)Let \(A\) be any subset of a group \(G\). Then \(C_G(A)\) is a subgroup of \(G\).
      </P>
      <p>
        \(\textbf{Proof. }\)We will prove it with subgroup criterion. Let \(x, y\in C_G(A)\) and \(a\in A\). Then we have
        \[
        yay^{-1}=a\in A.
        \]
        Hence,
        \[
        \begin{align}
          y^{-1}yay^{-1}y &= y^{-1}ay = a\in A.
        \end{align}
        \]
        Thus, we have \(y^{-1}\in C_G(A)\). Moreover, we have
        \[
        \begin{align}
          (xy^{-1})a(xy^{-1})^{-1} &= x(y^{-1}ay)x^{-1}\\
          &= xax^{-1} \\
          &= a\in A.
        \end{align}
        \]
        Hence, we have \(xy^{-1}\in C_G(A)\). Therefore, \(C_G(A)\) is a subgroup of \(G\). \[ \tag*{\(\square\)} \]
      </p>
    </section>


    <br>

    <section id = "normalizer">
    <h2>Normalizer</h2>
    <p>
      \(\textbf{Definition. }\) Let \(A\) be any set of a group \(G\). A subset of \(G\) such that
      \[
      N_G(A) = \{g\in G\mid gAg^{-1}=A\},
      \]
      is called the normalizer of \(A\) in \(G\).
    </p>
    </section>

    <br>

    <section id = "stabilizer">
      <h2>Stabilizer</h2>
      <h3>Stabilizer of An Element</h3>
    <p>
      \(\textbf{Definition. }\)Let \(G\) be a group and \(x\) be an element. A subset of \(G\) such that
      \[
      G_x = \{g\in G\mid gx=x\},
      \]
      is called the stabilizer of \(x\) in \(G\).
    </p>
    <h3>Stabilizer of A Set</h3>
    <p>
      \(\textbf{Definition. }\)Let \(G\) be a group and \(X\) be a set. A subset of \(G\) such that
      \[
      G_X = \{g\in G\mid gx=x\text{ for all }x\in X\},
      \]
      is called the stabilizer of \(X\) in \(G\).
    </p>
    </section>

    <br>

    <section id="orbit">
      <h2>Orbit</h2>
      <p>
        \(\textbf{Definition. }\) Let \(G\) be a group acting on a set \(X\). The orbit of an element \(x\in X\) is the set
        \[
        Gx = \{gx\mid g\in G\}.
        \]
      </p>
      <p>
        \(\textbf{Lemma.}\)Let \(G\) be a group of order \(p^t\), with \(p\) prime, and assume \(G\) acts on the finite set \(X\). If \(r\) denotes the number of orbits with just one element, then \(|X| \equiv r \pmod{p}\).
      </p>
      <p>
        \(\textbf{Proposition.}\) Assume the group \( G \) acts on the set \( X \). Fix \( x \in X \). Then there is a 1-1, onto set map between \(\text{orb}(x)\) and the set of distinct left cosets of \( G_x \) given by \( g \cdot x \mapsto gG_x \). In particular, if \(\text{orb}(x)\) or \([G : G_x]\) is finite, then \(\left|\text{orb}(x)\right| = [G : G_x]\), and it follows that \(\left|\text{orb}(x)\right|\) divides \(\left|G\right|\), if \( G \) is finite.
      </p>
      <p>
        <b>Orbit Stabilizer Theorem.</b>
        Let \( G \) be a group which acts on a finite set \( X \).
        Let \( x \in X \).
        Let \( \text{Orb}(x) \) denote the orbit of \( x \).
        Let \( \text{Stab}(x) \) denote the stabilizer of \( x \) by \( G \).
        Let \( [G : \text{Stab}(x)] \) denote the index of \( \text{Stab}(x) \) in \( G \).
        Then:
        \[
        |\text{Orb}(x)| = [G : \text{Stab}(x)] = \frac{|G|}{|\text{Stab}(x)|}
        \]
      </p>
      <p>
        <a href = "https://proofwiki.org/wiki/Orbit-Stabilizer_Theorem">Source: Wiki Proof</a>
      </p>
      <p>
        \(\textbf{Class Equation. }\) Let \( G \) be a finite group. Then:
        \[
          |G| = |Z(G)| + \sum_{i=1}^r |c(x_i)| = |Z(G)| + \sum_{i=1}^r [G : C_G(x_i)],
        \]
        where the sum is taken over the distinct conjugacy classes with more than one element. Here \( Z(G) \) denotes the center of \( G \), where \( Z(G) := \{g \in G \mid gx = xg, \text{ for all } x \in G\} \).
      </p>
    </section>

    <br>

    <section id = "p_group">
      <h2>\(p\)-group</h2>
      <p>
        \(\textbf{Definition(\(p\)-group). }\)A group \(G\) is called a \(p\)-group if \(|G|=p^n\) (order of \(G\) is \(p^n\)) for some prime \(p\) and some integer \(n\geq 0\).
      </p>
      <h2>\(p\)-subgroup</h2>
      <p>
        \(\textbf{Definition(\(p\)-subgroup). }\)A subgroup \(H\) of a group \(G\) is called a \(p\)-subgroup if \(|H|=p^n\) for some prime \(p\) and some integer \(n\geq 0\).
      </p>
    </section>

    <br>

    <section id = "sylow_p_subgroup">
      <h2>Sylow \(p\)-Subgroup</h2>
      <p>
        \(\textbf{Definition. }\)Let \(G\) be a group and \(p\) be a prime.
        If \(G\) is a group of order \(p^nm\) where \(p\not\mid m\),
        then a subgroup \(H\) of \(G\) such that \(|H|=p^n\) is called a Sylow \(p\)-subgroup of \(G\).
      </p>
      <h2>\(Syl_p(G)\)</h2>
      <p>
        \(\textbf{Definition. }\)Let \(G\) be a group and \(p\) be a prime.
        The set of all Sylow \(p\)-subgroups of \(G\) is denoted by \(Syl_p(G)\).
      </p>
      <h2>\(n_p(G)\)</h2>
      <p>
        \(\textbf{Definition. }\)Let \(G\) be a group and \(p\) be a prime.
        The number of Sylow \(p\)-subgroups of \(G\) is denoted by \(n_p(G)\).
      </p>
    </section>

    <br>

    <section id = 'sylow_theorem'>
      <h2>Sylow's Theorem</h2>
      <p>
      \(\textbf{Sylow's Theorem. }\) Let \( G \) be a group of order \( p^{\alpha} m \), where \( p \) is a prime not dividing \( m \).
      </p>
      <ul>
        <li>
        \(\textbf{First Sylow's Theorem. }\) Sylow \( p \)-subgroups of \( G \) exist, i.e., \( \text{Syl}_p(G) \neq \emptyset \).
        </li>
        <li>
        \(\textbf{Second Sylow's Theorem.}\) If \( P \) is a Sylow \( p \)-subgroup of \( G \) and \( Q \) is any \( p \)-subgroup of \( G \), then there exists \( g \in G \) such that \( Q \leq gPg^{-1} \), i.e., \( Q \) is contained in some conjugate of \( P \). In particular, any two Sylow \( p \)-subgroups of \( G \) are conjugate in \( G \).
        </li>
        <li>
        \(\textbf{Third Sylow's Theorem.}\) The number of Sylow \( p \)-subgroups of \( G \) is of the form \( 1 + kp \), i.e.,
        \[ n_p \equiv 1 \mod p .\]
        </li>
      Further, \( n_p \) is the index in \( G \) of the normalizer \( N_G(P) \) for any Sylow \( p \)-subgroup \( P \), hence \( n_p \) divides \( m \).
      </ul>
    </section>

    <br>

    <section id = 'direct_product'>
      <h2>Direct Product</h2>
      <p>
        <b>Proposition.</b> Let \( H \) and \( K \) be subgroups of the group \( G \). The number of distinct ways of writing each element of the set \( HK \) in the form \( hk \), for some \( h \in H \) and \( k \in K \), is \( |H \cap K| \). In particular, if \( H \cap K = 1 \), then each element of \( HK \) can be written uniquely as a product \( hk \), for some \( h \in H \) and \( k \in K \).
      </p>
      <p>
        <b>Theorem.</b> Suppose \( G \) is a group with subgroups \( H \) and \( K \) such that
      </p>
      <ul>
        <li>
          \( H \) and \( K \) are normal in \( G \), and
        </li>
        <li>
          \( H \cap K = 1 \).
        </li>
      </ul>
      <p>
        <i><b>"Abstract Algebra", Dummit & Foote, Third Edition, Page 171</b></i>
      </p>
    </section>

    <br>

    <section id = 'simple_group'>
      <h2>Simple Group</h2>
      <p>
        \(\textbf{Definition. }\) A group \(G\) is \(\textit{simple}\) if \(G\) is nontrivial and the only normal subgroups of \(G\) are \(\{e\}\) and \(G\).
      </p>
      <p>
        \(\textbf{Theorem. }\) Let \(G\) be a simple group of order \(60\). Then \(G\) is isomorphic to \(A_5\).
      </p>
      <p>
        \(\textbf{Theorem. }\) The alternating group \(A_n\) is a simple group for \(n \geq 5\). In other words, there are no proper normal subgroups of \(A_n\), for \(n \geq 5\).
      </p>
    </section>

    <br>

    <section id = 'solvable_group'>
      <h2>Solvable Group</h2>
      <p>
        <b>Definition.</b> A finite group \( G \) is <i><b>solvable</b></i> if there are subgroups
        \[
        \{e\} = G_n \subseteq G_{n-1} \subseteq \cdots \subseteq G_1 \subseteq G_0 = G
        \]
        such that for \( i = 1, \ldots, n \) we have:
      </p>
        <ul>
          <li>
            (a) \( G_i \) is normal in \( G_{i-1} \).
          </li>
          <li>
            (b) \( [G_{i-1} : G_i] \) is prime.
          </li>
        </ul>
      <p>
      \(\textbf{Theorem. }\) Let \( G \) be a finite group with \( |G| = p^n \), with \( p \) prime and \( n \geq 1 \). Then:
      </p>
      <ul>
        <li>
          (i) \( Z(G) \neq \{e\} \).
        </li>
        <li>
          (ii) There is a sequence of subgroups \( \{e\} \subseteq H_1 \subseteq H_2 \subseteq \cdots \subseteq H_{n-1} \subseteq H_n = G \) such that each \( H_i \) is a normal subgroup of \( H_{i+1} \) and the quotient group \( H_{i+1}/H_i \cong \mathbb{Z}_p \).
        </li>
      </ul>

      <br>

      <p>
          <b>Theorem.</b> Let \(G\) be a group and \(H\) a normal subgroup. Then \(G\) is solvable if and only if \(H\) and \(G/H\) are solvable.
      </p>
      <p>
          <b>Proof.</b> Firstly, we want to show that if \(G\) is solvable, then we have \(H\) is solvable, and \(G/H\) is solvable.
          Given that \(G\) is solvable and \(H\) is normal. We can know that
          \[
            \{e\} = G_0\subset G_1\subset \dots G_r = G,
          \]
          where \(G_i\) is normal in \(G_{i+1}\) and \(G_{i+1}/G_i\) is abelian.
          Now, we define \(H_{i} = H\cap G_i\).
          Suppose that \(h'\in H_i\), we can know that for any \(h\in H_{i+1}\), we have \(h\cdot h'\cdot h^{-1}\in H\) since \(h, h', h^{-1}\in H\).
          At the same time, we can know that \(h\cdot h'\cdot h^{-1}\in G_i\), since \(h'\in G_i\) and \(G_i\) is normal in \(G_{i+1}\).
          Thus, we showed that \(h\cdot h'\cdot h^{-1}\in H\cap G_i = H_i\). Hence, we can know that \(H_i\) is normal in \(H_{i+1}\).
          Now, we define a map \(\varphi: H_{i+1}/H_i\to G_{i+1}/G_i\) such as
          \[
            \varphi(g\cdot H_i) = g\cdot G_i.
          \]
          Firstly, we want to show that the map is well-defined.
          Suppose that \(g\cdot H_i = h\cdot H_i\). Hence, we have \(h^{-1}\cdot g\in H_i\), which implies that \(h^{-1}g\in G_i\) for \(H_i\subset G_i\).
          Thus, we can know that \(h^{-1}g\cdot G_i \subset G_i\). Hence, for any \(g'\in G_i\) we have
          \[
            h^{-1}g\cdot g'\in G_i,
          \]
          which implies that
          \[
            g\cdot g'\in h\cdot G_i, \text{ for any }g'\in G_i.
          \]
          Thus, we have \(g\cdot G_i\subset h\cdot G_i\).
          Similarly, we can get \(g^{-1}h\in H_i\) from \(g\cdot H_i = h\cdot H_i\). Then, it shows that \(g^{-1}h\in G_i\), which implies that \(h\cdot G_i\subset g\cdot G_i\).
          Hence, we have \(g\cdot G_i = h\cdot G_i\) (i.e. \(\varphi(g\cdot H_i) = \varphi(h\cdot H_i)\)), and we showed the map is well-defined.
          Next, we need to show that \(\varphi\) is a homomorphism.
          Let \(g, h\in H_{i+1}\), we have
          \[
          \begin{align}
            \varphi(g\cdot H_i)\cdot \varphi(h\cdot H_i) &= g\cdot G_i\cdot h\cdot G_i = g\cdot hG_i, \\
            \varphi(gH_i\cdot hH_i) &= \varphi(g\cdot hH_i) = g\cdot hG_i.
          \end{align}
          \]
          Thus, we have \(\varphi(g\cdot H_i)\cdot \varphi(h\cdot H_i) = \varphi(gH_i\cdot hH_i)\).
          After that, we want to show that \(\varphi\) is injective.
          Suppose that \(\varphi(gH_i) = \varphi(hH_i)\) (i.e. \(gG_i = hG_i\)). Hence, we have \(h^{-1}g\in G_i\).
          Since \(h, g\in H\), we have \(h^{-1}g\in H\), which implies that \(h^{-1}g\in H_i\). Again, we can get \(gH_i\subset hH_i\).
          By the same process, we can get \(g^{-1}h\in G_i\), which will lead us to \(hH_i\subset gH_i\).
          Thus, \(gH_i = hH_i\). Hence, \(\varphi\) is injective. It allows us to know that \(\varphi(H_{i+1}/H_i)\) is a subgroup of \(G_{i+1}/G_i\).
          Since \(G_{i+1}/G_i\) is abelian by assumption, and \(H_{i+1}/H_i\cong \varphi(H_{i+1}/H_i)\subset G_{i+1}/G_i\), we can know that \(H_{i+1}/H_i\) is abelian for subgroup of an abelian group is abelian.
          Thus, we have
          \[
            \{e\} = \{e\}\cap H= H_0\subset H_1\subset \dots H_r = H\cap G,
          \]
          where each \(H_i\) is normal in \(H_{i+1}\) and \(H_{i+1}/H_i\) is abelian. Therefore, \(H\) is solvable.
        Now we need to show that \(G/H\) is solvable.
        We define \(K_i = G_i/H\) and want to show that \(K_i\) is normal in \(K_{i+1}\).
        Let \(gH\in K_{i+1}\) and \(g'H\in K_i\). We have
        \[
          (gH)(g'H)(gH)^{-1} = gHg'Hg^{-1}H = g g'g^{-1}H.
        \]
        Since \(G_i\) is normal in \(G_{i+1}\), we have \(g g'g^{-1}\in G_i\), which implies that \(g\cdot g'\cdot g^{-1}H \in G_i/H = K_i\).
        Hence, we show that \(K_i\) is normal in \(K_{i+1}\).
        Now, we need to show that \(K_{i+1}/K_i\) is abelian.
        If \(H\subset G_i\subset G_{i+1}\), we can know \(H\) is normal in \(G_i\) since \(H\) is normal in \(G\).
        By the Third Isomorphism Theorem, we have
        \[
           G_{i+1}/G_i\cong (G_{i+1}/H)/(G_i/H).
        \]
        Then, we have \((G_{i+1}/H)/(G_i/H)\) is abelian since \(G_{i+1}/G_i\) is abelian by assumption.
        (To be continued...)
        Now, suppose that \(H\) is a normal subgroup of \(G\), and \(H\) and \(G/H\) are solvable.
        We want to show that \(G\) is solvable. Since \(H\) is solvable, we have
        \[
        \{e\} = H_0\subset H_1\subset \dots H_n = H,
        \]
        where each \(H_i\) is normal in \(H_{i+1}\) and \(H_{i+1}/H_i\) is abelian.
        Since \(G/H\) is solvable, we have
        \[
        H \subset G_1/H\subset \dots \subset G_m/H = G/H,
        \]
        where \(H\subset G_i\) for all \(i\).
        Moreover, we have \(G_i/H\) is normal in \(G_{i+1}/H\) and \((G_{i+1}/H)/(G_i/H)\) is abelian.
        Since \(G_i/H\) is normal in \(G_{i+1}/H\), let \(g\in G_{i+1}\) and \(g'\in G_i\), we have
        \[
        \begin{align}
          (gH)(g'H)(gH)^{-1} &= gHg'Hg^{-1}H = g g'g^{-1}H\in G_i/H.
        \end{align}
        \]
        It shows that \(g g'g^{-1}\in G_i\), which implies that \(G_i\) is normal in \(G_{i+1}\).
        Since \((G_1/H)/H\cong G_1/H\), we have \(G_1/H\) is abelian.
        Thus, we can have a chain such as
        \[
        \{e\} = H_0\subset H_1\subset \dots H_n = H\subset G_1\subset \dots \subset G_m = G,
        \]
        where each \(H_i\) is normal in \(H_{i+1}\) and \(H_{i+1}/H_i\) is abelian, and each \(G_i\) is normal in \(G_{i+1}\) and \(G_{i+1}/G_i\) is abelian.
        Moreover, \(H\) is normal in \(G_1\) since \(H\) is normal in \(G\), and \(G_1/H\) is abelian.
        Therefore, we have \(G\) is solvable. \(\blacksquare\)
      </p>
      <p>
          <i><b>"Algebra", Page 19</b></i>
      </p>
    </section>


    <br>

    <section id = 'field'>
      <h2>Field</h2>
      <h3>Division Ring</h3>
      <p>
        \(\textbf{Definition. }\) A <strong>division ring</strong> is a ring \(R\) with identity \(1\) such that every nonzero element of \(R\) is a unit
        (i.e. every nonzero element of \(R\) has a multiplicative inverse).
      </p>
      <p>
        \(\textbf{Definition. }\) A <strong>field</strong> is a commutative ring \(R\) with identity \(1\) such that every nonzero element of \(R\) is a unit
        (i.e. commutative division ring).
      </p>
    </section>

    <br>

    <section id = 'ideal'>
      <p>
        \(\textbf{Proposition(1). }\) Let \(R\) be a ring with identity \(1\), and \(I\) is an ideal of \(R\). \(R = I\) if and only if \(I\) contains a unit.
      </p>
      <p>
        \(\textbf{Proof. }\)Firstly, suppose that \(R = I\).
        Since \(R\) is a ring with identity \(1\), then we can know that \(1\) is unit in \(R\).
        Hence, we can see that \(I\) contains a unit.
        For the other direction, suppose that \(I\) contains a unit \(u\in R\).
        Then we can know that there exists an inverse \(u^{-1}\in R\) such that \(u^{-1}u = 1\).
        Hence, we have for any \(r\in R\),
        \[
          r = r(1) = r(u^{-1}u) = (ru^{-1})(u)\in I.
        \]
        Therefore, we have \(R\subset I\). Since \(I\subset R\), we have \(R = I\). \(\blacksquare\)
      </p>
      <p>
        <b>Proposition 5.1 (Correspondence Theorem for Rings)</b>. If \( I \) is a proper ideal in a commutative ring \( R \), then there is an inclusion-preserving bijection \(\varphi\) from the set of all ideals \( J \) in \( R \) containing \( I \) to the set of all ideals in \( R/I \), given by
        \[ \varphi : J \mapsto J/I = \{ a + I \mid a \in J \} \].
      </p>
    </section>

    <br>

    <section id = 'prime'>
      <p>
        \(\textbf{Theorem. }\) Suppose that \(p\) is in a ring \(R\). Then \(p\) is prime if and only if \((p)\) is a prime ideal.
      </p>
      <p>
        \(\textbf{Proof. }\) We firstly show that if \(p\) is prime then \((p)\) is a prime ideal. Suppose that \(p\) is prime.
        Then we have \(p\neq 0\) and \(p\) is not a unit. If \(p\mid ab\) where \(a, b\in R\), then we have \(ab = pr\) for some \(r\in R\).
        In other words, \(ab\in (p)\). Since \(p\) is prime, we have \(p\mid a\), which implies that \(a = pu\) for some \(u\in R\) (i.e. \(a\in (p)\)),
        or \(p\mid b\), which implies that \(b = pv\) for some \(v\in R\) (i.e. \(b\in (p)\)). Therefore, we have \((p)\) is a prime ideal.
        For the other direction, we suppose that \((p)\) is a prime ideal. If \(ab\in (p)\) for some \(a, b\in R\), then we have \(ab = pr\) for some \(r\in R\).
        Since \((p)\) is a prime ideal, we have \(a\in (p)\) or \(b\in (p)\). Thus, we have \(p\mid a\) or \(p\mid b\). Therefore, \(p\) is prime. \(\blacksquare\)
      </p>
    </section>

    <br>

    <section id = 'homomorphism'>
      <p>
        \(\textbf{Corollary. }\) If \(R\) is a field then any nonzero ring homomorphism \(\varphi: R\to S\) is injective.
      </p>
      <p>
        \(\textbf{Proof. }\) Given \(R\) is a field, we can know that the only ideals of \(R\) are \(\{0\}\) and \(R\).
        We know that \(\ker(\varphi)\) is an ideal of \(R\). Thus, we only have two options, \(\ker(\varphi) = \{0\}\) or \(\ker(\varphi) = R\).
        Suppose that \(a\in \ker(\varphi)\) where \(a\neq 0\). Since \(R\) is a field, we have \(a^{-1}\in R\). Then we have
        \[
          0 = \varphi(a)\cdot \varphi(a^{-1}) = \varphi(aa^{-1}) = \varphi(1) = 1,
        \]
        which is a contradiction. Thus, we have \(\ker(\varphi) = \{0\}\). Therefore, \(\varphi\) is injective. \(\blacksquare\)
      </p>
    </section>


    <br>

    <section id = 'integral_domain'>
    <h2>Integral Domain</h2>
    <p>
      \(\textbf{Definition. }\) An integral domain is a commutative ring \(R\) with identity \(1\neq 0\) such that
      \[
        ab = 0 \implies a = 0 \text{ or } b = 0.
      \]
      (i.e. there is no zero divisors in \(R\)).
    </p>
    <p>
      \(\textbf{Statements of principal ideals. }\)For an integral domain \( R \):
    </p>
      <ul>
        <li> \( a \mid b \) if and only if \( \langle b\rangle  \subseteq \langle a\rangle \). </li>
        <li> \( \langle a \rangle= \langle b\rangle \) if and only if \( b = a\cdot u \), for some unit \( u \in R \). </li>
        <li> \( q \in R \) is irreducible if and only if \( \langle q\rangle \) is maximal among principal ideals. </li>
        <li> \( p \in R \) is prime if and only if whenever \( ab \in \langle p\rangle \), \( a \in \langle p \rangle \) or \( b \in \langle p \rangle \). </li>
      </ul>
      <ul>
        <li>\(\textbf{Example 1. }\) \(\mathbb{Z}\) is an integral domain.</li>
        <li>\(\textbf{Example 2. }\) \(\mathbb{Z}[i]\) (Gaussian Integer) is an integral domain.</li>
      </ul>
        <p>
          \(\textbf{Proof (2).}\) The major part is to show that there is no zero divisor in \(\mathbb{Z}[i]\).
          Suppose that there exists zero divisors in \(\mathbb{Z}[i]\).
          Suppose \(a + b i, c + d i\in \mathbb{Z}[i]\) such that \((a + b i)(c + d i) = 0\), where
          \(a\) or \(b\) is not zero and \(c\) or \(d\) is not zero. Then we have
          \[
            \begin{align}
            (a + bi)(c + di) &= 0\\
            ac + adi + bci + bdi^2 &= 0\\
            ac - bd + (ad + bc)i &= 0\\
            ac - bd &= 0\\
            ad + bc &= 0\\
            ac &= bd\\
            ad &= -bc\\
            \end{align}
          \]
          Then we have
          \[
          \begin{align}
            acd & = bd^2\\
            acd & = -bc^2\\
            bd^2 &= -bc^2\\
            d^2 &= -c^2\\
            d^2 + c^2 &= 0\\
          \end{align}
          \]
          Since \(d, c\in \mathbb{Z}\), we have \(d = c = 0\). However, we assume that \(c\) or \(d\) is not zero, which is a contradiction.
        </p>
      <ul>
        <li>\(\textbf{Example 3. }\) Quadratic Integer Ring \(\mathbb{Z}(\sqrt{D})\) is an integral domain</li>
        <li>\(\textbf{Example 4. }\) All fields are integral domains.</li>
        <li>\(\textbf{Claim 1. }\)\(2\) is irreducible in \(\mathbb{Z}(\sqrt{-5})\)</li>
      </ul>
          <p>
            \(\textbf{Proof. }\) suppose that \(2 = (a + b\sqrt{-5})(c + d\sqrt{-5})\) for some \(a, b, c, d\in \mathbb{Z}\).
            Then we have
            \[
            \begin{align}
              2 &= (a + b\sqrt{-5})(c + d\sqrt{-5})\\
              2 &= ac - 5bd + (ad + bc)\sqrt{-5}\\
            \end{align}
            \]
            We can see that \(ad + bc = 0\). Then we have
            \[
            \begin{align}
            2 &= ac - 5bd\\
            2 &= ac - 5bd - (ad + bc)\sqrt{-5}\\
            2 &= (a - b\sqrt{-5})(c + d\sqrt{-5})\\
            \end{align}
            \]
            In that case, we have
            \[
            \begin{align}
            4 &= 2\cdot 2\\
            4 &= (a + b\sqrt{-5})(c + d\sqrt{-5})(a - b\sqrt{-5})(c + d\sqrt{-5})\\
            4 &= (a^2 + 5b^2)(c^2 + 5d^2)\\
            \end{align}
            \]
            Thus, we can see that if \(b\neq 0\), then we have \(a^2 + 5b^2 \geq 5\).
            Similarly, if \(d\neq 0\), then we have \(c^2 + 5d^2 \geq 5\).
            Hence, we can see that \(b = d = 0\). Then we have \(2 = ac\).
            Since \(2\) is a prime number, we have \(a = 1\) and \(c = 2\).
            Therefore, we have \(2 = (2 + 0\sqrt{-5})(1 + 0\sqrt{-5})\), where one of them is a unit.
            Then, we have \(2\) is irreducible in \(\mathbb{Z}(\sqrt{-5})\). \( \blacksquare\)
          </p>
      <ul>
          <li>\(\textbf{Claim 2.}\) \(3\) is irreducible in \(\mathbb{Z}(\sqrt{-5})\)</li>
        </ul>
          <p>
            \(\textbf{Proof. }\) To show that \(2\) is not a prime, we only need to come up with an example.
            Firstly, we can see that \(6 = (1 + 5) = (1 + \sqrt{-5})(1 - \sqrt{-5})\).
            Then we have \(2\mid 6\). However, we can see that \(2\nmid (1 + \sqrt{-5})\) and \(2\nmid (1 - \sqrt{-5})\).
            Therefore, we can see that \(2\) is not a prime in \(\mathbb{Z}(-\sqrt{5})\). \(\blacksquare\)
          </p>
        <ul>
          <li>\(\textbf{Claim 2.}\) \(2\) is not a prime in \(\mathbb{Z}(\sqrt{-5})\)</li>
        </ul>
          <p>
            \(\textbf{Proof. }\) To show that \(2\) is not a prime, we only need to come up with an example.
            Firstly, we can see that \(6 = (1 + 5) = (1 + \sqrt{-5})(1 - \sqrt{-5})\).
            Then we have \(2\mid 6\). However, we can see that \(2\nmid (1 + \sqrt{-5})\) and \(2\nmid (1 - \sqrt{-5})\).
            Therefore, we can see that \(2\) is not a prime in \(\mathbb{Z}(-\sqrt{5})\). \(\blacksquare\)
          </p>
        <ul>
          <li>\(\textbf{Claim 3.}\) \(3\) is not a prime in \(\mathbb{Z}(\sqrt{-5})\)</li>
        </ul>
          <p>
            \(\textbf{Proof. }\) To show that \(3\) is not a prime, we come up with an example.
            Firstly, we can see that \(3\cdot 3 = 9 = (2 + \sqrt{-5})(2 - \sqrt{-5})\).
            Then we have \(3\mid 9\). However, we can see that \(3\nmid (2 + \sqrt{-5})\) and \(3\nmid (2 - \sqrt{-5})\).
            Therefore, we can see that \(3\) is not a prime in \(\mathbb{Z}(-\sqrt{5})\). \(\blacksquare\)
          </p>
      <ul>
          <li>\(\textbf{Claim 3.}\) \(2 + \sqrt{-5}\) is not a prime in \(\mathbb{Z}(\sqrt{-5})\)</li>
        </ul>
          <p>
            \(\textbf{Proof. }\)We prove it with contradiction. Suppose that \(2+\sqrt{-5}\) is a prime.
            We know that \(3\cdot 3 = 9 = (2 + \sqrt{-5})(2 - \sqrt{-5})\).
            Then we have \(2+\sqrt{-5}\mid 9\), which implies that \(2 + \sqrt{-5}\mid 3\).
            We know that \(3\) is irreducible in \(\mathbb{Z}(-\sqrt{5})\).
            Then \(2 + \sqrt{-5}\) is a unit, which is not true, or \(2 + \sqrt{-5}\) multiplied by a unit will be \(3\).
            There are only two units in \(\mathbb{Z}(-\sqrt{5})\), which are \(\pm 1\).
            However, \((2 + \sqrt{-5})\cdot 1 \neq 3\) and \(2 + \sqrt{-5}\cdot (-1) \neq 3\).
            It is a contradiction. Therefore, we can see that \(2 + \sqrt{-5}\) is not a prime in \(\mathbb{Z}(-\sqrt{5})\). \(\blacksquare\)
          </p>
    </section>

    <br>

    <section id = 'prime_irreducible'>
      <p>
        \(\textbf{Theorem. }\) Let \(R\) be an integral domain with identity \(1\). Then every prime element of \(R\) is irreducible.
      </p>
      <p>
        Suppose that \(p\) is a prime and \(p = ab\) for some \(a, b\in R\). Then we have \(p\mid ab\). Since \(p\) is prime, we have \(p\mid a\) or \(p\mid b\).
        Without loss of generality, we can assume that \(p\mid a\). Then we have \(a = pc\) for some \(c\in R\). Then we have
        \[
          p = a\cdot b = (pc)\cdot b = p(cb).
        \]
        Then we have \(p(1 - cb) = 0\). Since \(R\) is an integral domain, we can know that \(1 - cb = 0\), which implies that \(cb = 1\).
        Therefore, we have \(b\) is a unit. Thus, we have \(p\) is irreducible. \(\blacksquare\)
      </p>
    </section>

    <br>

    <section id = 'ascending_chain_condition'>
      <p>
        \(\textbf{Definition.}\) Given a chain of ideals \(I_1 \subset I_2 \subset \dots\), there exists \(n_0\) such that for all \(n\geq n_0\), \(I_{n_0} =I_n\).
      </p>
      <p>
        \(\textbf{Proposition.}\) The following conditions are equivalent for the commutative ring \( R \):
      </p>
      <ul>
        <li> \( R \) satisfies the ascending chain condition, i.e., given a chain of ideals \( I_1 \subseteq I_2 \subseteq \cdots \), there exists \( n_0 \) such that for all \( n \geq n_0 \), \( I_{n_0} = I_n \). </li>
        <li> \( R \) satisfies the maximal condition, i.e., any non-empty collection of ideals of \( R \) has a maximal element. </li>
        <li> Every ideal of \( R \) is finitely generated. </li>
      </ul>
    </section>

    <br>

    <section id = 'principal_ideal_domain'>
    <h2>Principal Ideal Domain</h2>
        <ul>
          <li>\(\textbf{Example 1. }\) \(\mathbb{Z}\) is a principal ideal domain.</li>
          <li>\(\textbf{Example 2. }\) All fields are principal ideal domains.</li>
          <li>\(\textbf{Example 3. }\) \(\mathbb{Z}[x]\) is a principal ideal domain.</li>
          <li>\(\textbf{Example 4. }\) Given \(F\) is a field, we have\(\mathbb{F}[x]\) is a principal ideal domain.</li>
          <li>\(\textbf{Example 5. }\) All Euclidean domains are principal ideal domains (one of the propositions below)</li>
        </ul>
      <p>
        \(\textbf{Theorem. }\) Let \(R\) be a principal ideal domain, then every prime ideal in \(R\) is maximal.
      </p>
      <p>
        \(\textbf{Proof. }\)Let \(R\) be a principal ideal domain and \((p)\) be a prime ideal in \(R\).
        Since \(R\) is a principal ideal domain, we find an ideal containing \((p)\) and assume it is \((m)\) (i.e. \((p)\subset (m)\)).
        Then we can know that \(p\in (m)\), which implies that \(p = mr\) for some \(r\in R\).
        Then we can get \(mr\in (p)\). Since \(p\) is a prime ideal, we have \(m\in (p)\) or \(r\in (p)\).
        If \(m\in (p)\), then we have \((m)\subset (p)\). Since \((p)\subset (m)\), we have \((p) = (m)\).
        If \(r\in (p)\), then we have \(r = ps\) for some \(s\in R\). Then we have \(p =mr = psm\), which implies that \(1 = sm\).
        Hence, we have \(m\) is a unit in \(R\). Thus, we have \((m) = R\).
        Therefore, we can see that \((p)\) is maximal. \(\blacksquare\)
      </p>
      <p>
        \(\textbf{Proposition. }\) Let \(R\) be a principal ideal domain. Then every irreducible element in \(R\) is prime.
      </p>
      <p>
        \(\textbf{Proof. }\) Suppose that \(p\) is irreducible in \(R\).
        If \( M \) is any ideal containing \( \langle p\rangle  \) then by hypothesis \( M = \langle m\rangle  \) is a principal ideal.
        Since \( p \in \langle m\rangle  \), \( p = rm \) for some \( r \in R\).
        Since \(p\) is irreducible, either \( r \) or \( m \) is a unit.
        If \(m\) is a unit, we have \(\langle m\rangle = R\). If \(r\) is a unit, we have \(\langle p\rangle = \langle m\rangle \).
        Thus the only ideals of \(R\) containing \( \langle p\rangle  \) are \( \langle p\rangle \) or \( R \).
        Thus, we can know that \(\langle p\rangle \) is a maximal ideal.
        Since maximal ideals are prime ideals, we know that \(p\) is prime. \(\blacksquare\)
      </p>
      <p>
        \(\textbf{Proposition. }\)Any euclidean domain is a principal ideal domain.
      </p>
      <p>
        \(\textbf{Note. }\)If \(R\) is a Euclidean Domain, it means that \(R\) has some form of division algorithm.
      </p>
      <p>
        \(\textbf{Proof. }\) Let \(I\) be an ideal in a Euclidean domain \(R\). We will show that there exists an element \(a \in I\) such that \(I = (a)\).
        Since the well ordering principle, we can choose \(a \in I\) such that \(a \neq 0\) and \(a\) has the smallest norm among all nonzero elements of \(I\). We claim that \(I = (a)\).
        Let \(x \in I\). We can write \(x = qa + r\), where \(q, r \in R\) and either \(r = 0\) or \(N(r) \lt N(a)\).
        Since \(x \in I\) and \(a \in I\), we have \(qa + r \in I\). Therefore, \(r \in I\).
        If \(r = 0\), then \(x = qa \in (a)\). If \(r \neq 0\), then \(N(r) \lt N(a)\).
        This contradicts the choice of \(a\). Therefore, \(r = 0\) and \(x = qa \in (a)\).
        Hence, every element of \(I\) can be written as a multiple of \(a\), so \(I = (a)\).
        Therefore, every ideal in a Euclidean domain is generated by a single element, and hence a Euclidean domain is a principal ideal domain. \(\blacksquare\)
      </p>
      <p>
        \(\textbf{Proposition.}\) Let \( R \) be a commutative ring.
      <ul>
          <li>An ideal \( P \subseteq R \) is a prime ideal if and only if \( R/P \) is an integral domain.</li>
          <li>An ideal \( M \subseteq R \) is a maximal ideal if and only if \( R/M \) is a field.</li>
      </ul>
    </section>


    <br>

    <section id = 'unique_factorization_domain'>
      <h2>Unique Factorization Domain</h2>
      Let \(R\) be an integral domain. Then the following are equivalent:
      <ul>
        <li>Every non-zero, non-unit of \(R\) can be written as a product of prime elements.</li>
        <li>Every non-zero, non-unit in \(R\) can be written uniquely (up to order and unit multiples) as a product of irreducible elements.</li>
      </ul>>
      <p>
        \(\textbf{Definition. }\) A unique factorization domain is an integral domain \(R\) such that every nonzero non-unit element of \(R\) can be written as a product of irreducible elements of \(R\) in a unique way up to order and units.
      </p>
      <p>
        \(\textbf{Example 1. }\) \(\mathbb{Z}\) is a unique factorization domain.
      </p>
      <p>
        \(\textbf{Example 2. }\) \(\mathbb{Z}[i]\) is a unique factorization domain.
      </p>
      <p>
        \(\textbf{Example 3. }\) \(\mathbb{Z}[\sqrt{D}]\) is a unique factorization domain.
      </p>
      <p>
        \(\textbf{Example 4. }\) \(\mathbb{Z}[x]\) is a unique factorization domain.
      </p>
      <p>
        \(\textbf{Example 5. }\) \(\mathbb{F}[x]\) is a unique factorization domain, where \(\mathbb{F}\) is a field.
      </p>
      <p>
        \(\textbf{Proposition. }\) Let \( a \) and \( b \) be two nonzero elements of the Unique Factorization Domain \( R \) and suppose
        \[
        a = up_1^{e_1} p_2^{e_2} \cdots p_n^{e_n} \quad \text{and} \quad b = vp_1^{f_1} p_2^{f_2} \cdots p_n^{f_n}
        \]
        are prime factorizations for \( a \) and \( b \), where \( u \) and \( v \) are units, the primes \( p_1, p_2, \ldots, p_n \) are distinct and the exponents \( e_i \) and \( f_i \) are \(\geq 0\). Then the element
        \[
        d = p_1^{\min(e_1, f_1)} p_2^{\min(e_2, f_2)} \cdots p_n^{\min(e_n, f_n)}
        \]
        (where \( d = 1 \) if all the exponents are 0) is the greatest common divisor of \( a \) and \( b \).
      </p>
      <p>
        \(\textbf{Remark. }\) A ring satisfying Bezout's identity is called a BÃ©zout domain.
        Not all unique factorization domains are BÃ©zout domains, but all BÃ©zout domains are unique factorization domains.
      </p>
    </section>

    <br>

    <section id = 'polynomial_ring'>
      <h2>Polynomial Ring</h2>
      <p>
        \(\textbf{Theorem. }\) Let \(F\) be a field. The polynomial ring \(F[x]\) is a \(\textit{Euclidean Domain}\).
        Specifically, if \(a(x)\) and \(b(x)\) are two polynomials in \(F[x]\) with \(b(x)\) nonzero, then there are unique \(q(x)\) and \(r(x)\) in \(F[x]\) such that
        \[
          a(x) =q(x)b(x) +r(x)\qquad \text{with}\qquad r(x) = 0 \text{ or } \deg(r(x)) \lt \deg(b(x)).
        \]
      </p>
      <p>
        \(\textbf{Theorem. }\) Let \(F\) be a field and \( f \in F[x_1, \ldots, x_n] \) be non-constant.
        Then we say that \(F[X_1, \ldots, x_n]\) is a Unique Factorization Domain.
        Specifically, there are irreducible polynomials \( g_1, \ldots, g_r \in F[x_1, \ldots, x_n] \) such that
        \[
          f = g_1 \cdots g_r.
        \]
        Furthermore, if there is a second factorization of \( f \) into irreducible polynomials
        \[
          f = h_1 \cdots h_s,
        \]
        then \( r = s \) and the \( h_i \)'s can be permuted so that each \( h_i \) is a constant multiple of \( g_i \).
      </p>
      <p>
        \(\textbf{Theorem. }\) Let \(F\) be a field and \( f, g \in F[x] \). Assume that \( g \) is nonzero.
        Then there are polynomials \( q, r \in F[x] \) such that
        \[
          f = qg + r, \quad \text{where } r = 0 \text{ or } \deg(r) \lt \deg(g).
        \]
        Furthermore, \( q \) and \( r \) are unique.
      </p>
      <p>
        \(\textbf{Corollary. }\)Let \(F\) be a field. We have \( \alpha \in F \) is a root of a polynomial \( f \in F[x] \) if and only if \( x - \alpha \) is a factor of \( f \) in \( F[x] \)
      </p>
      <p>
        \(\textbf{Definition. }\)To say that a field \( L \) contains \(\textit{all}\) roots of \( f \) means that \( f \) factors as
        \[
          f = a_0(x - \alpha_1) \cdots (x - \alpha_n),
        \]
        where \( \alpha_1, \ldots, \alpha_n \in L \). When this happens, we say that \( f \) splits completely over \( L \).
      </p>
      <p>
        \(\textbf{Theorem. }\) If \( F \) is a field and \( f \in F[x] \) is non-constant, then the following are equivalent:
      </p>
        <ul>
          <li>
            The polynomial \( f \) is irreducible over \( F \).
          </li>
          <li>
            The ideal \( (f) = \{ fg \mid g \in F[x] \} \) is a maximal ideal.
          </li>
          <li>
            The quotient ring \( F[x] / (f) \) is a field.
          </li>
        </ul>
      <p>
        \(\textbf{Definition (Primitive). }\) A polynomial \( f \in F[x] \) is \textit{primitive} if the greatest common divisor of its coefficients is \(1\).
        (i.e. for all prime elements \(p \in R\), \(p \not\mid f(x)\) in \(R[x]\)).
      <p>
        \(\textbf{Proposition.}\) Every nonzero ideal of \(F[x]\) can be written uniquely as \((f)\) where
        \(f\) is monic.
      </p>
      <p>
        \(\textbf{Proposition A. }\)For a UFD \(R\), if \(p \in R\) is a prime element, then \(p\) is also a prime element in \(R[x]\).
      </p>
      <p>
        \(\textbf{Gauss's lemma.}\) Let \(R\) be a UFD. Then the product of primitive polynomials is primitive.
      </p>
      <p>
        \(\textbf{Proposition B. }\)Suppose \(R\) is a UFD with quotient field \(K\) and \(f(x) \in R[x]\) is primitive. Then \(f(x)\) is irreducible in \(R[x]\) if and only if it is irreducible in \(K[x]\).
      </p>
      <p>
        \(\textbf{Proposition C. }\)Suppose \(R\) is a UFD and \(f(x) \in R[x]\) is primitive and irreducible. Then \(f(x)\) is a prime element.
      </p>
      <p>
        <b>Theorem.</b> Let \( f, g \in F[x] \), and assume that \( g \) is nonzero. Then there are polynomials \( q, r \in F[x] \) such that
        \[ f = qg + r, \]
        where \( r = 0 \) or \( \deg(r) < \deg(g) \).

        Furthermore, \( q \) and \( r \) are unique.
      </p>
      <p>
        <b><i>"Galois Theory", Second Edition, David A. Cox, Page 522</i></b>
      </p>
      <p>
        <b>Corollary.</b> Let \( f \in F[x] \) be non-constant. Then \( f \) has at most \(\deg(f)\) roots in the field \( F \).
      </p>
      <p>
        <b><i>"Galois Theory", Second Edition, David A. Cox, Page 522</i></b>
      </p>
    </section>

    <br>

    <section id = 'division_algorithm_sagemath'>
      <h2>Do Division Algorithm in SageMath</h2>
      <p>

      </p>
      <div class="code-box-container">
        <div class="code-box">
      <pre><code>
      <span class = 'keyword'>sage:</span> <span class = 'comment'># Define the polynomial ring over QQ</span>
      <span class = 'keyword'>sage:</span> R.<<span class = 'variable'>x</span>> = QQ['x']
      <span class = 'keyword'>sage:</span>
      <span class = 'keyword'>sage:</span> <span class = 'comment'># Define the polynomials</span>
      <span class = 'keyword'>sage:</span> f = x^<span class = 'number'>3</span> + <span class = 'number'>2</span>*x^<span class = 'number'>2</span> + <span class = 'number'>3</span>* + <span class = 'number'>4</span>
      <span class = 'keyword'>sage:</span> g = x + <span class = 'number'>1</span>
      <span class = 'keyword'>sage:</span>
      <span class = 'keyword'>sage:</span> <span class = 'comment'># Perform the division to get quotient and remainder</span>
      <span class = 'keyword'>sage:</span> quotient, remainder = f.quo_rem(g)
      <span class = 'keyword'>sage:</span>
      <span class = 'keyword'>sage:</span> <span class = 'comment'># Display the results</span>
      <span class = 'keyword'>sage:</span> <span class = 'function'>print</span>("Quotient:", quotient)
      <span class = 'outcome'>Quotient: x^2 + x + 2</span>
      <span class = 'keyword'>sage:</span> <span class = 'function'>print</span>("Remainder:", remainder)
      <span class = 'outcome'>Remainder: 2</span>
      </code></pre>
        </div>
      </div>
    </section>

    <br>

    <section id = 'adjoining_element'>
      <h2>Adjoining Element</h2>
      <p>
        \(\textbf{Definition.}\) The \(\textit{polynomial ring}\) in the variables \( x_1, x_2, \ldots, x_n \) with coefficients in \( R \), denoted \( R[x_1, x_2, \ldots, x_n] \), is defined inductively by
        \[
          R[x_1, x_2, \ldots, x_n] = R[x_1, x_2, \ldots, x_{n-1}][x_n].
        \]
      </p>
      <p>
        \(\textbf{Adjoining Elements.}\) We next show how to describe some interesting subrings and subfields of a given extension \( F \subset L \).
        Given \( \alpha_1, \ldots, \alpha_n \in L \), we define
        \[
          F[\alpha_1, \ldots, \alpha_n] = \{ h(\alpha_1, \ldots, \alpha_n) \mid h \in F[x_1, \ldots, x_n] \}.
        \]
        Hence \( F[\alpha_1, \ldots, \alpha_n] \) consists of all polynomial expressions in \( L \) that can be formed using \( \alpha_1, \ldots, \alpha_n \) with coefficients in \( F \).
      </p>
      <p>
        \(\textbf{Note. }\)Keep in mind that \(F[\alpha_1, \ldots, \alpha_n]\) is a ring, not necessarily a field.
      </p>
      <p>
        For example let Let \(F = \mathbb{Q}\) and \(\mathbb{Q}[\sqrt{2}+\sqrt{3}]\) is not a field.
        We know that \(1 + \sqrt{2} + \sqrt{3}\in \mathbb{Q}[\sqrt{2}+\sqrt{3}]\). However, we can see that
        \(\frac{1}{1 + \sqrt{2} + \sqrt{3}}\) is not in \(\mathbb{Q}[\sqrt{2}+\sqrt{3}]\).
      </p>
        <p>
        Let
        \[
          F(\alpha_1, \ldots, \alpha_n) = \left\{ \frac{\alpha}{\beta} \mid \alpha, \beta \in F[\alpha_1, \ldots, \alpha_n], \beta \neq 0 \right\}.
        \]
        Thus \( F(\alpha_1, \ldots, \alpha_n) \) is the set of all rational expressions in the \( \alpha_i \) with coefficients in \( F \).
      </p>
      <p>
        \(\textbf{Lemma. }\)\( F(\alpha_1, \ldots, \alpha_n) \) is the smallest subfield of the field \( L \) containing \( F \) and \( \alpha_1, \ldots, \alpha_n \).
      </p>
      <p>
        \(\textbf{Proof. }\) Let \(L\) be a field containing \(F\) and \(\alpha_1, \ldots, \alpha_n\).
        Firstly, we show that \( F(\alpha_1, \ldots, \alpha_n) \) is a subfield of \( L \).
        Thus, to prove the lemma, we must show that if \( K \) is a subfield of \( L \) containing \( F \) and \( \alpha_1, \ldots, \alpha_n \), then \( F(\alpha_1, \ldots, \alpha_n) \subseteq K \).
        This is what "smallest" means in the statement of the lemma.
        Suppose that \( K \subseteq L \) contains \( F \) and \( \alpha_1, \ldots, \alpha_n \).
        Since \( K \) is closed under multiplication and addition, it follows that \( p(\alpha_1, \ldots, \alpha_n) \in K \) for any polynomial \( p \in F[x_1, \ldots, x_n] \).
        This shows that \( F[\alpha_1, \ldots, \alpha_n] \subseteq K \). Then \( F(\alpha_1, \ldots, \alpha_n) \subseteq K \) follows immediately, since \( K \) is a field.
        Since \( F(\alpha_1, \ldots, \alpha_n) \) is a subfield of \( L \) containing \( F \), we get extensions
        \[
          F \subseteq F(\alpha_1, \ldots, \alpha_n) \subseteq L.
        \]
        We say that \( F(\alpha_1, \ldots, \alpha_n) \) is obtained from \( F \) by adjoining \( \alpha_1, \ldots, \alpha_n \in L \).
      </p>
  </section>

    <br>

    <section id = 'construction_field'>
      <h2>Construction of Fields</h2>
      <p>
        <b>Theorem.</b> For a prime \( p \) and a monic irreducible \( \pi(x) \) in \( \mathbb{F}_p[x] \) of degree \( n \), the ring \( \mathbb{F}_p[x]/(\pi(x)) \) is a field of order \( p^n \).
      </p>
      <p>
        <b>Proof.</b> The cosets mod \( \pi(x) \) are represented by remainders
        \[ c_0 + c_1 x + \cdots + c_{n-1} x^{n-1}, \quad c_i \in \mathbb{F}_p, \]
        and there are \( p^n \) of these. Since the modulus \( \pi(x) \) is irreducible, the ring \( \mathbb{F}_p[x]/(\pi(x)) \) is a field using the same proof that \( \mathbb{Z}/(m) \) is a field when \( m \) is prime. \(\blacksquare\)
      </p>
      <p>
        <a href="https://kconrad.math.uconn.edu/blurbs/galoistheory/finitefields.pdf"><b><i>"FINITE FIELDS", Keith Conrad</i></b></a>
      </p>
    </section>

    <section id = 'splitting_field'>
      <h2>Splitting Field</h2>
      <p>
        \(\textbf{Definition 5.1.1}\) Let \( f \in F[x] \) have degree \( n > 0 \). Then an extension \( F \subset L \) is a splitting field of \( f \) over \( F \) if
      </p>
        <ul>
          <li>
            \( f = c(x - \alpha_1) \cdots (x - \alpha_n) \), where \( c \in F \) and \( \alpha_i \in L \), and
          </li>
          <li>
            \( L = F(\alpha_1, \ldots, \alpha_n) \).
          </li>
        </ul>
      <p>
        \textbf{Definition.} Let \( K \) be a field and let \( f(x) \) be a polynomial in \( K[x] \). We say that \( f(x) \) \textit{splits} in \( K \) if there are elements \( \alpha_1, \alpha_2, \ldots, \alpha_n \) of \( K \) such that
        \[
        f(x) = \lambda(x - \alpha_1)(x - \alpha_2)\ldots(x - \alpha_n).
        \]
        We say that a field extension \( L/K \) is a \textit{splitting field} if \( f(x) \) splits in \( L \) and there is no proper intermediary subfield \( M \) in which \( f(x) \) splits.
      </p>
      <p>
        \(\textbf{Definition. }\) For a finite extension of fields \( F \subseteq K \), \( \alpha \in K \) is a \(\textit{primitive element}\) if \( K = F(\alpha) \).
      </p>
      <p>
        \(\textbf{Primitive Element Theorem. }\) Suppose \( F \subseteq K \) is an extension of fields satisfying \( [K : F] \lt \infty \). If \( \mathbb{Q} \subseteq F \), then there exists a primitive element \( \alpha \in K \) such that \( K = F(\alpha) \).
      </p>
      <p>
        \(\textbf{Proposition. }\) Let \( 0 \neq f(x) \in F[x] \) be a non-constant polynomial. The following are equivalent:
      </p>
        <ul>
          <li>
            \(\text{GCD}(f(x), f'(x)) = 1\)
          </li>
          <li>
            \( f(x) \) and \( f'(x) \) have no root in common (say, in the splitting field of \( f(x) \) over \( F \)).
          </li>
          <li>
            \( f(x) \) has distinct roots in its splitting field over \( F \).
          </li>
        </ul>
      <p>
        \(\textbf{Corollary. }\) If \( F \) is a field containing \( \mathbb{Q} \) and \( p(x) \in F[x] \) is irreducible, then \( p(x) \) has distinct roots in \( K \), the splitting of \( p(x) \) over \( F \).
      </p>
    </section>

    <br>


    <section id='minimal_polynomial'>
      <h2>Minimal Polynomial</h2>
      <p>
        \(\textbf{Proposition.}\) Let \(\alpha \in L\) be algebraic over \(F\), and let \(p \in F[x]\) be its minimal polynomial. If \(f \in F[x]\) is a non-constant monic polynomial, then
          \[
            f = p \Leftrightarrow f \text{ is a polynomial of minimal degree satisfying } f(\alpha) = 0 \Leftrightarrow f \text{ is irreducible over } F \text{ and } f(\alpha) = 0.
          \]
      </p>
      <p>
        Let us briefly talk about how to use SageMath to find the minimal polynomial of an element. Suppose that your \(\alpha = \sqrt{2}\).
      </p>
      <div class="code-box-container">
      <div class="code-box">
      <pre><code>
      <span class="keyword">sage:</span> <span class="function">var</span>(<span class="string">'a'</span>)
      <span class="keyword">sage:</span> a <span class="operator">=</span> <span class="function">sqrt</span><span class="group">(</span><span class="number">2</span><span class="group">)</span>; a
      <span class="outcome">sqrt(2)</span>
      <span class="keyword">sage:</span> p <span class="operator">=</span> a.minpoly<span class="group">()</span>; p
      <span class="outcome">x^2 - 2</span>
    </code></pre>
      </div>
      </div>
    </section>

    <br>

    <section id='field_extension'>
      <h2>Field Extension</h2>
      <p>
        <b>Proposition.</b> A splitting field of a polynomial of degree \( n \) over \( F \) is of degree at most \( n! \) over \( F \).
      </p>
      <p>
        <i><b>"Abstract Algebra", Page 538</b></i>
      </p>
      <p>
        \(\textbf{Definition. }\) Suppose that \(F\subset K\) and \([K: F]\lt\infty\). We say that \(\alpha\in K\) is a \(\textit{primitive element}\) for \(F\subset K\) if \(K = F(\alpha)\).
      </p>
      <p>
        \(\textbf{Lemma. }\) An extension \(F \subset L\) has degree \([L: F] = 1\) if and only if \(F = L\).
      </p>
      <p>
        \(\textbf{Proposition. }\) Let \(F \subset K\) and \([K: F]\lt\infty, |F| = \infty\).
        Then there exists a primitive element for \(F\subset K\) if and only if there are only finitely many intermediate fields between \(F\) and \(K\).
      </p>
      <p>
        \(\textbf{Corollary. }\) Suppose that \(\mathbb{Q}\subset F\) and \([K: F]\lt\infty\).
        Then there are only finitely many intermediate fields between \(F\) and \(K\).
      </p>
      <p>
        \(\textbf{Proposition.}\) Suppose that \([K: F]\lt\infty\). Then every \(\alpha \in K\) is algebraic over \(F\).
      </p>
      <p>
        \(\textbf{Theorem.}\) Suppose that \(F\subset E\subset K\), and \(E\) is algebraic over \(F\) and \(K\) is algebraic over \(E\).
        Then \(K\) is algebraic over \(F\).
      </p>
      <p>
        \(\textbf{Lemma.}\)
        Assume that \(F \subset L\) is a field extension, and let \(\alpha \in L\) be algebraic over \(F\) with minimal polynomial \(p \in F[x]\). Then there is a unique ring isomorphism
        \[
          F[\alpha] \cong F[x]/(p)
        \]
        that is the identity on \(F\) and maps \(\alpha\) to the coset \(x + (p)\).
      </p>
      <p>
      \(\textbf{Proposition.}\)
        Assume that \(F \subset L\) is a field extension, and let \(\alpha \in L\). Then \(\alpha\) is algebraic over \(F\) if and only if \(F[\alpha] = F(\alpha)\).
      </p>
      <p>
        \(\textbf{Theorem.}\) Let \( F \subseteq K \) be fields such that \( K \) is the splitting field of \( f(x) \) over \( F \). If the irreducible polynomial \( p(x) \in F[x] \) has a root in \( K \), then it splits over \( K \).
      </p>
      <p>
        \(\textbf{Crucial Proposition. }\) Let \( F_1 \subseteq K_1 \), \( F_2 \subseteq K_2 \) be fields, \( p_1(x) \in F_1[x] \), \( p_2(x) \in F_2[x] \) be monic irreducible polynomials of degree \( d \), and \( \alpha_1 \in K_1 \), \( \alpha_2 \in K_2 \) roots of \( p_1(x) \) and \( p_2(x) \), respectively. Suppose \( \sigma : F_1 \to F_2 \) is an isomorphism such that \( p_2(x) = p_1(x)^\sigma \). Then there exists an isomorphism \( \tilde{\sigma} : F_1(\alpha_1) \to F_2(\alpha_2) \) extending \( \sigma \) such that \( \tilde{\sigma}(\alpha_1) = \alpha_2 \).
        We noted that in the proposition, \( p_1(x)^\sigma \) denotes the polynomial in \( F_2[x] \) obtained by applying \( \sigma \) to the coefficients of \( p_1(x) \).
      </p>
    </section>

    <br>

    <section id = 'separable'>
      <h2>Separable</h2>
      <p>
        \(\textbf{Definition. }\)A polynomial \(f\in F [x]\) is separable if it is non-constant and its roots
        in a splitting field are all simple.
      </p>
      <p>
        \(\textbf{Theorem. }\)A nonzero polynomial in \(K[X]\) is separable if and only if it is relatively
        prime to its derivative in \(K[X]\).
      </p>
      <p>
        \(\textbf{Proof. }\)We firstly show that if a nonzero polynomial in \(K[X]\) is separable, then it is relatively prime to its derivative in \(K[X]\).
        Suppose that \(f(x)\in K[X]\) is separable, then we have \(f(x) = (x - \alpha)h(x)\) for some \(\alpha\) in the extension of \(K\).
        Note that \((x - \alpha)\) is the distinct factor of \(f\) because of the definition of separable.
        In other words, \(h(\alpha)\neq 0\).
        Then we have
        \[
        \begin{align}
          f'(x) &= h(x) + (x - \alpha)h'(x). \\
          f'(\alpha) &= h(\alpha) + (\alpha - \alpha)h'(\alpha) = h(\alpha) \neq 0. \\
        \end{align}
        \]
        In that case, we can know that \(f\) and \(f'\) do not share the same root, which implies that
        they do not have the same factor. Hence, we have \(f\) and \(f'\) are relatively prime.
        For the other direction, we will prove it with contrapositive.
        Suppose that \(f(x)\) is not separable, given the definition of separable, we can know that \(f(x)\) has a repeated roots.
        Then we have \(f(x) = (x - \alpha)^2h(x)\) for some \(\alpha\) in the extension of \(K\).
        Hence, we can get
        \[
        \begin{align}
          f'(x) &= 2(x - \alpha)h(x) + (x - \alpha)^2h'(x)\\
          f'(\alpha) &= 2(\alpha - \alpha)h(\alpha) + (\alpha - \alpha)^2h'(\alpha) = 0. \\
        \end{align}
        \]
        Therefore, we can know that \(f\) and \(f'\) have some similar factor. Hence, we have \(f\) and \(f'\) are not relatively prime. \(\blacksquare\)
      </p>
    </section>

    <br>

    <section id = 'algebraic_closure'>
      <h2>Algebraic Closure</h2>
      <p>
        \(\textbf{Definition.}\) Let \(F\) be a field and \(K\) be a subfield of \(F\). An element \(\alpha \in F\) is said to be \(\textbf{algebraic over}\) \(K\) if there exists a non-zero polynomial \(f(x) \in K[x]\) such that \(f(\alpha) = 0\). In other words, \(\alpha\) is a root of a non-zero polynomial with coefficients in \(K\).
      </p>
      <p>
        \(\textbf{Definition.}\) An \(\textbf{algebraic extension}\) \(L\) of a field \(K\) is a field extension such that every element of \(L\) is algebraic over \(K\). In other words, if \(L\) is an algebraic extension of \(K\), then for every \(\alpha \in L\), there exists a non-zero polynomial \(f(x) \in K[x]\) such that \(f(\alpha) = 0\).
      </p>
      <p>
        \(\textbf{Definition.}\) A field \(\mathbb{F}\) is algebraically closed if every non-constant polynomial in \(\mathbb{F}[x]\) has a root in \(\mathbb{F}\).
      </p>
      <p>
        \(\textbf{Definition.}\) Let \(F\) be a field. The set of all elements in \(F\) that are algebraic over \(K\) is denoted by \(\overline{K}\) and is called the \(\textbf{algebraic closure}\) of \(K\) in \(F\).
      </p>
      <p>
        \(\textbf{Alternate Definition.}\) An algebraic closure of a field \(F\) is an algebraic extension \(K\) of \(F\) such that every polynomial in \(F[x]\) splits in \(K\).
      </p>
      <p>
        \(\textbf{Theorem.}\) Let \( F \) be a field, then there exists an algebraic closure for \( F \), i.e., a field \( \overline{F} \subseteq F \) such that \( \overline{F} \) is algebraically closed and algebraic over \( F \).
      </p>
    </section>

    <br>

    <section id = 'galois_theory'>
      <h2>Galois Theory</h2>
      <p>
        \(\textbf{Proposition. }\) Let \( F \subset L \) be a finite extension and let \( \sigma \in \text{Gal}(L/F) \). Then:
      </p>
        <ul>
          <li>If \(h \in F[x]\) is a non-constant polynomial with \( \alpha \in L \) as a root, then \( \sigma(\alpha) \) is also a root of \( h \) lying in \( L \).</li>
          <li>If \(L = F(\alpha_1, \ldots, \alpha_n)\), then \( \sigma \) is uniquely determined by its values on \( \alpha_1, \ldots, \alpha_n \).</li>
        </ul>
    </section>

    <br>

    <section id = 'galois_group'>
      <h2>Galois Group</h2>
      <p>
        <b>Definition.</b> Let \( F \subseteq L \) be a finite extension. Then \( \text{Gal}(L/F) \) is the set
        \[ \{\sigma: L \rightarrow L \mid \sigma \text{ is an automorphism, } \sigma(a) = a \text{ for all } a \in F\}. \]
        In other words, \( \text{Gal}(L/F) \) consists of all automorphisms of \( L \) that are the identity on \( F \). The basic structure of \( \text{Gal}(L/F) \) is as follows.
      </p>
      <p>
        <b>Definition.</b> Let \( K / F \) be a finite extension. Then \( K \) is said to be Galois over \( F \) and \( K / F \) is a Galois extension if \( | \text{Aut}(K / F) | = [K : F] \). If \( K / F \) is Galois the group of automorphisms \( \text{Aut}(K / F) \) is called the Galois group of \( K / F \), denoted \( \text{Gal}(K / F) \).
      </p>
      <p>
        <b>Corollary.</b> If \( K \) is the splitting field over \( F \) of a separable polynomial \( f(x) \) then \( K / F \) is Galois.
      </p>
      <p>
        <i><b>"Abstract Algebra", Page 562</b></i>
      </p>
      <p>
        <b>Definition.</b> If \( f(x) \) is a separable polynomial over \( F \), then the Galois group of \( f(x) \) over \( F \) is the Galois group of the splitting field of \( f(x) \) over \( F \).
      </p>
      <p>
        <i><b>"Abstract Algebra", Page 563</b></i>
      </p>
      <p>
      \(\textbf{Theorem. }\) If \( L \) is the splitting field of a separable polynomial in \( F[x] \), then the Galois group of \( f \) over \( F \) has order \( \left| \text{Gal}(L/F) \right| = [L : F] \).
      </p>
      <p>
        \(\textbf{Proposition. }\) Let \( F \subseteq L \) be a finite extension. Then \( \text{Gal}(L/F) \) is a group under composition of functions.
      </p>
      <p>
        \(\textbf{Proof.}\) We need to check the following properties:
      </p>
        <ul>
          <li>
            \( \text{Gal}(L/F) \) is closed under composition of functions.
          </li>
          <li>
            Suppose that \(\sigma\) and \(\delta\) are in \( \text{Gal}(L/F) \).
            Then we have \(\sigma(\delta(a)) = \sigma(a) = a\) for all \(a\in F\).
          </li>
        </ul>
      <p>We firstly show that \( \text{Gal}(L/F) \) is closed under composition of functions.</p>
      <div class="code-box-container">
      <div class="code-box">
      <pre><code>
        <span class="keyword">sage:</span> R.<span class="operator">&lt;</span>x<span class="operator">&gt;</span> <span class="operator">=</span> QQ[]

        <span class="keyword">sage:</span> K.<span class="operator">&lt;</span>a<span class="operator">></span> <span class="operator">=</span> <span class="function">NumberField</span><span class="group">(</span>x<span class="operator">^</span><span class="number">3</span> <span class="operator">+</span> x<span class="operator">^</span><span class="number">2</span> <span class="operator">+</span> <span class="number">2</span><span class="group">)</span>

        <span class="keyword">sage:</span> G <span class="operator">=</span> K.galois_group<span class="group">()</span>; G
        <span class="outcome">Galois group 3T2 (S3) with order 6 of x^3 + x^2 + 2</span>

        <span class="keyword">sage:</span> G.easy_order<span class="group">()</span>
        <span class="outcome">6</span>

        <span class="keyword">sage:</span> G.list<span class="group">()</span>
        <span class="outcome">[(),
        (1,2,3)(4,5,6),
        (1,3,2)(4,6,5),
        (1,4)(2,6)(3,5),
        (1,5)(2,4)(3,6),
        (1,6)(2,5)(3,4)]</span>
        </code></pre>
      </div>
      </div>
    </section>

    <br>

    <h2 id = 'january_2015'>KU 2015 (January)</h2>
    <section id = 'ku_2015_1_1'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>1.</b> Let \( G \) be a finite abelian group of odd order. Prove that for each \( x \in G \), there exists a unique \( y \in G \), such that \( y^2 = x \).
          </p>
        </div>
        </div>
      <p>
        <b>Proof.</b> Let \(\varphi: G\to G\) such that \(g\mapsto g^2\) for all \(g\in G\).
        Firstly, we want to show that \(\varphi\) is well-defined. Suppose that \(g = h\) for some \(g, h\in G\), then we have \(g^2 = h^2\).
        Then, we want to show that \(\varphi\) is a group homomorphism.
        For any \(g, h\in G\), we have \(\varphi(gh) = (gh)^2 = g^2h^2 = \varphi(g)\varphi(h)\) since \(G\) is abelian.
        Now, we want to show that \(\varphi\) is injective.
        Suppose that \(\varphi(g) = \varphi(h)\) for some \(g, h\in G\), then we have \(g^2 = h^2\).
        Hence, we can have \(g^2h^{-2} = (gh^{-1})^2 = e\). Given that \(G\) is group of odd order. Hence, we can know that there does not exist any element of even order in \(G\).
        If \(gh^{-1}\) is an non identity element of \(G\), then we can say that \(gh^{-1}\) has order of \(2\), which is a contradiction.
        Hence, we have \(gh^{-1} = e\), which implies that \(g = h\). Thus, we showed that \(\varphi\) is injective.
        Given that \(\varphi: G\to G\) and \(G\) has finite order, according to \(\textbf{Pigeon Hole Principle}\), we can know that \(\varphi\) is surjective.
        Thus, we can have for any \(x\in G\), there exists a unique \(y\in G\) such that \(y^2 = x\). \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2015_1_2'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
              <p>
                <b>2.</b>Prove that a group of order \(435=3\cdot 5\cdot 29\) must be abelian.
              </p>
            </div>
        </div>
      <p>
        <b>Proof.</b> Given that \(435 = 3\cdot 5\cdot 29\), we can know that there exists a sylow 3-subgroup \(G\), sylow 5-subgroup \(H\), and sylow 29-subgroup \(K\).
        And the sylow 3-subgroup has order of \(3\), which is a prime. Hence, we can know that the sylow 3-subgroup is cyclic and isomorphic to \( \mathbb{Z}/3\mathbb{Z} \).
        For the similar reason, we can have the sylow 5-subgroup is cyclic and isomorphic to \( \mathbb{Z}/5\mathbb{Z} \) and the sylow 29-subgroup is cyclic and isomorphic to \( \mathbb{Z}/29\mathbb{Z} \).
        Suppose that \(g\neq e\in G\cap H\), then we can know that \(g\) has order either \(3\) or \(5\), but cannot be both. Thus, we can know that \(G\cap H = \{e\}\).
        For the similar reason, we can have \(H\cap K = \{e\}\) and \(G\cap K = \{e\}\).
        Now, according to the \(\textbf{Third Sylow's Theorem}\), we can know that the number of sylow 3-subgroup, sylow 5-subgroup, and sylow 29-subgroup are \(3a + 1\), \(5b + 1\), \(29c + 1\) for some \(a, b, c\in \mathbb{Z}\).
        Moreover, we have \(3a + 1 \mid 435\), \(5b + 1 \mid 435\), and \(29c + 1 \mid 435\). Hence, we can conclude that \(a = b = c = 0\).
        And the number of the sylow 3-subgroup, sylow 5-subgroup, and sylow 29-subgroup are \(1\), \(1\), and \(1\), respectively.
        For any \(g\) in our original group, we can know that \(gGg^{-1}\) is a group of order \(3\) and there is only one subgroup of order \(3\), which is \(G\). Hence, we can know that \(gGg^{-1} = G\), which implies that \(G\) is normal in our original group.
        Similarly, we can know that \(H\) and \(K\) are normal in our original group. The inner direct product of two normal subgroups are normal. Hence, we can know that \(G H\) is normal in our original group.
        Besides that, we can have
        \[
        \begin{align}
        |GH| = \frac{|G||H|}{|G\cap H|} = 15,
        |GHK| = \frac{|GH||K|}{|GH\cap K|} = 435.
        \end{align}
        \]
        Thus, we know that our original group is \(GHK\).
        Since we know that both \(G\) and \(H\) are normal and \(G\cap H = \{e\}\), we can know that \(GH = G\times H\).
        Since \(GH\) and \(K\) are normal, and \(GH\cap K = \{e\}\), we can know that \(GHK = GH\times K\).
        Thus, we can know that \(GHK = G\times H\times K = \mathbb{Z}/3\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/29\mathbb{Z}\).
        Since \(\mathbb{Z}/3\mathbb{Z}\times \mathbb{Z}/5\mathbb{Z}\times \mathbb{Z}/29\mathbb{Z}\) is abelian, we can know that our original group is abelian. \(\blacksquare\)
      </p>
    </section>

    <section id = ;ku_2015_1_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
            <b>3.</b> Let \( k = \mathbb{Z}/2\mathbb{Z} \) and set \( R := k[X, Y] \), the polynomial ring in two variables over \( k \). Let \( I \subseteq R \) be a proper ideal.
        </p>
        <p>
            (i) Explain why \( R/I \) is a vector space over \( k \).
        </p>
        <p>
            (ii) Let \( q \) be a fixed power of two and suppose that \( f_1, \ldots, f_n \) is a set of generators for \( I \). Set \( I^{[q]} \) to be the ideal generated by \( f_1^q, \ldots, f_n^q \). Prove that \( I^{[q]} \) is an ideal of \( R \) that does not depend upon the set of generators chosen.
        </p>
        <p>
            (iii) Compute the dimension of \( R/I^{[q]} \) as a vector space over \( k \).
        </p>
        </div>
      </div>
      <p>
          <b>Proof (i).</b> Given that \(I\) is a proper ideal, we can know that \(1\notin I\).
          Hence, we have \(1 + I\in R/I\), which implies that the multiplicative identity exists in \(R/I\).
          And it is not hard to see that \(0 + I = I\in R/I\), which implies that the additive identity exists in \(R/I\).
      </p>
    </section>

    <section id = 'ku_2015_1_4'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>4.</b> Find the minimal polynomial of \( \sqrt{2} + \sqrt[3]{2} \) over \( \mathbb{Q} \).
          </p>
        </div>
        </div>
      <p>
        <b>Solution.</b> Let \( \alpha = \sqrt{2} + \sqrt[3]{2} \). Then we have
        \[
        \begin{align}
        \alpha - \sqrt{2} &= \sqrt[3]{2} \\
        (\alpha - \sqrt{2})^3 &= 2 \\
        \alpha^3 - 3\alpha^2\sqrt{2} + 6\alpha - 2\sqrt{2} &= 2 \\
        -3\alpha^2\sqrt{2} - 2\sqrt{2} &= 2 - \alpha^3 - 6\alpha \\
        \sqrt{2}(-3\alpha^2 - 2) &= 2 - \alpha^3 - 6\alpha \\
        \sqrt{2} &= \frac{2 - \alpha^3 - 6\alpha}{-3\alpha^2 - 2} \\
        &= \frac{\alpha^3 + 6\alpha - 2}{3\alpha^2 + 2}.
        \end{align}
        \]
        Hence, we can know that \( \sqrt{2} \) is in the field \( \mathbb{Q}(\alpha) \).
        And we have \(\mathbb{Q}(\sqrt{2}) \subset \mathbb{Q}(\alpha)\).
        Since \(\mathbb{Q}(\sqrt{2})\subset \mathbb{Q}(\sqrt{2}, \sqrt{3})\).
        Given that \(\sqrt{2} + \sqrt[3]{2}\) is in the field \(\mathbb{Q}(\sqrt{2}, \sqrt[3]{2})\), we can know that \(\mathbb{Q}(\sqrt{2} + \sqrt[3]{2}) \subset \mathbb{Q}(\sqrt{2}, \sqrt[3]{2})\).
        Since \(\sqrt{2}\in \mathbb{Q}(\sqrt{2} + \sqrt[3]{2})\), we can know that \(\sqrt[3]{2} = (\sqrt{2} + \sqrt[3]{2}) - \sqrt{2}\) is in the field \(\mathbb{Q}(\sqrt{2} + \sqrt[3]{2})\).
        Thus, we have \(\mathbb{Q}(\sqrt{2}, \sqrt[3]{2}) \subset \mathbb{Q}(\sqrt{2} + \sqrt[3]{2})\).
        Therefore, we can know that \(\mathbb{Q}(\sqrt{2} + \sqrt[3]{2}) = \mathbb{Q}(\sqrt{2}, \sqrt[3]{2})\).
        We know \([\mathbb{Q}(\sqrt{2}): \mathbb{Q}] = 2\) since \(x^2 - 2\) is an irreducible polynomial over \(\mathbb{Q}\) and \(\sqrt{2}\) is a root of \(x^2 - 2\) (i.e \(x^2 - 2\) is the minimal polynomial of \(\sqrt{2}\) over \(\mathbb{Q}\)).
        And \(\sqrt[3]{2}\notin \mathbb{Q}(\sqrt{2})\) since there is no \(a, b\in \mathbb{Q}\) such that \(a + b\sqrt{2} = \sqrt[3]{2}\).
        Let \(f(x)= x^3 - 2\) and we want to show that \(f(x)\) is irreducible over \(\mathbb{Q}(\sqrt{2})\) by contradiction.
        Suppose that \(f(x)\) is reducible over \(\mathbb{Q}(\sqrt{2})\), then we can have \(f(x) = (x + a)(x^2 + bx + c)\) for some \(a, b, c\in \mathbb{Q}(\sqrt{2})\).
        Hence, \(f(x)\) has a root in \( \mathbb{Q}(\sqrt{2}) \). We know that \(\sqrt[3]{2}\) is a root of \(f(x)\) but \(\sqrt[3]{2}\notin \mathbb{Q}(\sqrt{2})\).
        And \(f(x)\) has two other roots in \(\mathbb{C}\), which is a contradiction. Hence, we have \(f(x)\) is irreducible over \(\mathbb{Q}(\sqrt{2})\).
        Thus, we can know that
        \[
        \mathbb{Q}(\sqrt{2})[x]/(x^3 - 2) \cong \mathbb{Q}(\sqrt{2})[\sqrt[3]{2}].
        \]
        Since \(\sqrt[3]{2}\) is algebraic over \(\mathbb{Q}(\sqrt{2})\), we have \( \mathbb{Q}(\sqrt{2})[\sqrt[3]{2}] = \mathbb{Q}(\sqrt{2})(\sqrt[3]{2}) = \mathbb{Q}(\sqrt{2}, \sqrt[3]{2}) = \mathbb{Q}(\sqrt{2} + \sqrt[3]{2})\).
        Given that \(x^3 - 2\) is the minimal polynomial of \(\sqrt[3]{2}\) over \(\mathbb{Q}(\sqrt{2})\), we can conclude that \([\mathbb{Q}(\sqrt{2}, \sqrt[3]{2}): \mathbb{Q}(\sqrt{2})] = 3\).
        Then, we have
        \[
        \begin{align}
        [\mathbb{Q}(\sqrt{2} + \sqrt[3]{2}): \mathbb{Q}] &= [\mathbb{Q}(\sqrt{2}, \sqrt[3]{2}): \mathbb{Q}] \\
        &=[\mathbb{Q}(\sqrt{2}, \sqrt[3]{2}): \mathbb{Q}(\sqrt{2})][\mathbb{Q}(\sqrt{2}): \mathbb{Q}] \\
        &= 3\cdot 2 = 6.
        \end{align}
        \]
        Now, we know that the minimal polynomial of \(\sqrt{2} + \sqrt[3]{2}\) over \(\mathbb{Q}\) is degree \(6\).
        We already had
        \[
        \sqrt{2} = \frac{\alpha^3 + 6\alpha - 2}{3\alpha^2 + 2}.
        \]
        Then, we square both sides and simplify it,
        \[
        \begin{align}
        2 &= \frac{(\alpha^3 + 6\alpha - 2)^2}{(3\alpha^2 + 2)^2} \\
        2(3\alpha^2 + 2)^2 &= (\alpha^3 + 6\alpha - 2)^2 \\
        2(9\alpha^4 + 12\alpha^2 + 4) &= \alpha^6 + 12\alpha^4 - 4\alpha^3 + 36\alpha^2 - 24\alpha + 4 \\
        18\alpha^4 + 24\alpha^2 + 8 &= \alpha^6 + 12\alpha^4 - 4\alpha^3 + 36\alpha^2 - 24\alpha + 4 \\
        \alpha^6 - 6\alpha^4 - 4\alpha^3 + 12\alpha^2 - 24\alpha - 4 &= 0.
        \end{align}
        \]
        Since \(x^6 - 6x^4 - 4x^3 + 12x^2 - 24x - 4\) had degree of \(6\) and \(\sqrt{2} + \sqrt[3]{2}\) is a root of \(x^6 - 6x^4 - 4x^3 + 12x^2 - 24x - 4\), we can know that \(x^6 - 6x^4 - 4x^3 + 12x^2 - 24x - 4\) is the minimal polynomial of \(\sqrt{2} + \sqrt[3]{2}\) over \(\mathbb{Q}\).
      </p>
    </section>

    <section id = 'ku_2015_1_5'>
        <div class = 'question-box-container'>
          <div class = 'question-box'>
              <p>
              <b>5.</b> Let \( V \) be a vector space over the field \( F \).
              </p>
              <p>
                  (i) Define the dual space \( V^* \).
              </p>
              <p>
                  (ii) Prove that the canonical map \( V \to V^{**} \) is an isomorphism when \( V \) is finite dimensional over \( F \).
              </p>
              <p>
                  (iii) Give an example to show that (ii) may fail if \( V \) is not finite dimensional.
              </p>
          </div>
        </div>
      <p>
        <b>Solution (i).</b> The dual space \( V^* \) is the set of all linear transformations from \( V \) to \( F \).
      </p>
    </section>

    <section id = 'ku_2015_1_6'>
        <div class = 'question-box-container'>
          <div class = 'question-box'>
              <p>
                  <b>6.</b> Let \( A \) be an \( n \times n \) matrix with entries in \( \mathbb{R} \), the field of real numbers.
                  Let \( \phi_A : \mathbb{R}^n \to \mathbb{R}^n \) be the linear transformation defined by \( \phi_A(v) = A \cdot v \), for each column vector \( v \in \mathbb{R}^n \). Set \( W := \{v \in \mathbb{R}^n \mid \phi_A(v) = v\} \) and assume that \( \dim \ker(\phi_A) + \dim W = n \).
              </p>
              <p>
                  (i) Give the minimal polynomial for \( A \).
              </p>
              <p>
                  (ii) Describe all possible Jordan canonical forms for \( A \).
              </p>
              <p>
                  (iii) Prove that if \( A \) is a symmetric matrix, then \( W \) is orthogonal to \( \ker(\phi_A) \). Assume that \( \mathbb{R}^n \) is endowed with its standard inner product.
              </p>
          </div>
        </div>
        <p>
        <b>Solutions (i).</b> Suppose that \(v\in \ker(A)\cap W\). Then we have \(A\cdot v = v = 0\), which implies that \(W\cap \ker(\phi_A) = 0\).
        Besides that, with \( \dim \ker(\phi_A) + \dim W = n \), we can know that \( \ker(\phi_A)\oplus W = \mathbb{R}^n \).
        Since we know that \(\ker(\phi_A)\oplus \text{Range}(\phi_A) = \mathbb{R}^n\), we can know that \(\text{Range}(\phi_A) = W\).
        Hence, for any \(v\in \mathbb{R}^n\), we can write \(v = v_1 + v_2\), where \(v_1\in \ker(\phi_A)\) and \(v_2\in W\).
        Then, we have \(A\cdot v = Av_1 + Av_2 = Av_2 = v_2\). And \(A(Av) = A(Av_1 + Av_2) = A(Av_2) = Av_2 = v_2\).
        Thus, we can get
        \[
        A^2\cdot v - A\cdot v= (A^2 - A)\cdot v = 0, \text{ for all } v\in \mathbb{R}^n.
        \]
        Hence, we can know that \(A^2 - A = 0\). Then, we can conclude that the minimal polynomial \(\mu_A \mid x^2 - x\).
        Suppose that \(\mu_A\) is a polynomial of degree \(1\). Then we can know that \(\mu_A = x\) or \(\mu_A = x - 1\).
        If \(\mu_A\) is a polynomial of degree \(2\), then we can know that \(\mu_A = x(x - 1)\).
        </p>
        <p>
        <b>Solution (ii).</b> If \(\mu_A = x\), then we have \(A = 0\). Hence, the Jordan canonical form of \(A\) is \(0\).
        If \(\mu_A = x - 1\), then we have \(A = I\). Hence, the Jordan canonical form of \(A\) is \(I\).
        If \(\mu_A = x(x - 1)\), then we want to prove that the Jordan Canonical Form of \(A\) is a diagonal matrix with \(0\) and \(1\) on the diagonal entries.
          Since \(W = \{v\in \mathbb{R}^n \mid Av = v\}\), we can know that \(W = \ker(A - I)\).
          Given that \(\text{dim}\ker(A) + \text{dim}W = n\), we have \(\text{dim}\ker(A - 0\cdot I) + \text{dim}\ker(A - I) = n\).
          Thus, we can know that \(A\) is diagonalizable. Hence, the Jordan Canonical Form of \(A\) is a diagonal matrix with \(0\) and \(1\) on the diagonal entries.
        </p>
        <p>
        <b>Proof (iii).</b> Suppose that \(A\) is a symmetric matrix. Then we have \(A = A^T = A^*\) since \(A\) is a real matrix.
        Let \(w\in W\) and \(v\in \ker(\phi_A)\). Then we have
        \[
        \langle w, v\rangle = \langle Aw, v\rangle = \langle w, A^*v\rangle = \langle w, Av\rangle = \langle w, 0\rangle = 0.
        \]
        Hence, we can know that \(W\) is orthogonal to \(\ker(\phi_A)\). \[\tag*{\(\blacksquare\)}\]
        </p>
    </section>

    <h2>KU 2015 (August)</h2>

    <section id = 'ku_2015_8_5'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
            <p>
                <b>5.</b> Let \(A\) and \(B\)  be \(n \times n\) commuting matrices over \(\mathbb{C}\).
            </p>
            <p>
                (a) Prove that \(A\) and \(B\) have a common eigenvector.
            </p>
            <p>
                (b) Assume that \(B\) has \(n\) distinct eigenvalues. Prove that \(A\) is diagonalizable.
            </p>
            </div>
        </div>
      <p>
        <b>Proof (a).</b> (to be continued...)
      </p>
      <p>
        <b>Proof (b).</b> Given that \(B\) has \(n\) distinct eigenvalues, and they are \(\lambda_1, \dots, \lambda_n\).
        Thus, we can know that \(\ker(A-\lambda_1 I)\oplus \dots \oplus \ker(A - \lambda_nI) = \mathbb{C}^n\).
        Hence, we can know that any two eigenvectors correspondent to different eigenvalues are orthogonal to each other. \
        Here is the proof: Suppose that \(v\in \ker(A-\lambda_vI)\) and \(w\in \ker(A-\lambda_wI)\).
        \[
        \lambda Bv, w\lambda
        \]
      </p>
    </section>
    <section id = 'ku_2015_8_6'>
        <div class = 'question-box-container'>
          <div class = 'question-box'>
      <p>
        <b>Problem 6.</b> Let \( A \) be the \( n \times n \) matrix over \( \mathbb{C} \) all of whose entries equal \(1\).
      </p>
      <p>
        (a) Find the minimal polynomial of \( A \).
      </p>
        <p>
        (b) Find the Jordan canonical form of \( A \).
          </p>
            <p>
        (c) Let \( B \) denote the \( n \times n \) matrix over \( \mathbb{C} \) whose diagonal entries are 0 and all other entries are 1. Find the Jordan canonical form of \( B \).
      </p>
    </div>
    </div>
      <p>
        <b>Solution (a).</b> Let \(A\) be the \(n \times n\) matrix over \(\mathbb{C}\) all of whose entries equal \(1\).
        Then, we can know that \(A^2 = nA\). Thus, we have \(A^2 - nA = 0\), which implies that \(\mu_A \mid x^2 - nx = x(x - n)\).
        If \(\mu_A\) is the polynomial of degree \(1\), the \(\mu_A = x\) or \(\mu_A = x - n\). However, we know that
        \(A\neq 0\) and \(A - n\cdot I\neq 0\), which is the contradiction. Therefore, we can know that \(\mu_A = x(x - n)\).
      </p>
      <p>
        <b>Solution (b).</b> According to the minimal polynomial, we can know that it only has two eigenvalues, \(0\) and \(n\).
        Then we try to find the dimension of the eigenspace of \(0\) and \(n\). Since we can see that \(\text{dim}\ker(A-0\cdot I) = n-1\).
        Besides that, we can know that \(\text{dim}\ker(A - n\cdot I)\geq 1\), which means that \(\text{dim}\ker(A-0\cdot I)+\text{dim}\ker(A-n\cdot I)\geq n\).
        We also have \(\(\text{dim}\ker(A-0\cdot I)+\text{dim}\ker(A-n\cdot I)\leq n\), which implies that \(\text{dim}\ker(A-0\cdot I)+\text{dim}\ker(A-n\cdot I)= n\).
        Then, we can know that the geometric Multiplicity equals to the algebraic multiplicity. Hence, the Jordan canonical form of \(A\) is the diagonal matrix with \(0\) and \(n\) on the diagonal.
      </p>
      <p>
      <b>Solution (c (1)).</b> Let \(A_n\) to denote the \(n\times n\) matrix with all entries equal to 1.
      Then, we denote \(B_n\) as \(A_n - I_n\) where \(I_n\) is the identity matrix of size \(n\times n\).
      Since, we know that \(A_n\) has diagonlization in the form of \(A = PDP^{-1}\) where \(D\) is the diagonal matrix with \(0\) and \(n\) on the diagonal entries.
      Hence, we can know that
      \[
        B_n  = A_n - I_n = PDP^{-1} - PI_nP^{-1} = P(D - I_n)P^{-1}.
      \]
      It is not hard to see that \(D - I_n\) is a diagonal matrix, which means that \(B_n\) is diagonalizable.
      Again, since the diagonal entries of \(D\) is either \(0\) or \(n\), we can know that \(D - I_n\) is the diagonal matrix with diagonal entries of \(-1\) or \(n-1\).
      Therefore, the Jordan Canonical Form of \(B_n\) is the diagonal matrix with diagonal entries of \(-1\) or \(n-1\).
      </p>
      <p>
        <b>Solution (c (2)).</b> Let \(A_n\) to denote the \(n\times n\) matrix with all entries equal to 1.
        Then, we denote \(B_n\) as \(A_n - I_n\) where \(I_n\) is the identity matrix of size \(n\times n\).
        Let \(e_1\) to be the first standard basis vector in \(\mathbb{C}^n\).
        Then we have \(B\cdot e_1 = [0, 1, 1, \ldots, 1]^T\).
        Since \(B_n^2 = (A_n - I_n)^2 = A_n^2 - 2A_n + I_n = nA_n - 2A_n + I_n = (n - 2)A_n + I_n\).
        Hence, we can see that \(B_n^2\) is the \(n\times n\) matrix with all entries equal to \(n-2\) besides the diagonal entries are \(n - 1\).
        Then, we can get \(B_n^2 \cdot e_1 = [n-1, n-2, n-2, \ldots, n-2]^T\).
        Thus, we will get the following equations:
        \[
        \begin{align}
        (n-1)\cdot e_1 + (n-2)\cdot B_n\cdot e_1 &= B_n^2\cdot e_1 \\
        B_n^2\cdot e_1 - (n-2)\cdot B_n\cdot e_1 &- (n-1)\cdot e_1 = 0.
        \end{align}
        \]
        Therefore, we can have the minimal polynomial of \(B_n\) is \(x^2 - (n-2)x - (n-1)\).
        By Quadratic Formula, we can find the two roots of the minimal polynomial, which are \(n-1\) and \(-1\).
        Hence, we can know that \(\mu_{B_n} = (x - (n-1))(x + 1)\). Now, we try to find the dimension of the eigenspace of \(-1\).
        Since \(\ker(B_n -(-1)\cdot I) = \ker(A_n) \) and we already knew that \(\text{dim}\ker(A_n) = n-1\), \(\text{dim}\ker(B_n -(-1)\cdot I) = n-1 \).
        By the similar reason, we can know that \(\text{dim}\ker(B_n - (n-1)\cdot I)\geq 1\) and it shows that \(\text{dim}\ker(B_n - (n-1)\cdot I)+\text{dim}\ker(A_n)\geq n\).
        With the condition that \(\text{dim}\ker(B_n - (n-1)\cdot I)+\text{dim}\ker(A_n)\leq n\), we have \(\text{dim}\ker(B_n - (n-1)\cdot I)+\text{dim}\ker(A_n)= n\).
        Again, the geometric Multiplicity equals to the algebraic multiplicity, we the Jordan canonical form of \(B_n\) os the diagonal matrix with \(-1\) and \(n-1\) on the diagonal.
      </p>
    </section>

    <br>

    <h2>KU 2016 (January)</h2>
    <section id = 'ku_2016_1_2'>
        <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
            <b>2.</b> Let \(F\) be a field and \(f(x)\) an irreducible, separable polynomial over \(F\). Write \(E\) for the splitting field of
            \(f(x)\) over \(F\), and suppose that \(\alpha\) and \(\alpha + 1\) are roots of \(f(x)\).
        </p>
        <p>
            (a) Prove that the characteristic of \(F\) is not zero.
        </p>
          <p>
            (b) Prove that there exists a field \(L\) between \(F\) and \(E\) such that \([E : L]\) equals the characteristic of \(F\) .
        </p>
        </div>
        </div>
        <p>
            <b>Proof (a).</b> We will prove it with contradiction. Suppose that \(F\) has characteristic \(0\). Since \(E\) ist he splitting field of \(f(x)\), which is irreducible, we can know that there exists an isomorphism \(\sigma:E\to E\)
            such that \(\sigma(\alpha) = \alpha + 1\) given that \(\alpha\) and \(\alpha + 1\) are two roots of \(f(x)\) and \(\sigma(a) = a\) for any \(a\in F\).
            Since, we can know that the \(\sigma\) sends the roots of \(f(x)\) to the roots of \(f(x)\), then we have
            \[
            \begin{align}
            \sigma(\alpha + 1) &= \sigma(\alpha) + \alpha(1) = \alpha + 1 + 1 = \alpha + 2\\
            \sigma(\alpha + 2) &= \sigma(\alpha) + \alpha(2) = \alpha + 1 + 2 = \alpha + 3\\
            \vdots\\
            \sigma(\alpha + n) &= \sigma(\alpha) + \alpha(n) = \alpha + 1 + n = \alpha + n+1\\
            \vdots \\
            \end{align}
            \]
            Given that the characteristic of \(F\) is \(0\), we can know that \(\alpha + n\) is a root of \(f(x)\) for any \(n\in \mathbb{N}\).
            In that case, \(f(x)\) has infinitely many roots, which is a contradiction. Hence, we can know that the characteristic of \(F\) is not \(0\). \(\blacksquare\)
        </p>
        <p>
            <b>Proof (b).</b> Given that \(F\) does not have characteristic \(0\), we can know that the characteristic of \(F\) is \(p\), where \(p\) is a prime number.
          According to part (a), we can know that \(f(x)\) contains the following roots:
          \[
          \alpha, \alpha + 1, \alpha + 2, \ldots, \alpha + p - 1.
          \]
          Fix the following the isomorphism we found in part (a), which is \(\sigma:E\to E\).
          Then we have
          \[
          \sigma(\alpha) = \alpha + 1, \sigma(\alpha + 1) = \alpha + 2, \ldots, \sigma(\alpha + p - 1) = \alpha.
          \]
          In other words, we have \(\sigma^p(\alpha) = \alpha\). Hence, we can know that \(\sigma\in \text{Gal}(E/F)\) has order \(p\).
          Thus, we can know that \(\langle \sigma \rangle\) is a subgroup of \(\text{Gal}(E/F)\) with order \(p\).
          According to the \(\textbf{Galois Correspondence}\), we can know that there exists a field \(L\) between \(F\) and \(E\) such that \([E:L] = p\). \(\blacksquare\)
        </p>
    </section>
    <section id = 'ku_2016_1_5'>
      <div class = 'question-box-container'>
      <div class = 'question-box'>
      <p>
      <b>Problem 5.</b> Let \( V \) be a finite dimensional vector space over the field \( F \) and \( T : V \to V \) is a linear transformation. Suppose that \( \chi_T(x) \), the characteristic polynomial of \( T \), factors as \( \chi_T(x) = p_1(x)^{f_1} \cdots p_r(x)^{f_r} \), where each \( p_i(x) \) is irreducible over \( F \). Prove that the minimal polynomial of \( T \) equals \( p_1(x)^{e_1} \cdots p_r(x)^{e_r} \), where for each \( 1 \leq i \leq r \), \( e_i \) is the first exponent for which the kernel of \( p_i(T)^{e_i} \) equals the kernel of \( p_i(T)^{e_i+1} \).
    </p>
      </div>
      </div>
    <p>
      <b>Proof.</b> We will prove it with mathematical contradiction. Given that the characteristic polynomial of \( T \) is \( \chi_T(x) = p_1(x)^{f_1} \cdots p_r(x)^{f_r} \), where each \( p_i(x) \) is irreducible over \( F \).
      Then we have the minimal polynomial of \( T \) is \( p_1(x)^{e_1} \cdots p_r(x)^{e_r} \), where \( 1 \leq e_i \leq f_i \) for each \(i\). By the following theorem:
    </p>
      <p>
        <b>Theorem.</b>
        Let \( V \) be a finite-dimensional vector space, \( T \) an operator on \( V \), and assume the minimal polynomial of \( T \) is \( \mu_T(x) = p_1(x)^{e_1} \cdots p_t(x)^{e_t} \), where the polynomials \( p_i(x) \) are irreducible and distinct.
        For each \( i \), let
        \[
        V_i = V(p_i) = \{ v \in V \mid p_i(T)^{e_i}(v) = 0 \} = \text{Ker}(p_i(T)^{e_i}).
        \]
        Then each of the spaces \( V_i \) is \( T \)-invariant and
        \[
        V = V_1 \oplus V_2 \oplus \cdots \oplus V_t.
        \]
      </p>
      Now, suppose that \(e_i\) is not the first exponent for which the kernel of \(p_i(T)^{e_i}\) equals the kernel of \(p_i(T)^{e_i+1}\).
      In other words, \(\ker(p_i(T)^{e_i-1}) = \ker(p_i(T)^{e_i})\) (to be continued...)
    </section>

    <br>

    <h2>KU 2016 (August)</h2>
    <section id = 'ku_2016_8_1'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
      <p>
        <b>1.</b> Let \(R\) be a commutative ring with unity. Let \(U(R)\) be the set of units in \(R\).
      </p>
      <p>
        (a) Show that \(U(R)\) is an abelian group under multiplication.
      </p>
      <p>
        (b) Let \(R = \mathbb{Z}[x]/(x^2)\). Show that \(U(R) \cong \mathbb{Z} \times \mathbb{Z}_2\). Justify your answer carefully.
      </p>
        </div>
        </div>
      <p>
        <b>Proof (a).</b> Given that \(R\) is a commutative ring with unity and \(U(R)\) is the set of units in \(R\).
        Hence, we know that \(1\in U(R)\). For any \(a\in U(R)\), we have \(a\cdot a^{-1}\in U(R)\) where \(a^{-1}\in U(R)\) since \(a\) is a unit.
        For any \(a, b\in U(R)\), we can know that \(ab\in U(R)\) since \(b^{-1}, a^{-1}\in U(R)\) and \(b^{-1}a^{-1}\in U(R)\).
        Therefore, we can know that \(U(R)\) is a group under multiplication. \(\blacksquare\)
      </p>
      <p>
        <b>Proof (b).</b> Firstly, we can know that \((x^2) = \{f\cdot x^2 \mid f\in \mathbb{Z}[x]\}\).
        Hence, let \(f = a_nx^n + a_{n-1}x^{n-1} + \cdots + a_1x + a_0\), where \(a_i\in \mathbb{Z}\).
        Hence, we have \(f\cdot x^2 = a_nx^{n+2} + a_{n-1}x^{n+1} + \cdots + a_1x^3 + a_0x^2\).
        Thus, we can know that \(R = \mathbb{Z}[x]/(x^2) = \{ax + b\,\mid\, a, b\in \mathbb{Z}\}\).
        Suppose that \(ax + b\in U(R)\), then we can know that there exists \(cx + d\in U(R)\) such that
        \((ax + b)(cx + d) = 1\). Hence, we have \(acx^2 + (ad + bc)x + bd = (ad + bc)x + bd = 1\), which implies that \(ad + bc = 0\) and \(bd = 1\).
        Since \(b, d\in \mathbb{Z}\), we can know that \(b = d = -1\) or \(b = d = 1\) in order to make sure \(bd = 1\).
        Hence, we have \(a + c = 0\), which implies that \(a = -c\).
        Hence, we can know that \(U(R) = \{ax + 1, bx - 1\,\mid\, a, b\in \mathbb{Z}\}\).
        Let \(\varphi: U(R) \to \mathbb{Z}\times \mathbb{Z}_2\) be a map such that \(\varphi(ax + 1) = (a, 0)\) and \(\varphi(bx - 1) = (b, 1)\).
      </p>
    </section>

    <br>

    <section id = 'ku_2016_8_2'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            2. Recall that a splitting field for a polynomial \( f(x) \) over a field \( F \) is the smallest (in terms of degree) extension \( K \) of \( F \) such that \( f(x) \) factors completely in \( K[x] \). Let \( F = \mathbb{Z}_2 \).
          </p>
          <p>
            (a) Prove that \( K = F[t]/(t^3 + t + 1) \) is a field of order 8.
          </p>
          <p>
            (b) Prove that \( K \) is a splitting field for \( f(x) = x^7 - 1 \) over \( F \).
            </p>
        </div>
        </div>
      <p>
        <b>Proof (a).</b> Firstly, we want to show that \(t^3 + t + 1\) is irreducible in \(F[t]\) by contradiction.
        Suppose that \(t^3 + t + 1 = (t + a)(t^2 + bt + c)\) for some \(a, b, c\in F\).
        Then we know that \(t^3 + t + 1\) has a root in \(F\), which is \(-a\).
        However, \(1^3 + 1 + 1 = 1\) and \(0^3 + 0 + 1 = 1\). Hence, we can know that \(t^3 + t + 1\) has no root in \(F\), which is a contradiction.
        Thus, we can know that \(t^3 + t + 1\) is irreducible in \(F[t]\). Hence, we have \(K = F[t]/(t^3 + t + 1)\) is a field.
        Hence, the element in \(K\) is of the form \(a + bt + ct^2\) where \(a, b, c\in F\).
        Each \(a, b, c\) has two choices, which implies that \(K\) has \(2^3 = 8\) elements. Therefore, we can know that \(K\) is a field of order 8. \(\blacksquare\)
      </p>
      <p>
        <b>Proof (b).</b> Given that \(K\setminus\{0\}\) is a group of order \(7\) under multiplication. Thus, for any \(x\in K\setminus \{0\}\), we have
        \(x^7 = 1\).
        Since each element of \(K\setminus\{0\}\) is root of \(x^7 - 1\), we can conclude that \(K\) is a splitting field for \(f(x) = x^7 - 1\) over \(F\). \(\blacksquare\)
      </p>
    </section>

    <br>

    <section id = 'ku_2016_8_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>3.</b> Let \( G \) be a group and \( \text{Aut}(G) \) be the group of automorphisms of \( G \). Recall that for any \( c \in G \), we have an automorphism of \( G \) given by \( f_c(x) = c^{-1}xc \) (such an automorphism is called an inner automorphism of \( G \)). It is not hard to see that \( \text{Inn}(G) \), the collection of inner automorphisms of \( G \), is a subgroup of \( \text{Aut}(G) \).
          </p>
          <p>
            (a) Show that \( G/Z(G) \cong \text{Inn}(G) \). Here \( Z(G) \) is the center of \( G \).
          </p>
          <p>
            (b) Show that if \( \text{Aut}(G) \) is cyclic, then \( G \) is abelian.
          </p>
          <p>
            (c) Find all prime numbers \( p \) such that there is a finite group \( G \) with \( \text{Aut}(G) \cong \mathbb{Z}_p \). (Hint: show that if \( G \) is not \( \mathbb{Z}_2 \), then \( \text{Aut}(G) \) must have an element of order 2).
          </p>
        </div>
        </div>
      <p>
        <b>Proof (a)</b> Firstly, we define a map \(\varphi: G\to \text{Inn}(G)\) such that
        \[
        \varphi(g) = f_g(x) = g^{-1}xg.
        \]
        Then, we can see that \(\varphi\) is well-defined since if \(g = h\in G\), then we will have \(g^{-1}xg = h^{-1}xh\).
        Now, we want to show that \(varphi\) is a group homomorphism. Suppose that \(g, h\in G\), then we have
        \[
        \varphi(h)\cdot \varphi(g) = \varphi(g)\circ\varphi(h) = f_g\circ f_h(x) = f_g(h^{-1}xh) = g^{-1}h^{-1}xhg = (hg)^{-1}x(hg) = f_{hg}(x) = \varphi(hg).
        \]
        Hence, we can know that \(\varphi\) is a group homomorphism. Since for any \(f_g(x)\in \text{Inn}(G)\), we have \(\varphi(g) = f_g(x)\), which implies that \(varphi\) is surjective.
        Now, we want to figure the kernel of \(\varphi\). In \(\text{Inn}(G)\), we can know that the identity of \(\text{Inn}(G)\) is \(f_e(x) = e^{-1}xe = x\).
        Hence, for any \(g\in \ker(\varphi)\), we have \(f_g(x) = g^{-1}xg = x\), which implies that \(g\in Z(G)\).
        In other direction, for any \(z\in Z(G)\), we have \(f_z(x) = z^{-1}xz = x\), which implies that \(z\in \ker(\varphi)\).
        Thus, we can know that \(\ker(\varphi) = Z(G)\). By the \(\textbf{First Isomorphism Theorem}\), we can know that \(G/Z(G) \cong \text{Inn}(G)\). \(\blacksquare\)
      </p>
      <p>
        <b>Proof (b).</b> We know that if \(G\) is a cyclic group, any subgroup of a cyclic group is cyclic. Since \(\text{Inn}(G)\) is a subgroup of \(\text{Aut}(G)\) and \(\text{Aut}(G)\) is cyclic, we can know that \(\text{Inn}(G)\) is cyclic.
        And we already showed that \(\text{Inn}(G)\} \cong G/Z(G)\). Hence, we can know that \(G/Z(G)\) is cyclic. Since \(G/Z(G)\) is cyclic, we can know that \(G/Z(G) = \langle aZ(G)\rangle\) for some \(a\in G\).
        Hence, for any \(g\in G\), we can know that \(gZ(G) = (aZ(G))^n = a^nZ(G)\) for some \(n\in \mathbb{Z}\).
        Thus, we have \(Z(G) = (a^{-1})^ngZ(G) = a^{-n}gZ(G)\), which implies that there exists \(z\in Z(G)\) such that \(a^{-n}g = z\).
        Hence, we have \(g = za^n = a^nz\) for some \(z\in Z(G)\) and \(n\in \mathbb{Z}\). Now, suppose that \(g = a^nz_1\) and \(h = a^mz_2\) for some \(n, m\in \mathbb{Z}\) and \(z_1, z_2\in Z(G)\).
        Then we have
        \[
        gh = a^nz_1a^mz_2 = (a^nz_1a^m)z_2 = z_2a^nz_1a^m = z_2a^na^mz_1 = z_2a^{n+m}z_1 = z_2a^ma^nz_1 = a^mz_2a^nz_1 = hg.
        \]
        Therefore, we can know that \(G\) is abelian. \(\blacksquare\)
      </p>
      <p>
        <b>Solution (c).</b> Suppose that \(G\) is a finite group and there exists a prime \(p\) such that \(\text{Aut}(G) = \mathbb{Z}_p\).
        We know that \(\mathbb{Z}_p\) is a cyclic group. Based on part (b), we can know that \(G\) is an abelian group. Assume that \(G\neq \mathbb{Z}_2\).
        In that case, we can know there exists \(g\in G\) such that \(g^{-1}\neq g\).
        Now define \(\varphi: G\to G\) such that \(\varphi(g) = g^{-1}\). Firstly, we can see that \(\varphi\) is well-defined since if \(g = h\), we will have \(g^{-1} = h^{-1}\).
        Now, we want to show that \(\varphi\) is a group homomorphism. Suppose that \(g, h\in G\), then we have
        \[
        \varphi(h)\cdot \varphi(g) = \varphi(g)\circ\varphi(h) = g^{-1}\circ h^{-1} = (hg)^{-1} = (gh)^{-1} = \varphi(gh).
        \]
        Hence, we can know that \(\varphi\) is a group homomorphism. Suppose that \(\varphi(g) = \varphi(h)\), then we have \(g^{-1} = h^{-1}\), which implies that \(g = h\).
        It shows that \(\varphi\) is injective. Given that \(G\) is a finite group, we can know that \(\varphi\) is surjective by the \(\textbf{Pigeonhole Principle}\).
        It means that \(\varphi\) is an automorphism of \(G\). For any \(g\in G\), we have \(\varphi^{2}(g) = g\), which implies that \(\varphi\) has order of \(2\).
        Hence, we can know that \(2\mid |\mathbb{Z}_p| = p\). If \(p\neq 2\), we can know that it is impossible that \(2\mid p\) since \(p\) is a prime number.
        Hence, \(p\) has to be \(2\) when \(G\neq \mathbb{Z}_2\). Let \(G = \mathbb{Z}_3\). For any \(\varphi\in \text{Aut}(G)\), we have \(\varphi(0) = 0\), \(\varphi(1) = 1\) and \(\varphi(2) = 2\), which implies that \(\varphi\) is the identity automorphism.
        Besides that \(\psi\in \text{Aut}(G)\) such that \(\psi(0) = 0\), \(\psi(1) = 2\) and \(\psi(2) = 1\), which implies that \(\psi\) has order of \(2\).
        And those are the only automorphisms of \(\mathbb{Z}_3\), which means \(\text{Aut}(\mathbb{Z}_3) = \mathbb{Z}_2\).
        When \(G = \mathbb{Z}_2\), let \(\varphi\in \text{Aut}(G)\) such that \(\varphi(0) = 0\) and \(\varphi(1) = 1\).
        Then we have \(\varphi\) is the identity automorphism, and it is the only automorphism of \(\mathbb{Z}_2\). Same for \(G = \mathbb{Z}_1\).
        Thus, we can know that the only possible \(p\) is \(2\).
      </p>
    </section>

    <section id = 'ku_2016_8_4'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>4.</b> Let \( A \) be an \( n \times n \) matrix over a field \( F \). Prove \( \det(A) \) equals \( (-1)^n \) times the constant term of the characteristic polynomial of \( A \).
      </p>
            </div>
        </div>
      <p>
        <b>Proof.</b> Since the characteristic polynomial of \( A \) is \( \chi_A(x) = \det(xI - A) \), which is a polynomial of degree \( n \) with variable \( x \).
        And we know that \(\det(-A) = (-1)^n\det(A)\). Hence, we plug in \(x = 0\), we have
        \[
          (-1)^n\det(A) = \det(-A) = \det(0I - A).
        \]
        This implies that \( \det(A) \) equals \( (-1)^n \) times the constant term of the characteristic polynomial of \( A \). \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2016_8_5'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
            <p>
                5. Let \( V \) denote the complex vector space of complex polynomials having degree at most five, endowed with the usual inner product. In other words, for \( f(x), g(x) \in V \), \(\langle f(x), g(x) \rangle := \int_0^1 f(x) \overline{g(x)} \, dx \).
            </p>
            <p>
                (a) Find an orthonormal basis for the space \( W \) spanned by \( x + x^2, x^2 + x^3, x^3, x^3 + x^4 \).
            </p>
            <p>
                (b) Find (with proof) a self adjoint operator \( T : W \to W \) that is not the identity map.</p>
            </p>
            </div>
        </div>
        <p>
            <b>Solution (a).</b> We will first find an orthogonal basis for \( W \). Let \( v_1 = x + x^2 \), \( v_2 = x^2 + x^3 \), \( v_3 = x^3 \), and \( v_4 = x^3 + x^4 \) by \(\textbf{Gram-Schmidt orthogonalization}\).
            We normalize \(v_1\) firstly and have
            \[
                u_1 = \dfrac{v_1}{\|v_1\| } = \dfrac{x + x^2}{\sqrt{\langle x + x^2, x + x^2 \rangle}} = \dfrac{x + x^2}{\sqrt{\int_0^1 (x + x^2)(x + x^2) \, dx}} = \dfrac{x + x^2}{\sqrt{\dfrac{31}{30}} = \sqrt{\dfrac{30}{31}}(x + x^2)}.
            \]
            Then we have
            \[
            \begin{align}
                u_2 &= v_2 - \langle v_2, u_1 \rangle u_1 \\
                &= x^2 + x^3 - \sqrt{\dfrac{30}{31}} \int_0^1 (x^2 + x^3)(x + x^2) \, dx (x + x^2)(\sqrt{\dfrac{30}{31}}) \\
                &= x^2 + x^3 - \dfrac{30}{31} \int_0^1 (x^2+x^3)(x + x^2) \, dx (x + x^2) \\
                &= -\frac{49}{62}x + x^3 - \dfrac{13}{62} x^2. \\
                u_3 &= v_3 - \langle v_3, u_1 \rangle u_1 - \langle v_3, u_2 \rangle u_2 \\
            \end{align}
            ]
        </p>
    </section>

    <br>

    <h2 id = 'january_2017'>KU 2017 (January)</h2>
    <section id = 'ku_2017_1_1'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
          <b>1.</b> Let \( G \) be a finite group with \( |G| = p^n \), \( p \) prime.
        </p>
          <p>
          (i) Prove that \( Z(G) \), the center of \( G \), is non-trivial.
          </p>
          <p>
            (ii) Prove that if \( N \subseteq G \) is a normal subgroup of order \( p \), then \( N \subseteq Z(G) \). Hint: Let \( G \) act on \( N \).
          </p>
          <p>
            (iii) Give an example of a non-abelian group of order \( p^n \) whose center contains more than one normal subgroup of order \( p \).
          </p>
      </div>
      </div>
      <p>
        <b>Proof (i).</b>
      </p>
      <p>
        <b>Proof (ii).</b> Firstly, we define a map \(\varphi: G\to \text{Aut}(N)\) such that \(\varphi(g) = f_g = gng^{-1}\) for any \(g\in G\) and \(n\in N\).
        The reason that \(f_g\) is in \(\text{Aut}(G)\) is \(N\) is a normal subgroup such that \(gNg^{-1} = N\).
        We can see that \(\varphi\) is well-defined since if \(g = h\), we will have \(f_g = f_h\).
        Suppose that \(g, h\in G\), we will have
        \[
        \varphi(g)\varphi(h) = \varphi(g)\circ\varphi(h) = f_g\circ f_h = f_g(hnh^{-1}) = g h n h^{-1}g^{-1} = (gh)n(gh)^{-1} = f_{gh}(n) = \varphi(gh),
        \]
        which implies that \(\varphi\) is a group homomorphism. Hence, we can see that \(\varphi(G)\) is a subgroup of \(\text{Aut}(N)\).
        Given that \(N\) is a subgroup of order \(p\), we have \(N\cong \mathbb{Z}_p\). Hence, we have \(N\) is cyclic.
        For any \(f\in \text{Aut}(N)\), any nontrivial \(g\in N\) is a generator of \(N\), and once determine \(f(g)\), we can determine \(f\) completely.
        Hence, there will be \(p - 1\) automorphisms of \(N\) since each nontrivial element has \(p-1\) choices to be mapped. Thus, we can know that \(|\text{Aut}(N)| = p - 1\).
        Since \(\varphi(G)\) is a subgroup of \(\text{Aut}(G)\), we have \(|\varphi(G)|\) divides \(|\text{Aut}(N)|\), which implies that \(|\varphi(G)|\) divides \(p - 1\).
        By the \(\textbf{First Isomorphism Theorem}\), we have \(G/\ker(\varphi) \cong \varphi(G)\).
        Since \(|G/\ker(\varphi)| = [G:\ker(\varphi)]\), we have \(|G/\ker(\varphi)|\) divides \(p^n\). Hence, we have \(|G/\ker(\varphi)| = p^k\) for some \(0\leq k\leq n\).
        Since \(|\varphi(G)|\) divides \(p - 1\) and \(|G/\ker(\varphi)| = |\varphi(G)| = p^k\), we have \(p^k\mid p-1\). Thus, \(p^k\leq p-1\), which implies that \(k = 0\).
        Thus, we can know that \(|\varphi(G)| = 1\), which implies that \(\varphi(G) \subset \text{Aut}(N)\) is trivial. Hence, we can know that \(gng^{-1} = n\) for any \(g\in G\) and \(n\in N\), which implies that \(N\subset Z(G)\). \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2017_1_2'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
                <p>
                    <b>2.</b> Let \( R \) be an integral domain. Suppose there exists a nonzero, non-unit \( a \in R \) such that for every \( r \in R \), there exists a unit \( u \) and \( n \geq 0 \) such that \( r = ua^n \). Such a ring is called a discrete valuation ring. Set \( P := aR \). Let \( R[\frac{1}{a}] \) denote the ring of polynomial expressions in \(\frac{1}{a}\) with coefficients in \( R \). Note, \(\frac{1}{a} \notin R \).
                </p>
                <p>
                    (i) Prove that \( P \) is a maximal ideal, and in fact, the only maximal ideal.
                </p>
                <p>
                    (ii) Prove that \(\bigcap_{n=1}^{\infty} P^n = (0)\).
                </p>
                <p>
                    (iii) Prove that \( R[\frac{1}{a}] \) is a field.
                </p>
                <p>
                    (iv) Let \( R \) be the ring of formal power series over \(\mathbb{Q}\). Thus, a typical element in \( Râ€‹ \) is of the form \( \sum_{n=0}^{\infty} a_n x^n \) where \( a_n \in \mathbb{Q} \). Let \( a = x \). Prove that \( R \) is a discrete valuation ring.
                </p>
            </div>
        </div>
        <p>
        <b>Proof (i).</b> Given that \(a\) is not a unit, we can know that \(a^n\) will never be a unit for any \(n\geq 1\).
        In that case, we have \(ar\) is not a unit for any \(r\in R\). It is because if \(ar\) is a unit, then there exists \(s\in S\) such that
        \((ar)s = a(rs) = 1\), which implies \(a\) is a unit. Thus, we can know that \(aR\) does not contain a unit; hence, \(aR\) is a proper ideal.
        Now, we want to show that \(aR\) is a maximal ideal by contradiction. Suppose that \(aR\) is not a maximal ideal.
        Since every proper ideal is contained in a maximal ideal. Thus, we can know that \(aR\) is contained in a maximal ideal \(M\) such that \(aR\neq M\).
        Hence, there exists \(m\in M\) such that \(m\) is not a unit and \(m\notin aR\).
        However, we know that \(m = ua^n\) for some unit \(u\) and \(n\geq 0\) by assumption, which means that \(m\in aR\). It is a contradiction.
        Hence, we can know that \(aR\) is a maximal ideal.
        Actually, for any non-unit \(r\in R\), we have \(r = ua^n\) for some unit \(u\) and \(n\geq 0\), which implies that \(r\in aR\).
        In short, \(aR\) contains all the non-units in \(R\). And we know that every maximal ideal is a proper ideal. In other words, every element in each maximal ideal is a non-unit.
        Hence, if \(M\) is a maximal ideal of \(R\), we have \(M\subset aR\), which implies that \(M = aR\). Therefore, \(aR\) is the only maximal ideal. \(\blacksquare\)
        </p>
    </section>

    <section id = 'ku_2017_1_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>3.</b> Let \(\mathbb{Z}^n\) denote the free abelian group of rank \( n \), its elements being row vectors of length \( n \). Let \( A \) be an \( r \times n \) matrix over \(\mathbb{Z}\) and write \( K_A \) for the subgroup of \(\mathbb{Z}^n\) generated by the rows of \( A \).
          </p>
          <p>
            (i) Suppose \( B := PAQ \), where \( P \) is an \( r \times r \) invertible matrix over \(\mathbb{Z}\) and \( Q \) is an invertible \( n \times n \) matrix over \(\mathbb{Z}\). Prove that \(\mathbb{Z}^n / K_A\) and \(\mathbb{Z}^n / K_B\) are isomorphic as abelian groups.
          </p>
          <p>
            (ii) Suppose \( A = \begin{pmatrix} 4 & -2 & 4 \\ 2 & 4 & 4 \end{pmatrix} \). Write \(\mathbb{Z}^3 / K_A\) as a direct sum of cyclic groups.
          </p>
        </div>
      </div>
      <p>
        <b>Proof (i).</b> Given that \(K_A\) is the subgroup of \(\mathbb{Z}^n\) generated by the rows of \(A\), we have \(K_A = \{x\in \mathbb{Z}^n\,\mid\, x = \sum_{i=1}^r a_iA_i\}\), where \(A_i\) is the \(i\)-th row of \(A\).
        And we can know that \(K_A\) is isomorphic to the subgroup of \(\mathbb{Z}^r\) generated by the columns of \(A^T\), where \(A^T\) is the transpose of \(A\), which is a \(n\times r\) matrix.
        Now, we have \(B^T = (PAQ)^T = Q^T A^T P^T\). We know that, if \(P\) is invertible, then \(p^T\) is invertible and \((P^T)^{-1} = (P^{-1})^T\).
        If \(y\in K_A\), we have \(y = A^Tx\) for some \(x\in \mathbb{Z}^r\). Then, we can have \(y = A^T(P^T(P^T)^{-1})x = (A^TP^T)((P^T)^{-1}x)\), where \((P^T)^{-1}x\in \mathbb{Z}^r\).
        Hence, we have \(K_A \subset K_{PA}\). For the other direction, if \(y\in K_{PA}\), we can know that \(y = A^TP^Tx\) for some \(x\in \mathbb{Z}^r\).
        Since \(y = A^T(P^Tx)\) where \(P^Tx\in \mathbb{Z}^r\), we have \(K_{PA} \subset K_A\). We can conclude that \(K_A = K_{PA}\).
        Then, we want to show that for any \(r\times n\) matrix \(M\) and invertible matrix \(Q\), we have \(K_{MQ} \cong K_M\).
        Let \(\varphi: K_{MQ}\to K_{M}\) be a map such that \(\varphi(x) = Q^Tx\) for any \(x\in K_{MQ}\). Since \(Q\) is invertible, we have \(Q^T\) is invertible, which implies that \(\varphi\) is a bijection.
        Hence, we can know that \(K_{M}\cong K_{MQ}\). Now, replace \(M\) with \(PA\), we have \(K_A = K_{PA} \cong K_{PAQ} = K_B\).
        Therefore, we can conclude that \(\mathbb{Z}^n / K_A\) and \(\mathbb{Z}^n / K_B\) are isomorphic as abelian groups. \(\blacksquare\)
      </p>
      <p>
        <b>Solution (ii). </b> Firstly, we define \(Q_1\) as the following
        \[
        Q = \begin{pmatrix} 1 & 1 & 0 \\ -1 & 0 & 2 \\ -1 & -1 & 1 \end{pmatrix}.
        \]
        Hence, we have
        \[
        (AQ_1)^T = Q^TA^T = \begin{bmatrix}
        1 & - 1 & - 1 \\
        1 & 0 & -1 \\
        0 & 2 & 1
        \end{bmatrix}\cdot \begin{bmatrix}
        4 & 2 \\
        -2 & 4 \\
        4 & 4
        \end{bmatrix} = \begin{bmatrix}
        2 & -6 \\
        0 & -2 \\
        0 & 12 \\
        \end{bmatrix}.
        \]
        Now, define \(P\) as
        \[
        P = \begin{bmatrix} 1 & 0 \\ 3 & 1 \end{bmatrix}.
        \]
        Then, we have
        \[
        (PAQ_1)^T = Q^TA^TP^T = \begin{bmatrix}
        2 & -6 \\
        0 & -2 \\
        0 & 12 \\
        \end{bmatrix}\cdot \begin{bmatrix}
        1 & 3 \\
        0 & 1
        \end{bmatrix} = \begin{bmatrix}
        2 & 0 \\
        0 & -2 \\
        0 & 12
        \end{bmatrix}.
        \]
        Now, we define \(Q_2\) as
        \[
        Q_2 = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 5 & 6 \\ 0 & 1 & 1 \end{bmatrix}.
        \]
        Then, we have
        \[
        (PAQ_1Q_2)^T = Q_2^TQ_1^TA^TP^T = \begin{bmatrix}
        1 & 0 & 0 \\
        0 & 5 & 1 \\
        0 & 6 & 1
        \end{bmatrix}\cdot \begin{bmatrix}
        2 & 0 \\
        0 & -2 \\
        0 & 12
        \end{bmatrix} = \begin{bmatrix}
        2 & 0 \\
        0 & 2 \\
        0 & 0 \\
        \end{bmatrix}.
        \]
        Since \(\det(Q_1) = \det(P) = 1, \det(Q_2\) = -1\), thus we know that \(Q_1Q_2\) and \(P\) are invertible.
        Thus, we can know that \(\mathbb{Z}^3 / K_A \cong \mathbb{Z}^3 / K_{PAQ_1Q_2}\).
        Given that \(PAQ_1Q_2 = \begin{bmatrix} 2 & 0 & 0 \\ 0 & 2 & 0 \end{bmatrix}\). Hence, we have \(K_{PAQ_1Q_2} = 2\mathbb{Z}\oplus 2\mathbb{Z}\).
        Therefore,
        \[
        \mathbb{Z}^3 / K_A \cong \mathbb{Z}^3 / K_{PAQ_1Q_2} \cong (\mathbb{Z}\oplus\mathbb{Z}\oplus \mathbb{Z})/(2\mathbb{Z}\oplus 2\mathbb{Z}) \cong \mathbb{Z}_2\oplus \mathbb{Z}_2\oplus \mathbb{Z}\cong \mathbb{Z}_2\times \mathbb{Z}_2\times \mathbb{Z}.
        \]
      </p>
    </section>

    <section id = 'ku_2017_1_4'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>4.</b> Let \( f(x) := x^3 - 9x + 3 \in \mathbb{Q}[x] \) and \( \alpha \) a root of \( f(x) \).
          </p>
          <p>
            (i) Prove that \( f(x) \) is irreducible over \( \mathbb{Q} \).
          </p>
          <p>
            (ii) In the field \( \mathbb{Q}(\alpha) \), write \( (3\alpha^2 + 2\alpha + 1)^{-1} \) in terms of the basis \( 1, \alpha, \alpha^2 \).
          </p>
        </div>
      </div>
      <p>
        <b>Proof (i).</b>
      </p>
      <p>
        <b>Solution (ii).</b>
        Since \(\alpha^3 - 9\alpha + 3 = 0\), we have \(\alpha^3 = 9\alpha - 3\) and \(\alpha^4 = 9\alpha^2 - 3\alpha\).
        Suppose that \((3\alpha^2 + 2\alpha + 1)^{-1} = x\alpha^2 + y\alpha + z\) for some \(x, y, z\in \mathbb{Q}\).
        Then we have
        \[
        \begin{align}
        (3\alpha^2 + 2\alpha + 1)(x\alpha^2 + y\alpha + z) &= 1 \\
        3x\alpha^4 + (3y + 2x)\alpha^3 + (3z + 2y + z)\alpha^2 + (2z + y)\alpha + z &= 1\\
        3x(9\alpha^2 - 3\alpha) + (3y + 2x)(9\alpha - 3) + (3z + 2y + z)\alpha^2 + (2z + y)\alpha + z &= 1\\
        (28x + 3z + 2y)\alpha^2 + (28y + 9x + 2z)\alpha -6x - 9y + z &= 1 \\
        (28x + 3z + 2y)\alpha^2 + (28y + 9x + 2z)\alpha -6x - 9y + z - 1&= 0.
        \end{align}
        \]
      Since \(\alpha^2, \alpha, 1\) form a basis of \( \mathbb{Q}(\alpha) \), we have
        \[
        \begin{align}
        28x + 3z + 2y &= 0 \tag*{(1)}\\
        28y + 9x + 2z &= 0 \tag*{(2)}\\
        -6x - 9y + z - 1 &= 0 \tag*{(3)}
        \end{align}
        \]
        From \((3)\), we have \(z = 6x + 9y + 1\). Plug it into \((1)\) and \((2)\), we have
        \[
        \begin{align}
        46x + 27y + 3 &= 0, \\
        21x + 46y + 2 &= 0.
        \end{align}
        \]
        Hence, we have
        \[
        \begin{align}
        x &= -\frac{84}{1549}, \\
        y &= -\frac{29}{1549}, \\
        z &= \frac{784}{1549}.
        \end{align}
        \]
        Therefore, we have \((3\alpha^2 + 2\alpha + 1)^{-1} = -\frac{84}{1549}\alpha^2 - \frac{29}{1549}\alpha + \frac{784}{1549}\).
      </p>

    </section>
    <br>

    <section id = 'ku_2017_1_5'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
      <p>
        <b>5.</b> Let \( A \) be an \( n \times n \) matrix over the field \( F \) and \( F^n \) denote the vector space of column vectors of length \( n \). Suppose \( A \) is idempotent, i.e., \( A^2 = A \).
      </p>
      <p>
        (i) Prove that \( F^n = U \oplus W \), where \( A \cdot u = 0 \), for all \( u \in U \) and \( A \cdot w = w \), for all \( w \in W \).
      </p>
      <p>
        (ii) If \( F = \mathbb{Z}_p \), how many idempotent \( 3 \times 3 \) matrices are there?
      </p>
        </div>
        </div>
      <p>
        <b>Proof (i).</b> Given that \(A^2 = A\), we have \(A^2 - A = A(A - I) = 0\). Hence, we define \(p(x) = x(x - 1)\).
        If \(p(x)\) is the minimal polynomial of \(A\), then we can know that
        \[
        F^n = \ker(A) \oplus \ker(A - I).
        \]
        Let \(U = \ker(A)\) and \(W = \ker(A - I)\). Hence, for any \(u\in U\), we have \(A\cdot u = 0\) by the definition of the kernel.
        Let \(w\in W\), then we have \((A - I)\cdot w = 0\). Thus, we have \(A\cdot w = w\). Suppose that \(p(x)\) is not the minimal polynomial of \(A\).
        Then, we can know that the minimal polynomial of \(A\) divides \(p(x)\). Hence, we have two options: either it is \(x\) or \(x - 1\).
        (To be continued...)
      </p>
      <p>
        <b>Proof (ii).</b> Firstly, we know that \(V = \ker(A) \oplus \ker(A - I)\). Hence, we can know that \(A\) is diagonalizable.
        And we can know that \(A\) has only two possible eigenvalues: \(0\) and \(1\). Let \(G\) be the set of all nonsingular matrices over \(\mathbb{Z}_p\).
        Then we have \(|G| = (p^3 - 1)(p^3 - p)(p^3 - p^2)\).
        And we denote \(X\) be the set such as
        \[
          X = \left\{x_0 = \begin{bmatrix}
            0 & 0 & 0 \\
            0 & 0 & 0 \\
            0 & 0 & 0 \\
            \end{bmatrix}, x_1 = \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 0 & 0 \\
            0 & 0 & 0 \\
            \end{bmatrix}, x_2 = \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 0 \\
            \end{bmatrix},x_3 = \begin{bmatrix}
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 1 \\
            \end{bmatrix}\right\}.
        \]
        Since \(A\) is diagonalizable, we have \(A = gxg^{-1}\) for some \(g\in G\) and \(x\in X\).
        Now, we try to find the centralizer for each element in \(X\).
        For identity matrix and zero matrix, we know they are in the center of \(G\). Hence, we have \(|C_G(x_0)| = |C_G(x_3)| = |G| = (p^3 - 1)(p^3 - p)(p^3 - p^2)\).
        For the matrix \(x_1 = \begin{bmatrix}
          1 & 0 & 0 \\
          0 & 0 & 0 \\
          0 & 0 & 0 \\
          \end{bmatrix}\), suppose that \(g = \begin{bmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i \\
            \end{bmatrix}\), such that
        \[
        gxg^{-1} = \begin{bmatrix}
              1 & 0 & 0 \\
              0 & 0 & 0 \\
              0 & 0 & 0 \\
              \end{bmatrix}.
        \]
        Hence,
        \[
        \begin{align}
        \begin{bmatrix}
          a & b & c \\
          d & e & f \\
          g & h & i \\
          \end{bmatrix}\begin{bmatrix}
          1 & 0 & 0 \\
          0 & 0 & 0 \\
          0 & 0 & 0 \\
          \end{bmatrix} &= \begin{bmatrix}
          1 & 0 & 0 \\
          0 & 0 & 0 \\
          0 & 0 & 0 \\
          \end{bmatrix}\begin{bmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i \\
            \end{bmatrix},\\
        \begin{bmatrix}
        a & 0 & 0 \\
        d & 0 & 0 \\
        g & 0 & 0 \\
        \end{bmatrix} &= \begin{bmatrix}
        a & b & c \\
        0 & 0 & 0 \\
        0 & 0 & 0 \\
        \end{bmatrix},\\
        g &=
        \begin{bmatrix}
        a & 0 & 0 \\
        0 & e & f \\
        0 & h & i \\
        \end{bmatrix}.
        \end{align}
        \]
        Then, we can see that \(a\neq 0\), which implies that there are \(p - 1\) choices for \(a\).
        And the principal submatrix \(\begin{bmatrix}e & f \\ h & i\end{bmatrix}\) has to be nonsingular, which implies that there are \(p^2 - 1\) choices for \(e\) and \(h\) and \(p^2 - p\) choices for \(f\) and \(i\).
        In total, there are \((p - 1)(p^2 - 1)(p^2 - p)\) choices for \(g\).
        Now, we consider the matrix \(\begin{bmatrix}
          1 & 0 & 0 \\
          0 & 1 & 0 \\
          0 & 0 & 0 \\
          \end{bmatrix}\).
        Suppose that \(g = \begin{bmatrix}
          a & b & c \\
          d & e & f \\
          g & h & i \\
          \end{bmatrix}\), such that
        \[
        gxg^{-1} = \begin{bmatrix}
              1 & 0 & 0 \\
              0 & 1 & 0 \\
              0 & 0 & 0 \\
              \end{bmatrix}.
        \]
        Hence,
        \[
        \begin{align}
        \begin{bmatrix}
          a & b & c \\
          d & e & f \\
          g & h & i \\
          \end{bmatrix}\begin{bmatrix}
          1 & 0 & 0 \\
          0 & 1 & 0 \\
          0 & 0 & 0 \\
          \end{bmatrix} &= \begin{bmatrix}
          1 & 0 & 0 \\
          0 & 1 & 0 \\
          0 & 0 & 0 \\
          \end{bmatrix}\begin{bmatrix}
            a & b & c \\
            d & e & f \\
            g & h & i \\
            \end{bmatrix},\\
        \begin{bmatrix}
        a & b & 0 \\
        d & e & 0 \\
        g & h & 0 \\
        \end{bmatrix} &= \begin{bmatrix}
        a & b & c \\
        d & e & f \\
        0 & 0 & 0 \\
        \end{bmatrix}
        \end{align}.
        \]
          Then, we have
        \[
        g = \begin{bmatrix}
        a & b & 0 \\
        d & e & 0 \\
        0 & 0 & i \\
        \end{bmatrix}.
        \]
        Similarly, we have \(i\neq 0\), which implies that there are \(p - 1\) choices for \(i\).
        And the principal submatrix \(\begin{bmatrix}a & b \\ d & e\end{bmatrix}\) has to be nonsingular, which implies that there are \(p^2 - 1\) choices for \(a\) and \(d\) and \(p^2 - p\) choices for \(b\) and \(e\).
        In total, there are \((p - 1)(p^2 - 1)(p^2 - p)\) choices for \(g\).
        Hence, we have \(|C_G(x_1)| = |C_G(x_2)| = (p - 1)(p^2 - 1)(p^2 - p)\).
        And we can get the
        \[
        \begin{align}
      \text{orb}(x_0) &= 1,\\
        \text{orb}(x_1) &= \dfrac{|G|}{|C_G(x_1)|} = \frac{(p^3 - 1)(p^3 - p)(p^3 - p^2)}{(p - 1)(p^2 - 1)(p^2 - p)} = p^2(p^2 +p + 1) = p^4 + p^3 + p^2,\\
        \text{orb}(x_2) &= \dfrac{|G|}{|C_G(x_2)|} = \frac{(p^3 - 1)(p^3 - p)(p^3 - p^2)}{(p - 1)(p^2 - 1)(p^2 - p)} = p^2(p^2 +p + 1) = p^4 + p^3 + p^2,\\
        \text{orb}(x_3) &= 1.
        \end{align}
        \]
        Then, we have the number of idempotent \(3 \times 3\) matrices is \(2p^4 + 2p^3 + 2p^2 + 2\).
      </p>
    </section>

    <h2 id = 'ku_2017_8'>KU 2017 (August)</h2>
    <section id = 'ku_2017_8_6'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        \(\textbf{Problem 6. }\) Consider the matrix \( A = \begin{bmatrix}
          0 & 1 & 0 & 1 \\
          -1 & 1 & 0 & 0 \\
          -2 & 0 & -1 & -2 \\
          1 & -1 & 0 & 0 \\
          \end{bmatrix} \), with entries in \( \mathbb{C} \).
        Find \( J \), the Jordan canonical form for \( A \) and an invertible matrix \( P \) such that \( J = P^{-1}AP \).
      </p>
            </div>
        </div>
      <p>
        \(\textbf{Solution. }\)We firstly find the characteristic polynomial of \(A\).
        \[
        \chi_A(x) = x^4 -x^2 = x^2(x+1)(x-1) = (x - 0)^2(x - 1)(x + 1).
        \]
        Now we try to determine the minimal polynomial of \(A\), which leaves us two possibilities: \(x^2(x-1)(x+1)\)
        and \(x(x-1)(x+1)\).
        We plug in \(A\) to \(x(x-1)(x+1)\) and find that it is not the zero matrix. Thus, we have the minimal
        polynomial is the same as the characteristic polynomial.
        Hence, we have the Jordan canonical form of \(A\) is
        \[
        J = \begin{bmatrix}
        0 & 0 & 0 & 0 \\
        1 & 0 & 0 & 0 \\
        0 & 0 & 1 & 0 \\
        0 & 0 & 0 & -1 \\
        \end{bmatrix}.
        \]
        Now we calculate the eigenvectors of \(A\).
        Then we have the eigenvectors of \(A\) are \(v_1 = (0, 1, 1, -1)^T\) for eigenvalue \(1\),
        \(v_2 = (0, 0, 1, 0)^T\) for eigenvalue \(1\), \(v_3 = (1, 1, 0, -1)^T\) for eigenvalue \(0\).
        We need to find another column vector of \(P\). Suppose that it is \((a, b, c, d)^T\) such that
        \[
        A \begin{bmatrix}
        a \\
        b \\
        c \\
        d \\
        \end{bmatrix} = v_3 = \begin{bmatrix}
        1 \\
        1 \\
        0 \\
        -1 \\
        \end{bmatrix}.
        \]
        Then we have \((a, b, c, d)^T = (1, 2, 0, -1)^T\). Hence, we have a matrix such that
        \[
        B = \begin{bmatrix}
        1 & 1 & 0 & 0 \\
        2 & 1 & 0 & 1 \\
        0 & 0 & 1 & 1 \\
        -1 & -1 & 0 & -1 \\
        \end{bmatrix}.
        \]
        Then, we calculate the determinant of \(B\) and find that it is not zero. Hence, we have \(P = B\), where \(A =
        P^{-1}JP\).
      </p>
    </section>

    <br>


    <h2 id = 'january_2018'>KU 2018 (January)</h2>
    <section id = 'ku_2018_1_1'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
              <p>
                <b>Question 1.</b> Let \( R = \mathbb{C}[x, y, z] \) be the ring of polynomials in 3 variables over the complex numbers.
              </p>
              <p>
                (a) Show that \( I = (x, y) \) is a prime ideal in \( R \).
              </p>
              <p>
                (b) Let \( J = (x^2, y^2) \). Prove that for any collection of polynomials \( \{f_1, f_2, \ldots, f_n\} \) such that the product \( f_1 f_2 \cdots f_n \) is in \( J \), we can find a subset of at most 3 polynomials whose product is already in \( J \).
              </p>
              <p>
                (c) Let \( K = (x^2 y^2, y^2 z^2, z^2 x^2) \). Prove that for any collection of polynomials \( \{f_1, f_2, \ldots, f_n\} \) such that the product \( f_1 f_2 \cdots f_n \) is in \( K \), we can find a subset of at most 9 polynomials whose product is already in \( K \).
              </p>
            </div>
        </div>
      <p>
        <b>Proof (a).</b> We will prove that \(I\) is a prime ideal in \(R\) by contrapositive. Suppose that \(f, g\in R\) and neither \(f\) nor \(g\) is in \(I\).
        Then, we can know that \(f\) and \(g\) do not contain a term such as \(az^n\) or \(b\), where \(a, b\in \mathbb{C}\) since there is no \(h\in R\) such that \(xh = az^n\) or \(yh = az^n\) or \(xh = b\) or \(yh = b\).
        Thus, we can write \(f = f' + a_nz^n + a_{n-1}z^{n-1} + \dots + a_1z_1 + a_0\) and \(g = g' + b_mz^m + b_{m-1}z^{m-1} + \dots + b_1z_1 + b_0\), where \(f', g'\in R\).
        Then, we have
        \[
        fg = f'g' +(a_nz^n + a_{n-1}z^{n-1} + \dots + a_1z_1 + a_0)g' + (b_mz^m + b_{m-1}z^{m-1} + \dots + b_1z_1 + b_0)f' + a_nb_mz^{n+m}+ \dots + a_1b_1z^2 + a_0b_0,
        \]
        where contains some term \(az^{t}\) or \(b\).
        Thus, we can know that \(fg\notin I\). Therefore, we showed that \(I\) is a prime ideal. \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2018_1_2'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 2.</b> Consider \( G := \mathbb{Z} \times \mathbb{Z} \) regarded as an abelian group.
          </p>
          <p>
            a) Find an element \((a,b) \ne (0,0)\) such that the factor group \( G / \langle (a,b) \rangle \) is torsion free, i.e., there are no elements of finite order.
          </p>
          <p>
            b) Suppose \( a, b \in \mathbb{Z} \) are nonzero. Set \( H_1 := \langle (a,0) \rangle \) and \( H_2 := \langle (0,b) \rangle \). Prove that \( G / (H_1 \times H_2) \) is isomorphic to \( \mathbb{Z} / \langle \text{GCD}(a,b) \rangle \times \mathbb{Z} / \langle \text{LCM}(a,b) \rangle \).
          </p>
        </div>
      </div>
      <p>
        <b>Solution (a).</b> Let \((a , b) = (1, 0)\). Then we have \(G/\langle (1, 0) \rangle \cong \mathbb{Z} \times \{0\} \cong \mathbb{Z}\).
        We know that \(\mathbb{Z}\) is torsion free since there are no elements of finite order in \(\mathbb{Z}\).
      </p>
      <p>
        <b>Proof (b).</b> We want to show that \(\left\langle (a, 0), (0, b)\right\rangle = \left\langle (a, b), (0, b)\right\rangle\).
        We have \(\left\langle (a, 0), (0, b)\right\rangle \subset \left\langle (a, b), (0, b)\right\rangle\)
        since \((a, 0) + (0, b) = (a, b)\).
        And we get that \(\left\langle (a, b), (0, b)\right\rangle \subset \left\langle (a, 0), (0, b)\right\rangle\)
        since \((a, b) - (0, b) = (a, 0)\). Thus, we have \(\left\langle (a, 0), (0, b)\right\rangle = \left\langle (a, b), (0, b)\right\rangle\).
        It is not hard to see that \(\left\langle (a, b), (0, b)\right\rangle \cong \left\langle \begin{bmatrix} a \\ b \end{bmatrix}, \begin{bmatrix} 0 \\ b\end{bmatrix}\right\rangle \).
        Define \(K_A\) as the column space of \(A\) where
        \[
        A = \begin{bmatrix}
        a & 0 \\
        b & b \\
        \end{bmatrix}.
        \]
        Thus, we can know that \(K_A\cong \left\langle \begin{bmatrix} a \\ b \end{bmatrix}, \begin{bmatrix} 0 \\ b\end{bmatrix}\right\rangle \cong \langle (a, b), (0, b) \rangle\).
        We denote \(d = \gcd(a, b)\), then there exists \(x, y\in \mathbb{Z}\) such that \(d = ax + by\) according to \( \textbf{BÃ©zout's Identity}\).
        And we denote that \(a'  = a/d\in \mathbb{Z}\) and \(b' = b/d\in \mathbb{Z}\).
        We define a matrix
        \[
        P = \begin{bmatrix}
        x & y \\
        b' & -a' \\
        \end{bmatrix}.
        \]
        And \(\det(P) = -a'x - yb' = - (a/d)x - (b/d)y = -(ax + by)/d = -d/d = -1\), which implies that \(P\) is invertible.
        Hence, we can get that
        \[
        PA =
        \begin{bmatrix}
        x & y \\
        b' & -a' \\
        \end{bmatrix} \begin{bmatrix}
        a & 0 \\
        b & b \\
        \end{bmatrix} = \begin{bmatrix}
        d & by \\
        ab' - a'b & -a'b \\
        \end{bmatrix} = \begin{bmatrix}
        d & by \\
        \frac{ab}{d} - \frac{ab}{d} & -a'b \\
        \end{bmatrix} = \begin{bmatrix}
        d & by \\
        0 & -a'b \\
        \end{bmatrix}.
        \]
        Then we define \(Q\) such that
        \[
        Q = \begin{bmatrix}
        1 & -b'y \\
        0 & 1 \\
        \end{bmatrix}.
        \]
        We can see that \(Q\) is invertible since \(\det(Q) = 1\ne 0\).
        Now we have
        \[
        PAQ = \begin{bmatrix}
        d & by \\
        0 & -a'b \\
        \end{bmatrix}\cdot
        \begin{bmatrix}
        1 & -b'y \\
        0 & 1 \\
        \end{bmatrix} = \begin{bmatrix}
        d & 0 \\
        0 & a'd \\
        \end{bmatrix}.
        \]
        Now, we want to show that \(K_A = K_{PAQ}\) where \(P\) and \(Q\) are invertible.
        Given that \(K_A\) is the column space of matrix \(A\) over \(\mathbb{Z}\).
        If \(y\in K_A\), then we can know that there exists \(x\in \mathbb{Z}^2\) such that \(y = Ax\).
        Given that \(Q\) is an invertible matrix, we can know that \(y = Ax = A(Q^{-1}Q)x = (AQ)(Q^{-1}x)\), where \(Q^{-1}x\in \mathbb{Z}^2\).
        Hence, we can know that \(y\in K_{AQ}\). Thus, we have \(K_A \subseteq K_{AQ}\).
        For the other direction, we can know that if \(y\in K_{AQ}\), there exists \(x\in \mathbb{Z}^2\) such that \(y = AQx\).
        Since \(Qx\in \mathbb{Z}^2\), we can know that \(y = AQx = A(Qx)\), which implies that \(y\in K_A\) and \(K_{AQ} \subseteq K_A\).
        Thus, we can know that \(K_A = K_{AQ}\).
        Now, we want to show that \(K_A \cong K_{PA}\).
        We define a map \( \phi: K_A \to K_{PA} \) by \( \phi(x) = Px \). Since \(P\) is invertible, we can know that \( \phi \) is a bijection.
        Hence, we can know that \( K_A \cong K_{PA} \). Thus, we can know that \(K_A\cong K_{PA} = K_{PAQ}\).
        Thus, we can get
        \[
        H_1\times H_2 = \langle (a, b), (0, b)\rangle \cong K_A \cong K_{PAQ} \cong \langle (d, 0), (0, a'd)\rangle = d\mathbb{Z}\oplus a'd\mathbb{Z}.
        \]
        Since \(\{(1, 0), (0, 1)\}\) is a basis of \(G = \mathbb{Z}\times \mathbb{Z}\), we can know that \(G = \langle (1, 0), (0, 1)\rangle = \mathbb{Z}\oplus \mathbb{Z}\).
        Therefore, we have
        \[
        G/(H_1\times H_2) = \mathbb{Z}\oplus \mathbb{Z}/(d\mathbb{Z}\oplus a'd\mathbb{Z}) = \mathbb{Z}/d\mathbb{Z}\oplus \mathbb{Z}/a'd\mathbb{Z} = \mathbb{Z}/\langle \gcd(a, b)\rangle \oplus \mathbb{Z}/\langle a'b\rangle.
        \]
        Since we know that \(\gcd(a, b)\cdot \text{lcm}(a, b) = ab\), we have that \(a'b = \dfrac{ab}{d} = \text{lcm}(a, b)\).
        Then, we get
        \[
        G/(H_1\times H_2) \cong \mathbb{Z}/\langle \gcd(a, b)\rangle \oplus \mathbb{Z}/\langle \text{lcm}(a, b) \rangle \cong \mathbb{Z}/\langle \gcd(a, b)\rangle \times \mathbb{Z}/\langle \text{lcm}(a, b) \rangle. \tag*{\(\blacksquare\)}
        \]
      </p>
    </section>

    <section id = 'ku_2018_1_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 3.</b> Let the complex number \(\epsilon\) be a primitive \(5^{\text{th}}\) root of unity, i.e., \(\epsilon^5 = 1\), but \(\epsilon^j \ne 1\), for \(1 \leq j \leq 4\). Set \(F := \mathbb{Q}(\epsilon)\).
          </p>
          <p>
            a) Find \([F : \mathbb{Q}]\).
          </p>
          <p>
            b) Determine (with proof) whether or not there exists a field \(K\) such that \(\mathbb{Q} \subsetneq K \subsetneq F\).
          </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> Firstly, we know that \(x^5 - 1 = (x - 1)(x^4 + x^3 + x^2 + x + 1)\). Since \(\epsilon\) is a primitive \(5^{\text{th}}\) root of unity, we have \(\epsilon\neq 1\).
        Since \(\epsilon^5 - 1= (\epsilon - 1)(\epsilon^4 + \epsilon^3 + \epsilon^2 + \epsilon + 1) = 0 \) and \(\epsilon - 1\neq 0\), we have
        \[
        \epsilon^4 + \epsilon^3 + \epsilon^2 + \epsilon + 1 = 0.
        \]
        Now we denote \(p(x) = x^4 + x^3 + x^2 + x + 1\). We can know that \(p(\epsilon) = 0\) and we want to show that \(p(x)\) is irreducible over \(\mathbb{Q}\) by contradiction.
        Suppose that \(p(x)\) is reducible. Then we can get that
        \[
        p(x + 1) = \dfrac{(x + 1)^5 - 1}{x + 1 - 1} = \dfrac{x^5 + 5x^4 + 10x^3 + 10x^2 + 5x + 1 - 1}{x} = x^4 + 5x^3 + 10x^2 + 10x + 5.
        \]
        According to the \(\textbf{Eisenstein's Criterion}\), we can know that \(p(x + 1)\) is irreducible.
        If \(p(x)\) is reducible, then we can have \(p(x) = f(x)g(x)\) where \(f(x), g(x)\in \mathbb{Q}[x]\) and \(f(x)\) and \(g(x)\) are non-constant.
        Hence, we can have \(p(x + 1) = f(x + 1)g(x + 1)\), which implies that \(p(x+1)\) is reducible. Hence, it is a contradiction.
        Now, we have shown that \(p(x) = x^4 + x^3 + x^2 + x +1 \) is irreducible and \(\epsilon\) is a root of \(p(x)\). It means that \(p(x)\) is a minimal polynomial of \(\epsilon\).
        And we can have \([F : \mathbb{Q}] = [\mathbb{Q}(\epsilon) : \mathbb{Q}] = \text{deg}(p(x)) = 4\).
      </p>
      <p>
          <b>Solution (b).</b> Since we know that \(\epsilon\) is a primitive \(5^{\text{th}}\) root of unity, we can know that \(\epsilon, \epsilon^2, \epsilon^3, \epsilon^4, 1\) are the roots of \(x^5 - 1\).
          However, none of elements of \(\{\epsilon^2, \epsilon^3, \epsilon^4\}\) is a root of \(x - 1\). We can know that \(\epsilon^2, \epsilon^3, \epsilon^4\) are roots of \(p(x)\).
          It is not hard to see that \(\{\epsilon^2, \epsilon^3, \epsilon^4\}\subset \mathbb{Q}(\epsilon)\), which implies that \(\mathbb{Q}(\epsilon)\) is a splitting field of \(p(x)\).
          Again, since \(\epsilon\) is the \(5^{\text{th}}\) root of unity, \(\epsilon^2, \epsilon^3, \epsilon^4\) are all different, which implies that \(p(x)\) is separable.
          Thus, we can know that \(\mathbb{Q}(\epsilon)\) is galois and \(|\text{Gal}(\mathbb{Q}(\epsilon)/\mathbb{Q})| = [\mathbb{Q}(\epsilon): \mathbb{Q}] = 4\).
          Since \(\text{Gal}(\mathbb{Q}(\epsilon)/\mathbb{Q})\) is a group of order \(4\), and all groups of order \(4\) are either isomorphic to \(\mathbb{Z}/4\mathbb{Z}\) or \(\mathbb{Z}/2\mathbb{Z}\times \mathbb{Z}/2\mathbb{Z}\).
          Since both of them have subgroups of order \(2\), according to \(\textbf{Galois Correspondence Theorem}\), there exists a Intermediate Field \(K\) such that \([F : K] = 2\).
          Then, we can know that \([F : K][K : \mathbb{q}] = 2[K : \mathbb{Q}] = 4\) and \([K : \mathbb{q}] = 2\). Since we can know that \([F : K]\neq 1\) and \([K: \mathbb{Q}]\neq 1\), we know that \(F\neq K\) and \(K\neq \mathbb{Q}\).
          Therefore, there exists a \(K\) such that \(\mathbb{Q} \subsetneq K \subsetneq F\).
      </p>
    </section>


    <section id = 'ku_2018_1_4'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 4.</b> 1. Let \( V \) be a finite dimensional vector space over a field \( F \) and \( T : V \to V \) be a linear transformation.
            Let \( F[T] \) denote the ring of all linear transformations on \( V \) that can be expressed as a polynomial in \( T \).
            Assume that no nonzero subspace of \( V \) is mapped into itself by \( T \).
          </p>
          <p>
            (a) If \( 0 \ne S \in F[T] \), show that the null space of \( S \) is zero.
          </p>
          <p>
            (b) Prove that \( F[T] \) is a field.
          </p>
          <p>
            (c) Show that \([F[T] : F]\), the degree of \( F[T] \) over \( F \), equals \(\dim_F(V)\).
          </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> We will prove that the null space of \(S\) is zero by contradiction.
        Since \(T\) does not map nonzero subspace of \(V\) into itself, we can know that there are only two \(T\)-invariant subspaces of \(V\): \(\{0\}\) and \(V\).
        Hence, we can know that \(T\) is an irreducible operator. If \(T\) is an irreducible operator, then we can know that the minimal polynomial of \(T\) is irreducible and \(T\) is cyclic.
        It means that \(V = \langle T, v\rangle\) for some \(v\in V\).
        Firstly, we can know that all polynomials in \(F[T]\) has degree at most \(n\).
        Suppose that \(\text{Null}(S) \ne \{0\}\). Then, we can find a nonzero vector \(v\in V\) such that \(Sv = 0\).
        And we have \(\text{Null}(S) = \{0, v_1, v_2, \dots \}\). (to be continued ...)
      </p>
      <p>
        <b>Proof (b).</b> Since we know that if \(S\in F[T]\) is not zero, then its null space is \(\{0\}\).
        Hence, we can know that \(S\) is invertible. Thus, we can know that for any \(S\neq 0\in F[T]\), \(S^{-1}\) exists.
        Thus, we can know that \(F[T]\) is a field. \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2018_1_5'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 5.</b> Let \( V \) be the vector space of all polynomials of degree at most 3 over the complex numbers and \( T: V \to V \) be the linear transformation \( T(f) = f + f'' \).
            Describe, with proof, the Jordan Canonical Form of \( T \).
          </p>
        </div>
      </div>
      <p>
        Let \(V = \{ax^3 + bx^2 + cx + d\, \mid\, a, b, c, d\in\mathbb{C}\}\). We can know that \(V\cong \mathbb{C}^4\).
        Let \(f(x)\in V\) such that \(f(x) = ax^3 + bx^2 + cx + d\). We have \(f'(x) = 0x^3 + 3ax^2 + 2bx + c\) and \(f''(x) = 0x^3 + 0x^2 + 6ax + 2b\).
        Since \(T(f(x)) = f(x) + f''(x)\), we have \(f(ax^3 + bx^2 + cx + d) = ax^3 + bx^2 + (6a + c)x + (2b + d)\).
        Hence, we have
        \[
        \begin{align}
        T(\vec{e_1}) &= \vec{e_1} + 6\vec{e_3} \\
        T(\vec{e_2}) &= \vec{e_2} + 2\vec{e_4} \\
        T(\vec{e_3}) &= \vec{e_3} \\
        T(\vec{e_4}) &= \vec{e_4} \\
        \end{align}
        \]
        Thus, we can know that
        \[
        T_{\mathbb{C}^4\to\mathbb{C}^4} = A = \begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        6 & 0 & 1 & 0 \\
        0 & 2 & 0 & 1 \\
        \end{bmatrix}.
        \]
        Hence, we can know that the characteristic polynomial of \(T\) is \((x - 1)^4\) and its minimal polynomial \(\mu_A(x)\mid (x - 1)^4\).
        It is not hard to see that \(A - I\neq 0\). Through calculation, we have \((A - I)^2 = 0\). Hence, \(\mu_A(x) = (x - 1)^2\) and \(\ker((A - I)^2) = \mathbb{C}^4\).
        Then, we try to find the eigenvectors of \(A\). Let \(v\) be the eigenvector \(\begin{bmatrix}a \\ b \\ c \\ d\end{bmatrix}\) such that \((A - I)v = 0\).
        \[
        \begin{align}
        \begin{bmatrix}
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        6 & 0 & 0 & 0 \\
        0 & 2 & 0 & 0 \\
        \end{bmatrix}\begin{bmatrix}
        a \\ b \\ c \\ d
        \end{bmatrix} &= \begin{bmatrix}
        0 \\ 0 \\ 0 \\ 0
        \end{bmatrix} \\
        \begin{bmatrix}
        0 \\ 0 \\ 6a \\ 2b
        \end{bmatrix} &= \begin{bmatrix}
        0 \\ 0 \\ 0 \\ 0
        \end{bmatrix}.
        \end{align}
        \]
      </p>
      Hence, we can know that \(a = b = 0\), then we can know that the \(\ker(A - I) = \text{Span}(\vec{e_3}, \vec{e_4})\), which means that \(\dim\ker(A - I) = 2\).
      Then, we can know that the number of the Jordan block is \(\dim(\ker(A - I)^2) - \dim(\ker(A - I)) = 4 - 2 = 2\).
      Hence, we have the Jordan Canonical Form of \(A\) as
      \[
      J_A = \begin{bmatrix}
        1 & 1 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        0 & 0 & 1 & 1 \\
        0 & 0 & 0 & 1 \\
        \end{bmatrix}.
        \]
      Now, we want to find \(P\in \mathbb{C}^{4\times 4}\) such that \(P^{-1}AP = J_A\).
      Suppose that \(P = [\vec{v_1}, \vec{v_2}, \vec{v_3}, \vec{v_4}]\), where each \(\vec{v_i} = \begin{bmatrix}a_i \\ b_i \\ c_i \\ d_i\end{bmatrix}\).
      Then, we have
      \[
        \begin{align}
        AP &= PJ_A \\
        A[\vec{v_1}, \vec{v_2}, \vec{v_3}, \vec{v_4}] &= [\vec{v_1}, \vec{v_2}, \vec{v_3}, \vec{v_4}]J_A \\
        \begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        6 & 0 & 1 & 0 \\
        0 & 2 & 0 & 1 \\
        \end{bmatrix}\begin{bmatrix}
        a_1 & a_2 & a_3 & a_4 \\
        b_1 & b_2 & b_3 & b_4 \\
        c_1 & c_2 & c_3 & c_4 \\
        d_1 & d_2 & d_3 & d_4 \\
        \end{bmatrix} &= \begin{bmatrix}
      a_1 & a_2 & a_3 & a_4 \\
      b_1 & b_2 & b_3 & b_4 \\
      c_1 & c_2 & c_3 & c_4 \\
      d_1 & d_2 & d_3 & d_4 \\
      \end{bmatrix}\begin{bmatrix}
        1 & 1 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        0 & 0 & 1 & 1 \\
        0 & 0 & 0 & 1 \\
        \end{bmatrix}.
        \end{align}
        \]
        Then, let \(\vec{v_1} = \vec{e_3}\) and \(\vec{v_3} = \vec{e_4}\). Then, we have
      \[
      P = \begin{bmatrix}
        0 & a_2 & 0 & a_4 \\
        0 & b_2 & 0 & b_4 \\
        1 & c_2 & 0 & c_4 \\
        0 & d_2 & 1 & d_4 \\
        \end{bmatrix}.
        \]
      Since \(A\vec{v_2} = \vec{v_1} + \vec{v_2} = \vec{e_3} + \vec{v_2}\), and
      \[
      A\cdot \vec{v_2}
        = \begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        6 & 0 & 1 & 0 \\
        0 & 2 & 0 & 1 \\
        \end{bmatrix}\begin{bmatrix}
        a_2 \\ b_2 \\ c_2 \\ d_2
        \end{bmatrix} = \begin{bmatrix}
        a_2 \\ b_2 \\ 6a_2 + c_2 \\ 2b_2 + d_2
        \end{bmatrix} = \begin{bmatrix}
        a_2 \\ b_2 \\ 1 + c_2 \\ d_2
      \end{bmatrix}.
      \]
      Then, we have \(a_2 = \frac16\) and \(b_2 = 0\). Hence, we let \(\vec{v_2} = \begin{bmatrix}1/6 \\ 0 \\ 0 \\ 0\end{bmatrix}\).
      Similarly, we have \(A\cdot \vec{v_4} = \vec{v_3} + \vec{v_4}\), and
        \[
        A\cdot \vec{v_4}
          = \begin{bmatrix}
          1 & 0 & 0 & 0 \\
          0 & 1 & 0 & 0 \\
          6 & 0 & 1 & 0 \\
          0 & 2 & 0 & 1 \\
          \end{bmatrix}\begin{bmatrix}
          a_4 \\ b_4 \\ c_4 \\ d_4
          \end{bmatrix} = \begin{bmatrix}
          a_4 \\ b_4 \\ 6a_4 + c_4 \\ 2b_4 + d_4
          \end{bmatrix} = \begin{bmatrix}
          a_4 \\ b_4 \\ c_4 \\ 1 + d_4
        \end{bmatrix}.
        \]
        Then, we have \(a_4 = 0\) and \(b_4 = \frac12\). Hence, we let \(\vec{v_4} = \begin{bmatrix}0 \\ \frac{1}{2} \\ 0 \\ 0\end{bmatrix}\).
      Thus, we have
      \[
      P = \begin{bmatrix}
        0 & 1/6 & 0 & 0 \\
        0 & 0 & 0 & 1/2 \\
        1 & 0 & 0 & 0 \\
        0 & 0 & 1 & 0 \\
        \end{bmatrix},
        \]
      which is non-singular. Hence, we have \(P^{-1}AP = J_A\).
    </section>

    <h2 id = 'august_2018'>KU 2018 (August)</h2>

    <section id = 'ku_2018_8_2'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>2.</b> For each of the following, provide a proof if the statement is correct or provide a counter-example or justification, if the statement is false.
            <p>
            <b>(a)</b> Let \( A \) denote the ring of continuous real-valued functions on the open unit interval \( (0, 1) \). For \( 0 < \alpha < 1 \), let \( I_\alpha = \{ f \in A \mid f(\alpha) = 0 \} \).
            </p>
            <ul>
              <li>
                (i) Is \( I_\alpha \) a maximal ideal?
              </li>
                <li>
                    (ii) Is \( I_{1/2} \cap I_{\pi/4} \) a prime ideal?
                </li>
                <li>
                    (iii) Is \( (0) \) a prime ideal?
                </li>
            </ul>
            <p>
            (b) Is the ideal \( \langle 2, x^2 + x + 1 \rangle \) in \( \mathbb{Z}[x] \) a maximal ideal?
              </p>
          <p>
            (c) Is the ideal generated by the class of \( x \) in the quotient ring \( \mathbb{C}[x, y] / \langle xy \rangle \) prime?
          </p>
        </div>
      </div>
      <p>
        <b>Solution (ii).</b> \(I_{1/2} \cap I_{\pi/4} = \{ f \in A \mid f(1/2) = 0 \text{ and } f(\pi/4) = 0 \}\), which is not a prime ideal.
        Let
        \[
        \begin{align}
        f(x) &= |x - 1/2|, \\
        g(x) &= |x - \pi/4|.
        \end{align}
        \]
        Thus, we can know that both \(f(x)\) and \(g(x)\) are continuous real function and
        Hence, we can know that \(f(x)\cdot g(x)\in I_{1/2} \cap I_{\pi/4}\), but \(f(x)\) and \(g(x)\) are not in \(I_{1/2}\cap I_{\pi/4}\).
      </p>
      <p>
        <b>Solution (b).</b> \(\langle 2, x^2 + x + 1 \rangle\) is a maximal ideal.
      </p>
      <p>
      <b>Proof.</b>Since \(\mathbb{Z}[x]\) has division algorithm, we can know if \(p(x)\in \mathbb{Z}[x]\), then we have
      \[
      p(x) = q(x)(x^2 + x + 1) + r(x), \text{ where } \deg(r(x)) < \deg(x^2 + x + 1).
      \]
      In other words, \(r(x) = ax + b\), where \(a, b\in \mathbb{Z}\).
      Since \(2\in \langle 2, x^2 + x + 1\rangle\), we can know that \(r(x) = ax + b\) only has three possibilities: \(r(x) = 0, r(x) = x, r(x) = 1, r(x) = x+1\).
      Thus, we have
      \[
      \mathbb{Z}[x]/\langle 2, x^2 + x + 1\rangle = \{0, 1, x, x + 1\}.
      \]
      And \(x(x + 1) = x^2 + x = -1 = 1\), which implies that \(x\) and \(x + 1\) are units.
      Thus, we can see that \(\langle 2, x^2 + x + 1\rangle\) is a maximal ideal. \(\blacksquare\)
      </p>
      <p>
        <b>Solution (c).</b> The ideal generated by the class of \(x\) in the quotient ring \(\mathbb{C}[x, y]/\langle xy\rangle\) is a prime ideal.
      </p>
      <p>
        <b>Proof.</b> We can know that \(\mathbb{C}[x, y]/\langle xy\rangle = \{a_nx^n + \dots + a_1x + b_my^m + \dots + b_1y + c + \langle xy\rangle \mid a_i, b_j, c\in \mathbb{C}\}\).
        For \(\langle x\rangle\subset \mathbb{C}[x, y]/\langle xy\rangle\), we have
        \[
        \begin{align}
        \langle x \rangle + \langle xy \rangle &= \{x(a_nx^n + \dots + a_1x + b_my^m + \dots + b_1y + c) + \langle xy\rangle \mid a_i, b_j, c\in \mathbb{C}\}, \\
        &= \{a_nx^{n+1} + \dots + a_1x^2 + b_my^mx + \dots + b_1yx + cx + \langle xy\rangle \mid a_i, b_j, c\in \mathbb{C}\}, \\
        &= \{a_nx^{n+1} + \dots + a_1x^2 + cx + \langle xy\rangle \mid a_i, c\in \mathbb{C}\}, \\
        &= \{a_nx^{n} + \dots + a_1x + \langle xy\rangle \mid a_i\in \mathbb{C}\}.
        \end{align}
        \]
        Then, we denote \(R = \mathbb{C}[x, y]/\langle xy\rangle\).
        Thus, we have
        \[
        R/\langle x\rangle = \{b_my^m + b_{m-1}y^{m-1} + \dots b_1y + b_0 + \langle xy\rangle \mid b_i\in \mathbb{C}\} \cong \mathbb{C}[y].
        \]
        Since \(\mathbb{C}[y]\) is a PID, which is an integral domain. Hence, we can know that \(\langle x\rangle\) is a prime ideal.
      </p>
    </section>

    <br>

    <section id = 'ku_2018_8_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>3.</b> Let \( F = \mathbb{Z}/2\mathbb{Z} \) denote the field with two elements and set \( f(x) = x^5 + x^2 + 1 \in F[x] \).
          </p>
          <p>
            (a) Show that \( f(x) \) is irreducible over \( F \).
          </p>
          <p>
            (b) Let \( \alpha \) be a root of \( f(x) \) in some larger field. Express the element \( \alpha \cdot (\alpha^4 + \alpha + 1)^{-1} \) in \( F(\alpha) \) as a polynomial in \( \alpha \) over \( F \) of minimal degree.
          </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> We will show that \(f(x)\) is irreducible over \(F\) by contradiction. Suppose that \(f(x)\) is reducible over \(F\).
        Then we have two possibilities:
        \[
        \begin{align}
        f(x) &= (x + a)(x^4 + bx^3 + cx^2 + dx + e),\\
        f(x) &= (x^2 + ax + b)(x^3 + cx^2 + dx + e).\\
        \end{align}
        \]
        For the first case, we can know that \(f(x)\) has a root in \(\mathbb{Z}/2\mathbb{Z}\).
        However, \(f(0) = 0^5 + 0^2 + 1 = 1\) and \(f(1) = 1^5 + 1^2 + 1 = 1\), which implies that \(f(x)\) has no root in \(\mathbb{Z}/2\mathbb{Z}\).
        Hence, it leaves us with the second case.
        Then we have
        \[
        \begin{align}
        f(x) &= (x^2 + ax + b)(x^3 + cx^2 + dx + e)\\
        &= x^5 + (a + c)x^4 + (b + ac + d)x^3 + (ad + bc + e)x^2 + (ae + bd)x + be.
        &= x^5 + x^2 + 1.
        \end{align}
        \]
        Then we have
        \[
        \begin{align}
        be &= 1, \\
        ae + bd &= 0, \\
        ad + bc + e &= 1, \\
        b + ac + d &= 0, \\
        a + c &= 0.
        \end{align}
        \]
        Since \(be = 1\), we can have \(b = e = 1\). Then we rewrite the above equations as
        \[
        \begin{align}
        a + c &= 0, \\
        1 + ac +d &= 0, \\
        ad + c + 1 &= 1, \\
        a + d &= 0.
        \end{align}
        \]
        Since \(a + c = 0\) and \(a, c\in \mathbb{Z}/2\mathbb{Z}\), we can know that \(a = e\). By the similar reason, since \(a + d = 0\), we have \(a = d\).
        Now, we can know that \(a = c = d\), and we replace \(c\) and \(d\) with \(a\) and get
        \[
        \begin{align}
        1 + a^2 + a &= 0, \\
        a^2 + a + 1 &= 1. \\
        \end{align}
        \]
        Now, we see that \(a^2 + a + 1 \neq a^2 + a + 1\), which is a contradiction. Therefore, we can conclude that \(f(x)\) is irreducible over \(F\). \(\blacksquare\)
      </p>
      <p>
      <b>Solution (b).</b> Firstly, we know that \(\alpha^5 + \alpha^2 + 1 = 0\). Hence, we have
      \[
      \begin{align}
      \alpha^5 + \alpha^2 &= -1 = 1, \\
      \alpha(\alpha^4 + \alpha) &= 1. \\
      \end{align}
      \]
      Thus, we can \(\alpha^{-1} = \alpha^4 + \alpha\). Meanwhile, we have
      \[
        \begin{align}
        \alpha^5 + \alpha^2 + \alpha + 1 &= \alpha \\
        \alpha^5 + \alpha^2 + \alpha &= \alpha  - 1 = \alpha + 1 \\
        \alpha(\alpha^4 + \alpha + 1) &= \alpha + 1 \\
        (\alpha^4 + \alpha + 1) &= \dfrac{\alpha + 1}{\alpha} \\
        (\alpha^4 + \alpha + 1)^{-1} &= \dfrac{\alpha}{\alpha + 1} = \alpha(\alpha + 1)^{-1} \\
        \end{align}
      \]
      It shows that we need to find \(\alpha(\alpha + 1)^{-1}\). Given that
      \[
      \begin{align}
      (\alpha + 1)(\alpha + 1) &= \alpha^2 + 2\alpha + 1 = \alpha^2 + 1 = \alpha^5 \\
      (\alpha + 1)\dfrac{\alpha + 1}{\alpha^5} &= (\alpha + 1)(\alpha + 1)(\alpha^5)^{-1} = 1.
      \end{align}
      \]
      Since we know that \(\alpha^{-1} = \alpha^4 + \alpha\), we have
      \[
      \begin{align}
      (\alpha^5)^{-1} &= (\alpha^{-1})^{5} \\
        &= (\alpha^4 + \alpha)^5 = \alpha^5(\alpha^3 + 1)^5 = (\alpha^2 + 1)\cdot (\alpha^3 + 1)^4\cdot (\alpha^3 + 1) \\
        &= (\alpha^2 + 1)(\alpha^3 + 1)(\alpha^3 + 1)^2(\alpha^3 + 1)^2 \\
        &= (\alpha^5 + \alpha^2 + \alpha^3 + 1)(\alpha^6 + 1)^2 \\
        &= (\alpha^3)(\alpha^{12} + 1) \\
        &= \alpha^3(\alpha^5\cdot \alpha^5\cdot \alpha^2 + 1) \\
        &= \alpha^3((\alpha^2 + 1)^2\cdot \alpha^2 + 1) \\
        &= \alpha^3(\alpha^6 + \alpha^2 + 1) \\
        &= \alpha^3(\alpha\cdot \alpha^5 + \alpha^2 + 1) \\
        &= \alpha^3(\alpha(\alpha^2 + 1) + \alpha^2 + 1) \\
        &= \alpha^3(\alpha^3 + \alpha^2 + \alpha + 1) \\
        &= \alpha^6 + \alpha^5 + \alpha^4 + \alpha^3 \\
        &= \alpha(\alpha^2 + 1) + \alpha^2 + 1 + \alpha^4 + \alpha^3 \\
        &= \alpha^3 + \alpha^2 + \alpha + 1 + \alpha^4 + \alpha^3 \\
        &= \alpha^4 + \alpha^2 + \alpha + 1 \\
        \end{align}
      \]
      Thus, we can know that
      \[
      \begin{align}
      (\alpha + 1)\cdot(\alpha^5)^{-1} &= (\alpha + 1)\cdot (\alpha^4 + \alpha^2 + \alpha + 1) \\
      &= \alpha^5 + \alpha^3 + \alpha^2 + \alpha + \alpha^4 + \alpha^2 + \alpha + 1 \\
      &= \alpha^4 + \alpha^3 + \alpha^2.
      \end{align}
      \]
      Hence, the inverse of \(\alpha + 1\) is \(\alpha^4 + \alpha^3 + \alpha^2 \).
      Now, we can know that
      \[
      \begin{align}
      (\alpha^4 + \alpha + 1)^{-1} &= \alpha(\alpha + 1)^{-1} = \alpha(\alpha^4 + \alpha^3 + \alpha^2) = \alpha^5 + \alpha^4 + \alpha^3 = \alpha^4 + \alpha^3 + \alpha^2 + 1.\\
      \alpha(\alpha^4 + \alpha + 1)^{-1} &= \alpha(\alpha^4 + \alpha^3 + \alpha^2 + 1) = \alpha^5 + \alpha^4 + \alpha^3 + \alpha = \alpha^4 + \alpha^3 + \alpha^2 + \alpha + 1. \\
      \end{align}
      \]
      </p>
    </section>

    <br>

    <section id = 'ku_2018_8_4'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>4.</b> Let \( p > 0 \) be a prime number and set \( F := \mathbb{Z}/p\mathbb{Z} \), the field with \( p \) elements. Find the number of \( 2 \times 2 \) matrices with entries in \( F \) such that \( A^2 = I \).
      </p>
            </div>
        </div>
      <p>
      <b>Solution.</b>  Given that \(A^2 = I\), we have \(A^2 - I = 0\). Hence, we set \(f(x) = x^2 - 1 = (x - 1)(x + 1)\). Then, we have \(f(A) = 0\).
      Thus, we can know that the minimal polynomial of \(A\), \(\mu_A(x)\), divides \(f(x)\). Hence, we have three possibilities: \(x - 1\) or \(x + 1\) or \(f(x)\).
      If the minimal polynomial of \(A\) is \(x - 1\), then we can have \(A - I = 0\), which means that \(A = I\).
      If the minimal polynomial of \(A\) is \(x + 1\), then we can have \(A + I = 0\), which means that \(A = -I = (p - 1)I\).
      If \(p = 2\), then we can know that \(A = I\) is the solution for both case where \(\mu_A(x) = x - 1\) and \(\mu_A(x) = x + 1\).
        If \(\mu_A(x) = (x - 1)(x + 1)\), then we can know that \(\gcd(x - 1, x + 1) = 1\), when \(p>2\).
        Hence, we can have two eigenvalues, which are \(1\) and \(p - 1\). And \(F^2 = \ker(A - I) \oplus \ker(A + I)\).
        Then, we can know that \(A\) is diagonalizable over \(F\). Thus, we can write \(A = PDP^{-1}\), where
        \[
        D = \begin{bmatrix}
        1 & 0 \\
        0 & p - 1 \\
        \end{bmatrix}.
        \]
        And \(P\) is an invertible matrix with entries in \(F\). Denote \(P = [\vec{v_1}, \vec{v_2}]\), where \(\vec{v_1}\) and \(\vec{v_2}\) are the eigenvectors of \(A\).
        Besides, that \(\vec{v_1}, \vec{v_2}\) should be independent. Hence, for \(\vec{v_1}\in F^2\), we can know that it cannot be \(0\). Thus, there are \(p^2 - 1\) choices for \(\vec{v_1}\).
        For \(\vec{v_2}\in F^2\), we can know that it cannot be a multiple of \(\vec{v_1}\). Hence, there are \(p^2 - p\) choices for \(\vec{v_2}\).
        Then, we will have \((p^2 - 1)(p^2 - p)\) choices for \(P\). Hence, the number of \(2 \times 2\) matrices with entries in \(F\) such that \(A^2 = I\) is \(2 + (p^2 - 1)(p^2 - p)\) when \(p > 2\).
        When \(p=2\), there is only one matrix, which is the identity one.
      </p>

    </section>

    <h2 id = 'january_2019'>KU 2019 (January)</h2>

    <section id = 'ku_2019_1_2'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
                <p>
                    <b>2.</b> Let \( R \) denote the ring \( \mathbb{C}[t, t^{-1}] \) of Laurent polynomials over \( \mathbb{C} \).
                </p>
                <p>
                    (i) Give a rigorous proof that \( R \) is isomorphic to \( \mathbb{C}[x, y]/(xy - 1) \).
                </p>
                <p>
                    (ii) Show that every ideal in \( R \) is a principal ideal.
                </p>
                <p>
                    (iii) Give an example (with proof) of a non-zero prime ideal in \( R \).
                </p>
            </div>
        </div>
        <p>
            <b>Proof (i).</b> Firstly, we want to define a map \(\varphi: \mathbb{C}[x, y]\to \mathbb{C}[t, t^{-1}]\) such that
            \[
            \varphi(f(x, y)) = f(t, t^{-1}).
            \]
            Hence, we want to show tht \(\varphi\) is a ring homomorphism. Firstly, we can know that \(\varphi\) is well-define since if \(g(x, y) = h(x, y)\). then we will have \(g(t, t^{-1}) = h(t, t^{-1})\).
            Then, we can know that \(\varphi\) is a ring homomorphism since
            \[
            \begin{align}
                \varphi(g(x, y) + h(x, y)) &= g(t, t^{-1}) + h(t, t^{-1}) = \varphi(g(x, y)) + \varphi(h(x, y)), \\
                \varphi(g(x, y)h(x, y)) &= g(t, t^{-1})h(t, t^{-1}) = \varphi(g(x, y))\varphi(h(x, y)).
            \end{align}
            \]
            For any \(f(t, t^{-1})\in \mathbb{C}[t, t^{-1}]\), we can know that
            \[
                f(t, t^{-1}) = \sum_{i = -n}^{m} a_i t^i,\text{ where }n, m\in \mathbb{N}.
            \]
            In general, lets assume that \(n\neq 0\). Then, we can get that
            \[
            \begin{align}
                f(t, t^{-1}) &= \sum_{i = -n}^{m} a_i t^i = a_{-n}t^{-n} + \dots + a_{-1}t^{-1} + a_0 + a_1t + \dots + a_m t^m, \\
                &= a_{-n}(t^{-1})^n + a_{-n+1}(t^{-1})^{n-1} + \dots + a_{-1}t^{-1} + a_0 + a_1t + \dots + a_m t^m, \\
            \end{align}
            \]
            Then, we can see that when
            \[
            f(x, y)= a_{-n}(y)^n + a_{-n+1}(y)^{n-1} + \dots + a_{-1}y + a_0 + a_1x + \dots + a_m x^m, \\
            \]
            we have
            \[
            \varphi(f(x, y)) = f(t, t^{-1}).
            \]
            It shows that \(\varphi\) is surjective.
            Now, we want to show that \(\ker(\varphi) = (xy - 1)\).
            Suppose that \(f(x,y)\in (xy - 1)\), then \(f(x, y) = g(x, y)(xy - 1)\) for some \(g(x, y)\in \mathbb{C}[x, y]\). Then, we can know that
            \[
            \varphi(f(x, y)) = f(t, t^{-1}) = g(t, t^{-1})(t\cdot t^{-1} - 1) = g(t, t^{-1})(1 - 1) = 0.
            \]
            Thus, we showed that \((xy - 1)\subset \ker(\varphi)\).
            Suppose that \(f(x, y)\neq 0\) and \(f(x, y)\in \ker(\varphi)\).
        </p>

    </section>

    <section id = 'ku_2019_1_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
          <b>3.</b> Consider a field \( K \), and an irreducible polynomial \( f(x) \in K[x] \).
          Prove that if \( L \) is a field extension of \( K \) such that \([L : K] \) is relatively prime to the degree of \( f(x) \), then \( f(x) \) remains irreducible in \( L[x] \).
        </p>
        </div>
      </div>
      <p>
        <b>Proof.</b> Suppose that \( [L : K] = m \) and \(f(x)\) is an irreducible polynomial over \(K\) where its degree is \(n\) and \(\gcd(n, m) = 1\).
      Suppose that \(\alpha\) is a root of \(f(x)\) in \(L\). Then, we can know that \(f(x)\) is a minimal polynomial of \(\alpha\).
      And \(K(\alpha) = K[x]/(f(x))\) is a field extension of \(K\), which has degree of \(n\) (i.e. \( [K(\alpha) : K] = n \)) since the minimal polynomial of \(\alpha\) is \(f(x)\), which has degree of \(n\).
      Since \(L\) is an extension of \(K\), if \(f(x)\) is irreducible in \(L[x]\), then we have \( [L(\alpha) : L] = n \).
      If \(f(x)\) is reducible in \(L[x]\), then we have \( [L(\alpha) : L] < n \). In general we have \( [L(\alpha) : L] \leq n \).
      According to \(\textbf{Tower Theorem}\), we have
      \[
      [L(\alpha) : K] = [L(\alpha) : L][L : K] \leq n \cdot m.
      \]
        Now, for the other direction, we want to show that \([L(\alpha) : K]\geq mn\).
        Firstly, we have \([L(\alpha) : K] = [L(\alpha) : L][L : K]\), which implies that \(m = [L : K] \mid [L(\alpha) : K]\).
        Secondly, since \(L\) is an extension of \(K\), we can know that \(L(\alpha)\) is an extension of \(K(\alpha)\). Hence, we have
        \( [L(\alpha) : K] = [L(\alpha) : K(\alpha)][K(\alpha) : K]\), which implies that \(n = [K(\alpha) : K] \mid [L(\alpha) : K]\).
        Since \(\gcd(m, n)\cdot \text{lcm}(m, n) = mn\) and \(\gcd(m, n) = 1\), we can know that \(\text{lcm(m, n) = mn}\).
        Since \(n\mid [L(\alpha) : K]\) and \(m \mid [L(\alpha) : K]\), we can know that \([L(\alpha) : K]\) is the common multiple of \(m\) and \(n\) and \(mn \mid [L(\alpha) : K]\), which implies that \(mn \leq [L(\alpha) : K]\).
        Thus, we showed that
        \[
        [L(\alpha) : K] = mn.
        \]
        Since \([L(\alpha) : K] = [L(\alpha) : L][L : K] = [L(\alpha) : L]\cdot m = mn\), we can know that \([L(\alpha) : L] = n\).
        In that case, we can know that the minimal polynomial of \(\alpha\) over \(L\) has degree of \(n\), which is \(f(x)\).
        Since \(f(x)\) is the minimal polynomial of \(\alpha\) over \(L\), we can know that \(f(x)\) is irreducible in \(L[x]\). \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2019_1_6'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>6.</b> Let \( V \) be a finite dimensional vector space over the field \( F \) and suppose \( T : V \rightarrow V \) is a linear operator on \( V \).
      </p>
      <ul>
        <li>
          (i) Prove that if the minimal polynomial of \( T \) is \( x^2 - x \), then the kernel of \( T \) has a \( T \)-invariant complement.
        </li>
        <li>
          (ii) Give an example where \( V \) has a proper \( T \)-invariant subspace \( W \) such that \( W \) does not have a \( T \)-invariant complement.
        </li>
        <li>
          (iii) If \( V = \mathbb{R}^4 \), give an example where \( T \) has only finitely many \( T \)-invariant subspaces. Hint: It may be useful to consider the case that \( T \) is a normal operator on \( \mathbb{R}^4 \).
        </li>
      </ul>
            </div>
        </div>
      <p>
        <b>Proof (i).</b>
        Since \(\mu_T(x) = x^2 - x = x(x - 1)\), then we can know that
        \[
          V = \ker(T) \oplus \ker(T - I),
        \]
        where \(\ker(T)\) and \(\ker(T - I)\) are \(T\)-invariant subspaces.
        Thus, we can see that \(\ker(T-I)\) is a \(T\)-invariant complement of \(\ker(T)\).
      </p>
    </section>

    <br>


    <h2 id = 'august_2019'>KU 2019 (August)</h2>
    <section id = 'ku_2019_8_2'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Problem 2.</b> Let \(V\) be a finite dimensional vector space over the complex numbers and \(T\) a linear operator on \(V\) such that the subspaces of \(V\) generated by all the eigenvectors is one dimensional.
        Prove that the minimal polynomial of \(T\) is \((x âˆ’ \lambda)^n\) where \(n\) is the dimension of \(V\) .
      </p>
            </div>
        </div>
      <p>
        <b>Proof.</b> Given that the subspaces of \(V\) generated by all the eigenvectors is one dimensional, we can know that the basis of the subspace is \(\{v\}\), where \(v\) is the eigenvector of \(T\).
        Then we have \(T(v) = \lambda v\), where \(\lambda\) is the correspondent eigenvalue of \(v\). Hence, if \(v'\) is an eigenvector of \(T\). Then, we can know that \(v' = cv\) for some \(c\in\mathbb{C}\).
        Hence, we have
        \[
          T\cdot v' = T\cdot cv = cT\cdot v = c\lambda v = \lambda cv = \lambda v'.
        \]
        Thus, we show that there is only one eigenvalue of \(T\), which is \(\lambda\).
        Then, we can know that the characteristic polynomial of \(T\) is \((x - \lambda)^n\), where \(n\) is the dimension of \(V\).
        In that case, the minimal polynomial of \(T\) is \((x - \lambda)^m\), where \(m\leq n\) (to be continued...)
      </p>
    </section>

    <section id = 'ku_2019_8_5'>
        <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
            <b>5.</b> Consider the ring \(R = \mathbb{Q}[x, y, z]/I\), where \(I = (x^2y - z^5)\).
        </p>
        <p>
            (i) Prove that \(R\) is not a field. Then decide whether \(R\) is an integral domain, and justify your answer.
        </p>
        <p>
            (ii) Given \(f\in \mathbb{Q}[x, y, z]\), let \(\overline{f}\) denote the element \(f + I\) of \(R\). Is the ideal \(J = (\bar x, \bar y)\) a prime ideal of \(R\)?
            Prove your answer.
        </p>
        <p>
            (iii) Show that \(\overline{z^5} \in J^2\), but that \(\overline{z^4}\notin J^2\).
        </p>
        </div>
        </div>
        <p>
            <b>Proof (i).</b> We know that \(\mathbb{Q}[x, y, z]/I\) is a field if and only if \(I\) is a maximal ideal.
            We know that \((x^2y - z^5)\subset (x^2y - z^5, z)\) since \(x^2y - z^5 = 1\cdot (x^2y - z^5) + 0\cdot z\).
            Now, I want to show that \((x^2y - z^5, z)\) is a proper ideal of \(\mathbb{Q}[x, y, z]\).
            Firstly, for any \(f\neq 0\in \mathbb{Q}[x, y, z]\), we can know that \(f\cdot (x^2y - z^5)\) does not contain a term of constant.
            Similarly, we can know that \(g\cdot z\) is a polynomial without constant term for any \(g\neq 0\in \mathbb{Q}[x, y, z]\).
            Hence, we can know that if \(f\cdot (x^2y - z^5) + g\cdot z\neq 0\), then \(f\cdot (x^2y - z^5) + g\cdot z\notin \mathbb{Q}\).
            In other words, if \(i\in (x^2y - z^5, z)\), then \(i\) is not a unit.
            Thus, we have \((x^2y - z^5, z)\neq \mathbb{Q}[x, y, z]\), which implies that \((x^2y - z^5, z)\) is a proper ideal.
            Then, we can conclude that \((x^2y - z^5)\) is not a maximal ideal. Therefore, we can know that \(R\) is not a field. \(\blacksquare\)
        </p>
        <p>
            Now, we want to show that \(R\) is an integral domain.
        </p>
        <p>
            <b>Proof (i).</b> We know that \(\mathbb{Q}[x, y, z]/I\) is an integral domain if \(I\) is a prime ideal.
            Since \(\mathbb{Q}[x, y, z] = \mathbb{Q}[x, z][y]\), we can know that \(x^2y - z^5\) is a degree \(1\) polynomial of \(\mathbb{Q}[x, z][y]\).
            Hence, \(x^2y - z^5\) is irreducible, which implies that \(x^2y - z^5\) is prime. Thus, we can know that \(I = (x^2y - z^5)\)  is a prime ideal.
            Therefore, we have \(R\) is an integral domain. \(\blacksquare\)
        </p>
        <p>
            <b>Proof (ii).</b> We want to show that \(J = (\bar x, \bar y)\) is a prime ideal of \(R\).
            If \(\bar r\in (\bar x, \bar y)\), we can know that \(\bar r = \bar x\bar f + \bar y\bar g\) for some \(\bar f, \bar g\in R\).
            Then, we we can know that \(\bar r\) does not contain a term of \(a_nz^n\) for any \(n\in \mathbb{N}\) and \(a_n\in\mathbb{Q}\) (including the case that \(n = 0\).
            In the other direction, if \(\bar r\) is an element of \(R\) without a term of \(a_nz^n\) for any \(n\in \mathbb{N}\) and \(a_n\in\mathbb{Q}\), then we can
            know that \(\bar r = \bar x\bar f + \bar y\bar g\) for some \(\bar f, \bar g\in R\).
            Hence, if \(\bar f, \bar g\in R\) do not contain a term of \(a_nz^n\) for any \(n\in \mathbb{N}\) and \(a_n\in\mathbb{Q}\) (i.e. \(\bar f\notin J, \bar g\notin J\)),
            then we can know that
            \(\bar f\cdot \bar g\) does not contain a term of \(a_nz^n\) for any \(n\in \mathbb{N}\) and \(a_n\in\mathbb{Q}\) (i.e. \bar f\bar g\notin J).
            Therefore, we can know that \(J\) is a prime ideal of \(R\). \(\blacksquare\)
        </p>
        <p>
            <b>Proof (iii).</b> Firstly, we want to show that \(J^2 = ({\bar x}^2, \bar x\bar y, {\bar y}^2)\).
            Let \(\bar p, \bar q\in J\). Then, we can know that \(\bar p = \bar x\bar f + \bar y\bar g\) and \(\bar q = \bar x\bar h + \bar y\bar k\) for some \(\bar f, \bar g, \bar h, \bar k\in R\).
            Then, we can know that \(\bar p\bar q = \bar x\bar x\bar f\bar h + \bar x\bar y\bar f\bar k + \bar x\bar y\bar g\bar h + \bar y\bar y\bar g\bar k\).
            Hence, we can know that \(\bar p\bar q\in ({\bar x}^2, \bar x\bar y, {\bar y}^2)\), which implies that \(J^2\subseteq ({\bar x}^2, \bar x\bar y, {\bar y}^2)\).
            In the other direction, if \(\bar r\in ({\bar x}^2, \bar x\bar y, {\bar y}^2)\), then we can know that \(\bar r = \bar x\bar x\bar f + \bar x\bar y\bar g + \bar y\bar y\bar h\) for some \(\bar f, \bar g, \bar h\in R\).
        </p>
    </section>

    <section id = 'ku_2019_8_4'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            4. Recall that if \( G \) is a group and \( x, y \in G \), \( x \) and \( y \) are conjugate if \( y = gxg^{-1} \) for some \( g \in G \), and that conjugacy is an equivalence relation on \( G \). Let \( [x] \) denote the conjugacy class of an element \( x \in G \); i.e., \( [x] = \{gxg^{-1} \mid g \in G\} \).
          </p>
          <p>
            (i) Prove that for \( x \in G \), \( [x] \) has exactly one element if and only if \( x \in Z(G) \), where \( Z(G) \) denotes the center of \( G \).
          </p>
          <p>
            (ii) More generally, prove that the number of elements in \( [x] \) equals \( |G : C_G(x)| \), where \( C_G(x) \) is the centralizer of \( x \) in \( G \), i.e., \( C_G(x) = \{g \in G \mid gxg^{-1} = x\} \). Hint: When is \( gxg^{-1} \) equal to \( hxh^{-1} \)?
            </p>
          <p>
            (iii) Suppose that \( G \) is a finite group of odd order, and suppose that \( N \) is a normal subgroup of \( G \) of order 3. Prove that \( N \leq Z(G) \). Hint: What does the normality of \( N \) say about the conjugacy classes of elements \( x \in N \)? How can one use this to partition \( N \)?
            </p>
        </div>
      </div>
      <p>
        <b>Proof (i).</b> Firstly, we can know that \(x\in [x]\) since \(exe^{-1} = exe = x\). Thus, if \([x]\) has exactly one element, then we can know that \(gxg^{-1} = x\) for all \(g\in G\). Hence, we have \(x = gxg^{-1}\) for all \(g\in G\), which implies that \(x\in Z(G)\).
        If \(x\in Z(G)\), then we have that \(gxg^{-1} = x\) for all \(g\in G\), which implies that \(\{x\} = [x]\). Thus, we can know that \([x]\) has exactly one element. \(\blacksquare\)
      </p>
      <p>
          <b>Proof (ii).</b> Since the number of elements in \([x]\) is the number of elements in the orbits.
          We define the map \(\varphi: [x]\to G/C_G(x))\) by \(\varphi(gxg^{-1}) = gC_G(x)\). Firstly, we can know that the map is surjective since for any \(gC_G(x)\), we have \(gxg^{-1}\in [x]\) such that
          \[
            \varphi(gxg^{-1}) = gC_G(x).
          \]
          Now, suppose that \(gC_G(x) = hC_G(x)\). Then, we have \(h^{-1}g\in C_G(x)\), which implies that \(h^{-1}gxg^{-1}h = x\).
          Hence, we have
          \[
          \begin{align}
          h^{-1}gxg^{-1}h &= x\\
          h(h^{-1}gxg^{-1}h)h^{-1} &= hxh^{-1}\\
          gxg^{-1} &= hxh^{-1}.
        \end{align}
          \]
         Thus, we can know that the map is injective. Hence, we can know that the number of elements in \([x]\) equals \(|G/C_G(x)| = |G:C_G(x)|\). \(\blacksquare\)
      </p>
      <p>
          <b>Proof (iii).</b>We define a map \(\varphi: G\to \text{Aut}(N)\) by \(\varphi(g) = gng^{-1}\). The reason that \(\varphi(g)\) is a group automorphism of \(N\) is \(N\) is normal in \(G\).
        We can see that \(\varphi\) is well-defined since for any \(g = h\in G\), we have \(gng^{-1} = hnh^{-1}\).
        Then, we can know that \(\varphi\) is a group homomorphism since for any \(g, h\in G\), we have
        \[
        \varphi(g)\varphi(h) = \varphi(g)\circ \varphi(h) = g h n h^{-1}g^{-1} = (gh)n(gh)^{-1} = \varphi(gh).
        \]
        Hence, we can see that the image of \(\varphi\), \(\varphi(G)\), is a subgroup of \(\text{Aut}(N)\).
        Given that \(N\) has order of \(3\), we have \(N\cong \mathbb{Z}/3\mathbb{Z}\), which implies that \(N\) is cyclic.
        Hence, any non-trivial element is a generator of \(N\). Thus, we have \(N = \{e, x, x^2\}\), where \(x, x^2\) are the generators of \(N\).
        Once we know where \(x\) is mapped to, we can know where \(x^2\) is mapped to since \(\varphi\) is a group homomorphism.
        There are only two options, either \(x\to x\) or \(x\to x^2\). Hence, we can see that \(|\text{Aut}(N)| = 2\), which implies that \(\mathbb{Z}/2\mathbb{Z}\cong \text{Aut}(N)\).
        Since \(\varphi(G)\) is a subgroup of \(\text{Aut}(N)\), we have \(|\varphi(G)| = 1\) or \(2\).
        According to the \(\textbf{First Isomorphism Theorem}\), we have \(G/\ker(\varphi) \cong \varphi(G)\)\).
        Since \(|\varphi(G)| = |G/\ker(\varphi)| = [G:\ker(\varphi)]\), we have \([G:\ker(\varphi)] = 1\) or \(2\).
        Given that \([G:\ker(\varphi)]\mid |G|\) and \(|G|\) is odd, we have \([G:\ker(\varphi)] = 1\).
        Thus, we can see that \(\varphi(G) = \{e\}\), which implies that \(\ker(\varphi) = G\). And \(\ker(\varphi) = \{g\in G\mid \varphi(g) = e\}\), which implies that \(gng^{-1} = n\) for all \(n\in N\).
        Therefore, we can get that \(N\leq Z(G)\). \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2019_8_6'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>6.</b> Consider the polynomial \( p(x) = x^3 - 2 \in \mathbb{Q}[x] \). Find \( \alpha, \beta \in \mathbb{C} \) for which \( F = \mathbb{Q}(\alpha, \beta) \) is a splitting field for \( p(x) \), and prove that this is the case. Then find, with justification, the degree of the field extension \( \mathbb{Q} \subseteq F \).
          </p>
        </div>
      </div>
      <p>
        <b>Solution (6).</b> Firstly, we want to find the all the roots of \(p(x)\).
        Suppose that \(a\) is the root of \(p(x)\). Then we have \(p(a) = a^3 - 2 = 0\) and \(a^3 = 2\).
        Hence, we can know that \(a^3\) is a cube of \(2\). Thus, we can know that \(a = \sqrt[3]{2}\), which is a real number.
        Now, if \(a^3 = 2\cos(2\pi) + 2\sin(2\pi)i = 2(\cos(2\pi) + sin(2\pi)i) = 2e^{2\pi i}\), then we have \(a = \sqrt[3]{2}e^{2\pi i/3}\).
        Hence, \(a = \sqrt[3]{2}(\cos(2\pi/3) + \sin(2\pi/3)i) = \sqrt[3]{2}(-1/2 + \sqrt{3}/2i)\).
        Similarly, we can have \(a^3 = 2\cos(-2\pi) + 2\sin(-2\pi)i = 2e^{-2\pi i}\), which implies that \(a = \sqrt[3]{2}e^{-2\pi i/3}\).
        Hence, we have \(a = \sqrt[3]{2}(\cos(-2\pi/3) + \sin(-2\pi/3)i) = \sqrt[3]{2}(-1/2 - (\sqrt{3}/2)i)\).
        Then, we have the three distinct roots of \(p(x)\), which are
        \[
        a_1 = \sqrt[3]{2},\quad a_2 = \sqrt[3]{2}(-1/2 + (\sqrt{3}/2)i),\quad a_3 = \sqrt[3]{2}(-1/2 - (\sqrt{3}/2)i).
        \]
        Thus, we can know that the splitting field of \(p(x)\) is \(F = \mathbb{Q}(a_1, a_2, a_3)\).
        Since \(a_2 - a_3 = \sqrt[3]{2}\cdot\sqrt{3}i\), we have
        \[
        \dfrac{\sqrt[3]{2}\cdot\sqrt{3}i}{\sqrt[3]{2}} = \sqrt{3}i.
        \]
        Hence, \(\mathbb{Q}(\sqrt[3]{2}, \sqrt{3}i)\subset \mathbb{Q}(a_1, a_2, a_3)\).
        It is not hard to see that \(\mathbb{Q}(a_1, a_2, a_3)\subset \mathbb{Q}(\sqrt[3]{2}, \sqrt{3}i)\).
        Since \(\sqrt{3}i\) is a root of \(x^2 + 3 = 0\). Since there is no rational roots of \(x^2 + 3 = 0\), we can know that \(x^2 + 3\) is irreducible over \(\mathbb{Q}\).
        Thus, we can know that
        \[
        \mathbb{Q}(\sqrt{3}i\) \cong \mathbb{Q}[x]/(x^2 + 3).
        \]
        Hence, \(\mathbb{Q}(\sqrt{3}i\)\) has degree \(2\) since the minimal polynomial of \(\sqrt{3}i\) has degree \(2\).
        Then, we want to show that \(x^3 - 2\) is irreducible over \(\mathbb{Q}(\sqrt{3}i)\) by contradiction.
        If \(x^3 - 2\) is a reducible polynomial over \(\mathbb{Q}(\sqrt{3}i)\), then we have a root of \(x^3 - 2\) in \(\mathbb{Q}(\sqrt{3}i)\).
        Since \(\mathbb{Q}(\sqrt{3}i\) = \{a + b\sqrt{3}i\mid a, b\in \mathbb{Q}\), we can know that the root of \(x^3 - 2\) is \(a + b\sqrt{3}i\) for some \(a, b\in \mathbb{Q}\).
        Then suppose that \(a + b\sqrt{3}i) is a root of \(p(x)\),
        \[
        \begin{align}
        (a + b\sqrt{3}i\)^3 &= 2, \\
        (a^2 + 2ab\sqrt{3}i - 3b^2)(a + b\sqrt{3}i) = 2, \\
        (a + b\sqrt{3}i\)^3&= a^3 - 9 a b^2 + 3 i \sqrt{3} b (a^2 - b^2) = 2
        \end{align}
        \]\Hence, we can know that \(3b(a^2 - b^2)\) =0\), which implies that \(b = 0\) or \(a-b = 0\) or \(a + b = 0\).
        Given that \(b\neq 0\), or \(a + b\sqrt{3}i = a\) is a root of \(p(x)\), which is a contradiction.
        Suppose that \(a = b\), then we can have \(a^3 - 9a^3 = -8a^3 = 2\), which implies that \(a^3 = -1/4\), which is a contradiction.
        Suppose that \(a = -b\), then we can have \(a^3 - 9a^3 = -10a^3 = 2\), which implies that \(a^3 = -1/4\), which is a contradiction.
        Hence, there exists no roots in \(p(x)\) and \(p(x)\) is irreducible. Then \(\mathbb{Q}(\sqrt{3}i, \sqrt[3]{2})\cong \mathbb{Q}(\sqrt{3}i)[x]/(x^3 - 2)\).
        Therefore, we have
        \[
        [\mathbb{Q}(\sqrt{3}i, \sqrt[3]{2}): \mathbb{Q}(\sqrt{3}i)][\mathbb{Q}(\sqrt{3}i): \mathbb{Q}] = 3\cdot 2 = 6.
        \]
      </p>
    </section>

    <h2 id = 'ku_2020_1'>KU 2020 (January)</h2>
    <section>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>2.</b> Let \( T : \mathbb{R}^3 \rightarrow \mathbb{R}^3 \) be a linear operator.
      </p>
        <p>
        (a) Suppose the matrix of \( T \) with respect to the standard basis of \( \mathbb{R}^3 \) equals
        \[
        \begin{pmatrix}
        \alpha & 0 & 0 \\
        0 & \beta & -\gamma \\
        0 & \gamma & \beta
        \end{pmatrix},
        \]
        with \( \alpha, \beta, \gamma \in \mathbb{R} \). Prove that \( T \) is a normal operator.
        </p>
        <p>
        (b) Suppose the matrix of \( T \) with respect to the standard basis is
        \[
        A = \begin{pmatrix}
        1 & 1 & 0 \\
        0 & 1 & 1 \\
        1 & 0 & 1
        \end{pmatrix}.
        \]
        Prove that \( T \) is a normal operator and find an orthonormal basis \( B \) for \( \mathbb{R}^3 \) such that the matrix of \( T \) with respect to \( B \) has the form in part (a).
      </p>
            </div>
        </div>
      <p>
        <b>Proof (a).</b> Given that the matrix is the linear operator \(T\) respect to the standard basis. We have
        \[
        \begin{align}
        T(e_1) = \alpha e_1, \\
        T(e_2) = \beta e_2 + \gamma e_3, \\
        T(e_3) = -\gamma e_2 + \beta e_3.
        \end{align}
        \]
        Then, we have the transpose \(\begin{pmatrix}
        \alpha & 0 & 0 \\
        0 & \beta & \gamma \\
        0 & -\gamma & \beta
        \end{pmatrix}\), which is the adjoint of the matrix of \(T\).
        Thus, we have
        \[
        \begin{align}
        T^*(e_1) &= \alpha e_1, \\
        T^*(e_2) &= \beta e_2 - \gamma e_3, \\
        T^*(e_3) &= \gamma e_2 + \beta e_3.
        \end{align}
        \]
        Now, let \(v = a e_1 + b e_2 + c e_3\), then we have
        \[
        \begin{align}
        T^*(T(v)) &= T^*(a\alpha e_1 + b\beta e_2 + b\gamma e_3 - c\gamma e_2 + c\beta e_3)\\
        &= T^*(a\alpha e_1 + (b\beta - c\gamma) e_2 + (b\gamma + c\beta) e_3)\\
        &= a\alpha T^*(e_1) + (b\beta - c\gamma) T^*(e_2) + (b\gamma + c\beta) T^*(e_3)\\
        &= a\alpha \alpha e_1 + (b\beta - c\gamma)(\beta e_2 - \gamma e_3) + (b\gamma + c\beta)(\gamma e_2 + \beta e_3)\\
        &= a\alpha^2 e_1 + b(\beta^2 + \gamma^2)e_2 + c(\beta^2 + \gamma^2)e_3\\
        \end{align}
        \]
        For the other direction,
        \[
        \begin{align}
        T(T^*(v)) &= T(a\alpha e_1 + b\beta e_2 - b\gamma e_3 + c\gamma e_2 + c\beta e_3)\\
        &= T(a\alpha e_1 + (b\beta + c\gamma) e_2 + (-b\gamma + c\beta) e_3)\\
        &= a\alpha T(e_1) + (b\beta + c\gamma) T(e_2) + (-b\gamma + c\beta) T(e_3)\\
        &= a\alpha \alpha e_1 + (b\beta + c\gamma)(\beta e_2 + \gamma e_3) + (-b\gamma + c\beta)(-\gamma e_2 + \beta e_3)\\
        &= a\alpha^2 e_1 + b(\beta^2 + \gamma^2)e_2 + c(\beta^2 + \gamma^2)e_3\\
        \end{align}
        \]
      Hence, we can see that \(T^*(T(v)) = T(T^*(v))\) for any \(v\in \mathbb{R}^3\). Therefore, we have \(T\) is a normal operator. \(\blacksquare\)
      </p>
      <p>
        <b>Proof (b).</b> Similar to part \((a)\), we have
        \[
        \begin{align}
        T(e_1) &= e_1 + e_3, \\
        T(e_2) &= e_1 + e_2, \\
        T(e_3) &= e_2 + e_3.
        \end{align}
        \]
        Then we have the adjoint of the matrix of \(T\) is \(\begin{pmatrix}
        1 & 0 & 1 \\
        1 & 1 & 0 \\
        0 & 1 & 1
        \end{pmatrix}\).
        Then we have
        \[
        \begin{align}
        T^*(e_1) &= e_1 + e_2, \\
        T^*(e_2) &= e_2 + e_3, \\
        T^*(e_3) &= e_1 + e_3.
        \end{align}
        \]
        Now, set \(v = a e_1 + b e_2 + c e_3\), then we have
        \[
        \begin{align}
        T^*(T(v)) &= T^*(a e_1 + a e_3 + b e_1 + b e_2 + c e_2 + c e_3)\\
        &= T^*((a + b)e_1 + (b + c)e_2 + (a + c)e_3)\\
        &= (a + b)T^*(e_1) + (b + c)T^*(e_2) + (a + c)T^*(e_3)\\
        &= (a + b)(e_1 + e_2) + (b + c)(e_2 + e_3) + (a + c)(e_1 + e_3)\\
        &= (2a + b + c)e_1 + (a + 2b + c)e_2 + (a + b + 2c)e_3.
        \end{align}
        \]
        For the other direction,
        \[
        \begin{align}
        T(T^*(v)) &= T(a e_1 + a e_2 + b e_2 + b e_3 + c e_1 + c e_3)\\
        &= T((a + c)e_1 + (a + b)e_2 + (b + c)e_3)\\
        &= (a + c)T(e_1) + (a + b)T(e_2) + (b + c)T(e_3)\\
        &= (a + c)(e_1 + e_3) + (a + b)(e_1 + e_2) + (b + c)(e_2 + e_3)\\
        &= (2a + b + c)e_1 + (a + 2b + c)e_2 + (a + b + 2c)e_3.
        \end{align}
        \]
        Hence, we can see that \(T^*(T(v)) = T(T^*(v))\) for any \(v\in \mathbb{R}^3\). Therefore, we have \(T\) is a normal operator.
        When \(v = ae_1 + be_2 + ce_3\), we have
        \[
        T(v) = (a + b)e_1 + (b + c)e_2 + (a + c)e_3.
        \]
        Thus, we have \(T(a, b, c) = (a + b, b + c, a + c)\).
        Since \(T(e_1) + T(e_2) - T(e_3) = e_1 + e_3 + e_1 + e_2 - e_2 - e_3 = 2e_1\), we have \(T(e_1 + e_2 - e_3) = 2e_1\).
        Moreover, we have \(T(e_1) - T(e_2) =  -(e_1 + e_2) + e_1 + e_3 = e_3 - e_2\) and \(T(e_3) = e_2 + e_3\).
        Let \(\mathcal{B} = \{e_1 + e_2 - e_3, e_3, e_1 - e_2\} = \{[1, 1, -1]^T, [0, 0, 1]^T, [-1, 1, 0]^T\}\).
        We have the matrix of \(T\) with respect to \(\mathbb{B}\) is
        \[
        \begin{pmatrix}
        2 & 0 & 0 \\
        0 & 1 & -1 \\
        0 & 1 & 1
        \end{pmatrix}.
        \]
        Now, we only need to show that \(\mathcal{B}\) is a basis.
        \[
        \begin{align}
        a\cdot \begin{pmatrix} 1 \\ 1 \\ -1 \end{pmatrix} + b\cdot \begin{pmatrix} 1 \\ -1 \\ 0 \end{pmatrix} + c\cdot \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} &= \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}\\
        \begin{pmatrix} a + b \\ a - b \\ -a + c \end{pmatrix} &= \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}\\
        \end{align}
        \]
        Hence, we have \(a = b = c = 0\), which implies that they are independent. Thus, we have \(\mathcal{B}\) is a basis.
      </p>
    </section>

    <section id = 'ku_2020_1_4'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>4.</b> Given a field \( K \), consider the group \( GL_n(K) \) of invertible \( n \times n \) matrices with entries in \( K \).
      </p>
      <p>
        (a) Show that the center of \( GL_n(K) \) is \( \{ \alpha I_n \mid \alpha \in K^\times \} \), where \( I_n \) is the \( n \times n \) identity matrix.
        <i>Hint:</i> Consider the matrix \( I_n + A_{ij} \), where \( A_{ij} \) is the matrix whose \((i,j)\)-th entry is 1, and all other entries are 0.
      </p>
      <p>
        (b) Show that \( |SL_2(\mathbb{F}_3)| = 24 \), where \( \mathbb{F}_3 \) is the field with three elements, and \( SL_2(\mathbb{F}_3) \) is the subgroup of \( GL_2(\mathbb{F}_3) \) of \( 2 \times 2 \) matrices with determinant 1.
      </p>
      <p>
        (c) Use (a) to prove that \( SL_2(\mathbb{F}_3) \) is not isomorphic to the symmetric group \( S_4 \).
      </p>
            </div>
        </div>
      <p>
        <b>Proof (a).</b> Let us denote \(S\) as \( \{ \alpha I_n \mid \alpha \in K^\times \} \). Suppose that \(s\in S\), then we can have \(s = \alpha I_n\), for some \(\alpha\in K\setminus\{0\}\).
      Let \(g\in GL_n(K)\), then we have
        \[
        g\cdot s\cdot g^{-1} = g\cdot \alpha I_n\cdot g^{-1} = \alpha g\cdot I_n\cdot g^{-1} = \alpha I_n.
        \]
        Hence, we showed that \(s\in Z(GL_n(K))\). Now, suppose that \(z\in Z(GL_n(K))\), then we have
        \[
        g\cdot z\cdot g^{-1} = z,
        \]
        for any \(g\in GL_n(K)\). Then, we have
      </p>
      <p>
          <b>Proof (b).</b> For any \(g\in SL_2(\mathbb{F}_3)\), we can know that
          \[
            g = \begin{pmatrix} a & b \\ c & d \end{pmatrix},
          \]
          where \(ad - bc = 1\).
          Hence, we can count the number of combinations such that \(x - y = 1\) where \(x, y\in \mathbb{F}_3\).
            We have the following combinations:
            \[
            \begin{align}
            0 - 2 &= 1,\\
            1 - 0 &= 1,\\
            2 - 1 &= 1
            \end{align}
            \]
            Then, we want to count the number of combinations of \(xy = 0, 1, 2\) where \(x, y\in \mathbb{F}_3\). When \(xy = 0\), we have \(5\) combinations, which are
            \[
                0\cdot 0, 0\cdot 1, 1\cdot 0, 2\cdot 0, 0\cdot 2.
            \]
            When \(xy = 1\), we have \(2\) combinations, which are
            \[
            1\cdot 1, 2\cdot 2.
            \]
            When \(xy = 2\), we have \(2\) combinations, which are
            \[
            1\cdot 2, 2\cdot 1.
            \]
            Hence, we can know that there are \(5\cdot 2 = 10\) combinations such that we will have \(0 - 2 = 1\).
            And there are \(2\cdot 5 = 10\) combinations such that we will have \(1 - 0 = 1\).
            And there are \(2\cdot 2 = 4\) combinations such that we will have \(2 - 1 = 1\).
            Therefore, there are \(10 + 10 + 4 = 24\) such elements in \(SL_2(\mathbb{F}_3)\). \(\blacksquare\)
      </p>
      <p>
          <b>Proof (c).</b> Firstly, according to part (a), we have \(Z(GL_2(\mathbb{F}_3)) = \{ \alpha I_2 \mid \alpha\in \mathbb{F}_3\setminus\{0\} \}\).
          And we can know that \(Z(GL_2(\mathbb{F}_3))\subset Z(SL_2(\mathbb{F}_3)\).
          Hence, we have \(\{I_2, 2I_2\}\subset Z(SL_2(\mathbb{F}_3))\).
          In other words, \(|Z(SL_2(\mathbb{F}_3))|\geq 2\). Now, we want to look at the center of \(S_4\). We start from \(2\)-cycles of \(S_4\),
          Let \((a, b)\in S_4\) where \(a, b\in \{1, 2, 3, 4\}\). Hence, we can know that there exists \(c\in \{1, 2, 3, 4\}\) such that \(c\neq a\) and \(c\neq b\).
          Then, there exists \(\sigma\in S_4\) such that \(\sigma (a) = c\). Hence, we have
          \[
          \sigma\cdot (a, b)\cdot \sigma^{-1} = (\sigma(a), \sigma(b)) = (c, \sigma(b))\neq (a, b).
          \]
          Hence, we can know that there is no \(2\)-cycle in the center of \(S_4\).
          Now, we want to look at the \(3\)-cycles of \(S_4\). Suppose that \((a, b, c)\in S_4\), where \(a, b, c\in \{1, 2, 3, 4\}\).
          Then, we can know that there exists \(d\in \{1, 2, 3, 4\}\) such that \(d\neq a\), \(d\neq b\), and \(d\neq c\).
          Then, there exists \(\sigma\in S_4\) such that \(\sigma(a) = d\). Hence, we have
            \[
            \sigma\cdot (a, b, c)\cdot \sigma^{-1} = (\sigma(a), \sigma(b), \sigma(c)) = (d, \sigma(b), \sigma(c))\neq (a, b, c).
            \]
            Hence, there is no \(3\)-cycle in the center of \(S_4\).
            Now, we want to look at the \(4\)-cycles of \(S_4\). Suppose that \((a, b, c, d)\in S_4\), where \(a, b, c, d\in \{1, 2, 3, 4\}\).
            Then, we can know that there exists \(\sigma\in S_4\) where \(\sigma = (b, c)\). Hence, we can know that
            \[
            \sigma\cdot (a, b, c, d)\cdot \sigma^{-1} = (a, c, b, d)\neq (a, b, c, d).
            \]
            Hence, there is no \(4\)-cycle in the center of \(S_4\).
            The last category is the disjoint product of two \(2\)-cycles. Suppose that \((a, b)(c, d)\in S_4\), where \(a, b, c, d\in \{1, 2, 3, 4\}\).
            Then, we can know that there exists \(\sigma\in S_4\) such that \(\sigma = (b, c)\).
            We hae \(\sigma\cdot (a, b)(c, d)\sigma^{-1} = (a, c)\neq (b, d)\). Hence, there is no disjoint product of two \(2\)-cycles in the center of \(S_4\).
            We can know that the center of \(S_4\) is trivial. Hence, we have \(Z(S_4) = \{I_4\}\), which implies that \(|Z(S_4)|\lt |Z(SL_2(\mathbb{F}_3))|\).
            Therefore, we can know that \(SL_2(\mathbb{F}_3)\not\cong S_4\). \(\blacksquare\)
      </p>
    </section>

    <section id = 'ku_2020_1_5'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
          <b>5.</b> Given a commutative ring \( R \) with 1, the Jacobson radical, \( J(R) \), is the intersection of all maximal ideals of \( R \).
        </p>
        <p>
          (a) Find the Jacobson radical of \( \mathbb{Z}/12\mathbb{Z} \), and of \( \mathbb{Q}[x,y]/\langle x^2, y-5 \rangle \), with full justification.
        </p>
        <p>
          (b) Fix an element \( r \) of a commutative ring \( R \) with 1. Prove that \( r \in J(R) \) if and only if for every \( s \in R \), the element \( rs - 1 \) is a unit of \( R \).
        </p>
      </div>
      </div>
      <p>
        <b>Solution (a).</b> Firstly, we want to find all the maximal ideals of \(\mathbb{Z}/12\mathbb{Z}\).
        According to the \(\textbf{Correspondence Theorem of Rings}\), we can know the maximal ideals \(M\) of \(\mathbb{Z}\), which contains \(12\mathbb{Z}\) can be mapped to \(M/\langle 12 \rangle\) in \(\mathbb{Z}/12\mathbb{Z}\), which is a maximal ideal of \(\mathbb{Z}/12\mathbb{Z}\).
        Since \(\mathbb{Z}\) is a PID, any ideal \(I\) of \(\mathbb{Z}\) can be written as \(a\mathbb{Z}\) where \(a\in \mathbb{Z}\).
        If \(12\mathbb{Z}\subset a\mathbb{Z}\), we can know that \(a\mid 12\). Thus, we can know that \(\mathbb{Z}, 2\mathbb{Z}, 3\mathbb{Z}, 4\mathbb{Z}, 6\mathbb{Z}, 12\mathbb{Z}\) are ideals containing \(12\mathbb{Z}\).
        And \(a\mathbb{Z}\) is a maximal ideal if and only if \(a\mathbb{Z}\) is a prime ideal since \(\mathbb{Z}\) is a PID.
        And \(a\mathbb{Z}\) is a prime ideal if and only if \(a\) is a prime in \(\mathbb{Z}\). Hence, we can know that \(2\mathbb{Z}, 3\mathbb{Z}\) are the only maximal ideals containing \(12\mathbb{Z}\).
        Then, we have \(2\mathbb{Z}/12\mathbb{Z}\) and \(3\mathbb{Z}/12\mathbb{Z}\) are the maximal ideals of \(\mathbb{Z}/12\mathbb{Z}\).
        Since \(2\mathbb{Z}/12\mathbb{Z} = \{0, 2, 4, 6, 8, 10\}\) and \(3\mathbb{Z}/12\mathbb{Z} = \{0, 3, 6, 9\}\), we have \(J(\mathbb{Z}/12\mathbb{Z}) = 2\mathbb{Z}/12\mathbb{Z}\cap 3\mathbb{Z}/12\mathbb{Z} = 6\mathbb{Z}/12\mathbb{Z} = \{0, 6\}\).
      </p>
      <p>
        Now, we want to identity all the maximal ideals of \(\mathbb{Q}[x, y]/\langle x^2, y - 5 \rangle\).
        Firstly, we know that if \(a(x, y)\in \langle x^2, y - 5\rangle\), then
        \[
        a(x, y) = f(x, y)\cdot x^2 + g(x, y)\cdot (y - 5) = x\cdot (x\cdot f(x, y)) + g(x, y)\cdot (y - 5) \in \langle x, y - 5\rangle.
        \]
        In that case, we can know that \(\langle x^2, y - 5\rangle \subset \langle x, y - 5\rangle\).
        Now, we want to show that \(\langle x, y - 5\rangle\) is a maximal ideal by showing that \(\mathbb{Q}[x, y]/\langle x, y - 5\rangle\) is a field.
        Out first step is to show that \(\mathbb{Q}[x, y]/(x, y - 5) \cong \mathbb{Q}[y](y - 5)\).
        Define a map \(\psi: \mathbb{Q}[x, y]/\langle x, y-5\rangle\to \mathbb{Q}[y](y - 5)\) such that \(\psi(f(x, y) + (x, y - 5)) = f(0, y) + (y - 5)\).
        Let \(g(x, y), f(x, y)\in \mathbb{Q}[x, y]\), we can have
        \[
        \begin{align}
        \psi(g(x, y) + f(x, y) + \langle x, y-5\rangle) &= g(0, y) + f(0, y) + (y - 5),\\
        \psi(g(x, y)\cdot f(x, y) + (x, y - 5)) &= g(0, y)\cdot f(0, y) + (y - 5).
        \end{align}
        \]
        Hence, we can know that \(\psi\) is a ring homomorphism.
        Since \(\ker(\psi) = \{f(x, y) + \langle x, y-5\rangle \mid f(0, y) \in \langle y-5\rangle\}\), we can know that \(f(0, y) = (y-5) g(y)\) for some \(g(y)\in \mathbb{Q}[y]\).
        It means that \(f(x, y) = x\cdot h(x, y) + (y - 5)\cdot g(y)\) for some \(h(x, y)\in \mathbb{Q}[x, y]\), which implies that \(f(x, y)\in \langle x, y - 5\rangle\).
        Hence, we have \(\ker(\psi) = \langle x, y - 5\rangle\), which is trivial and we are able to conclude that \(\psi\) is an injective ring homomorphism.
        Now, for any \(f(y) + \langle y-5\rangle\in \mathbb{Q}[y]\), we define \(f(x, y) = f(y) + x\). Then, we can have
        \[
        \psi(f(x, y) + \langle x, y-5\rangle = f(0, y) + (y - 5) = f(y) + (y - 5).
        \]
        Hence, we have \(\psi\) is also a surjective ring homomorphism. And we can know that \(\psi\) is an isomorphism. Therefore, we have
        \[
        \mathbb{Q}[x, y]/\langle x, y-5\rangle\cong \mathbb{Q}[y]/\langle y - 5\rangle .
        \]
        Then, we will use the \(\textbf{First Isomorphism Theorem}\) to show that \(\mathbb{Q}[y](y - 5)\) is a field.
        We define a map \(\varphi: \mathbb{Q}[y]\to \mathbb{Q}\) such that \(\varphi(f(x)) = f(5)\).
        Let \(f(y), g(y)\in \mathbb{Q}[y]\). We can get
        \[
        \begin{align}
        \varphi(f(y) + g(y)) &= f(5) + g(5),\\
        \varphi(f(y)\cdot g(y)) &= f(5)\cdot g(5).
        \end{align}
        \]
        Hence, we can know that \(\varphi\) is a ring homomorphism.
        For any \(q\in \mathbb{Q}\), we also have \(q\in \mathbb{Q}[y]\) and \(\varphi(q) = q\) for any \(q\in \mathbb{Q}\).
        Thus, we can see that \(\varphi\) is a surjective ring homomorphism. Now, we want to show that \(\ker(\varphi) = \langle y - 5\rangle\).
        Suppose that \(h(y)\in \langle y - 5\rangle\), we can know that \(h(y) = (y - 5)\cdot k(y)\) where \(k(y)\in \mathbb{Q}[y]\).
        Then, we have \(\varphi(h(y)) = h(5) = 0\), which implies that \(h(y)\in \ker(\varphi)\) and \(\langle y - 5\rangle \subset \ker(\varphi)\).
        For the other direction, suppose that \(f(y)\in \ker(\varphi)\), then we have \(f(5) = 0\), which implies that \(f(y) = (y - 5)\cdot g(y)\) where \(g(y)\in \mathbb{Q}[y]\).
        Hence, we can know that \(f(y)\in \langle y - 5\rangle\) and \(\ker(\varphi) \subset \langle y - 5\rangle\). Then, we have \(\ker(\varphi) = \langle y - 5\rangle\).
        According to the \(\textbf{First Isomorphism Theorem}\), we can know that
        \[
        \mathbb{Q}[y]/\ker(\varphi) = \mathbb{Q}[y]/\langle y - 5\rangle \cong \mathbb{Q}.
        \]
        Hence, we have shown that \(\mathbb{Q}[x, y]/\langle x, y - 5\rangle \cong \mathbb{Q}/\langle y - 5\rangle \cong \mathbb{Q}\), which is a field.
        And we can conclude that \(\langle x, y - 5\rangle \) is a maximal ideal. Now, we want to show that if \((x^2, y-5)\subset M\) where \(M\) is a maximal ideal,
        we can have \(x\in M\) by contradiction.
        Suppose that \(x\notin M\) and \(\langle x^2, y-5\rangle \subset M\). Hence, we can know that \(M\neq M + \langle x\rangle\) since \(0\in M\) and \(x\in \langle x\rangle\) and \( 0 + x = x\in M + \langle x\rangle \).
        Given that \(M\) is a maximal ideal, we can conclude that \(M + \langle x \rangle  = R = \mathbb{Q}[x, y]\).
        Since \(1\in \mathbb{Q}[x, y]\), there exists \(f(x, y)\in \mathbb{Q}[x, y]\) and \(m(x, y)\in M\) such that
        \[
        \begin{align}
        m(x, y) + x\cdot f(x, y) &= 1, \\
        m(x, y) &= 1 - x\cdot f(x, y), \\
        x\cdot m(x, y) &= x - x^2\cdot f(x, y).
        \end{align}
        \]
        Since \(m(x, y)\in M\), we have \(x\cdot m(x, y)\in M\) and \(x - x^2 \cdot f(x, y)\in M\). Again, we know that \(x^2\in M\) by assumption, so we have \(x^2 \cdot f(x, y)\in M\).
        Hence, \(x - x^2\cdot f(x, y) + x^2\cdot f(x, y) = x\in M\), which is a contradiction. Therefore, we can know that \(x\in M\).
        In that case, we can know that for any maximal ideal containing \((x^2, y-5)\), it must contain \(x\) and \(y - 5\). Therefore, we can know that \(\langle x, y-5\rangle \subset M\) for all maximal ideals \(M\) containing \((x^2, y-5)\).
        And \(\langle x, y-5\rangle\) is a maximal ideal, which implies that there is only one maximal ideal containing \((x^2, y-5)\), which is \(\langle x, y-5\rangle\).
        According to the \(\textbf{Correspondence Theorem of Rings}\), we can know that \(J(\mathbb{Q}[x, y]/\langle x^2, y-5\rangle) = \langle x, y-5\rangle/\langle x^2, y-5\rangle \).
      </p>
      <p>
        <b>Proof (b).</b> We firstly showed that if \(r\in J(R)\), then we can know that \(rs - 1\) for any \(s\in R\).
        We know that if \(m\in M\) where \(M\) is a maximal ideal then we want to show that \(m - 1\notin M\) by contradiction.
        Suppose that \(m - 1\in M\). We have \(m - 1 + m = - 1\in M\), which implies that \(1\in M\). Since \(M\) is a proper ideal, we know it does not contain a unit.
        Hence, it is a contradiction. Thus, we can know that \(m - 1\) is not contained in \(M\). Suppose that \(a\in J(R)\), then we can know that \(a\) is in every maximal ideal of \(R\).
        Hence, we can know that \(a - 1\) is not in any maximal ideal of \(R\).
        Since \(a - 1\) is not in any maximal ideal, we can know that \(\langle a - 1\rangle \not\subset M\) for any maximal ideal \(M\).
        Hence, we can know that \(\langle a - 1\rangle\) is not a proper ideal of \(R\), which implies that \(\langle a - 1\rangle = R\).
        Hence, we can know that \(a - 1\) is a unit. Since \(r\in J(R)\) adn \(J(R)\) is an ideal, we can know that that \(rs \in J(R)\) for any \(s \in R\).
        Since we already showed that \(a - 1\) is a unit if \(a \in J(R)\), we can have \(rs - 1\) is a unit.
      </p>
      <p>
        For the other direction, suppose that \(rs - 1\) is a unit for any \(s\in R\). Then, we can know that \(r\cdot 1 - 1 = r- 1\) is a unit.
        Then, we can know that \(r\) is not a unit by contradiction. Suppose that \(r\) is a unit then there exists \(a\in R\) such that \(ra = 1\).
        It means that \(ra - 1 = 0\) for some \(a\in R\), which implies that \(ra - 1\) is not a unit. Thus, it is a contradiction. Thus, \(r\) is not a unit.
        Then, we can know that \(\langle r\rangle\) is a proper ideal of \(R\).
        Now, we want to show that \(\langle r \rangle \subset M\) for any maximal ideal \(M\) by contradiction.
        Suppose that there exists a maximal ideal \(M\) such that \(\langle r \rangle \not\subset M\).
        Then, we can know that \(\langle r \rangle + M \) is an ideal strictly containing \(M\).
        Since \(M\) is a maximal ideal, we can know that \(\langle r \rangle + M = R\).
        Thus, we can know that there exists \(m\in M\) and \(ra\in \langle r \rangle\) such that \(mb + rab = 1\) for some \(b\in R\).
        It shows that \(rab - 1 = -mb\). Since \(rab - 1\) is a unit by assumption, we can know that \(-mb\) is a unit.
        However, \(-mb\in M\) and \(M\) is a proper ideal, which implies that \(-mb\) is not a unit. Thus, it is a contradiction.
        Therefore, \(\langle r \rangle \subset M\) for any maximal ideal \(M\). Hence, we can know that \(r\in J(R)\). \(\blacksquare\)
      </p>
    </section>

    <br>

    <h2 id = 'august_2020'>KU 2020 (August)</h2>
    <section id = 'ku_2020_8_1'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
    <p>
      <b>1.</b> Let \( G := \{ I := C_1, C_2, \ldots, C_r \} \) be a finite set of invertible \( n \times n \) complex matrices, such that \( G \) is a finite group under matrix multiplication. Here \( I \) denotes the \( n \times n \) identity matrix.
    </p>
    <p>
      (i) Prove that each \( C_i \) is diagonalizable.
    </p>
    <p>
      (ii) Show that \( \text{trace}(C_i^{-1}) = \overline{\text{trace}(C_i)} \), for all \( i \), where \( \overline{z} \) denotes the complex conjugate of \( z \in \mathbb{C} \).
    </p>
    <p>
      (iii) Let \( \langle -, - \rangle \) denote the standard inner product on \( \mathbb{C}^n \). Define \( [v, w] := \frac{1}{|G|} \sum_{i=1}^r \langle C_i v, C_i w \rangle \), for all \( v, w \in \mathbb{C}^n \). Prove that \( [ -, - ] \) is an inner product on \( \mathbb{C}^n \) and that \( [v, w] = [C_i v, C_i w] \), for all \( v, w \in \mathbb{C}^n \) and \( C_i \in G \).
    </p>
        </div>
      </div>
    <p>
      <b>Proof (i).</b> Given that \(G\) is a finite group with order \(r\). Hence, we can see that for any \(C_i\), we have \(C_i^r = I\).
      Then, we have \(C^r - I = 0\). Let \(f(x) = x^r - 1\) and we have \(f(C_i) = 0\) for any \(i\). Denote the minimal polynomial of \(C_i\) as \(\mu_{C_i}(x)\).
      We can know that \(\mu_{C_i}(x)\mid f(x)\). Since \(f'(x) = rx^{r-1}\) and
      \[
      x^r - 1 = \frac1r x\cdot rx^{r-1} - 1,
      \]
      we can know that \(\gcd(f(x), f'(x)) = 1\), which implies that \(x^r - 1\) is separable in \(\mathbb{C}\).
      Hence, we can know that \(f(x)\) has distinct roots in \(\mathbb{C}\). Given that \(\mu_{C_i}(x)\mid f(x)\), we can know that \(\mu_{C_i}(x)\) has distinct roots in \(\mathbb{C}\).
      Since the minimal polynomial contains all the eigenvalues of \(C_i\) as roots.
      Let \(\mu_{C_i}(x) = (x - \lambda_1)(x - \lambda_2)\cdots(x - \lambda_{n_i})\), where \(\lambda_j\) are the eigenvalues of \(C_i\).
      Since each \(\lambda_j\) is distinct, we have
      \[
      V = \ker(C_i - \lambda_1I) \oplus \ker(C_i - \lambda_2I) \oplus \cdots \oplus \ker(C_i - \lambda_{n_i}I).
      \]
      Since the algebraic multiplicity of each eigenvalue is equal to the geometric multiplicity, we have \(C_i\) is diagonalizable. \(\blacksquare\)
    </p>
      <p>
        <b>Proof (ii).</b> Since we already showed each \(C_i\) is diagonalizable, we write \(C_i = P_iD_iP_i^{-1}\), where \(D_i\) is a diagonal matrix and \(P_i\) is an invertible matrix.
        Since \(C_i\) is invertible, we have \(D_i\) is invertible. Then, we can have \(C_i^{-1} = P_iD_i^{-1}P_i^{-1}\), where \(D_i^{-1}\) is a diagonal matrix and \(P_i\) is an invertible matrix.
        Moreover, the diagonal entries of \(D_i^{-1}\) is the reciprocal of the diagonal entries of \(D_i\).
        Since the diagonal entries of \(D_i\) are eigenvalues of \(C_i\), we have
        \[
        \begin{align}
        \text{trace}(C_i) &= \text{trace}(P_iD_iP_i^{-1}) = \text{trace}(D_iP_i^{-1}P_i) = \text{trace}(D_i) = \sum_{j=1}^n \lambda_j, \\
        \text{trace}(C_i^{-1}) &= \text{trace}((P_iD_iP_i^{-1})^{-1}) = \text{trace}(P_iD_i^{-1}P_i^{-1}) = \text{trace}(D_i^{-1}P_i^{-1}P_i) = \text{trace}(D_i^{-1}) = \sum_{j=1}^n \frac1{\lambda_j}.
        \end{align}
        \]
        Again, we can know that \((\lambda_i)^r - 1 = 0\), since the eigenvalue is the root of \(x^r - 1\) from the previous part.
        Then,
        \[
        \overline{\lambda_i^r - 1} = \overline{\lambda_i^r} - \overline{1} = \overline{\lambda_i}^r - 1 = 0.
        \]
        Thus, we can know that \(\lambda_i^r\) = 1 and \(\overline{\lambda_i}^r = 1\).
        Hence, we have
        \[
        \lambda_i^r\cdot \overline{\lambda_i}^r = (\lambda_i\overline{\lambda_i})^r = 1.
        \]
        Since \(\lambda_i\cdot \overline{\lambda_i} = |\lambda_i|^2\geq 0\), we have \((\lambda_i\cdot \overline{\lambda_i} =1\), for every eigenvalue \(\lambda_i\) of \(C_i\).
        Thus, we have
        \[
        \text{trace}(C_i^{-1}) = \sum_{j=1}^n \frac1{\lambda_j} = = \sum_{j=1}^n \frac{\overline{\lambda_j}}{\lambda_j\overline{\lambda_j}} = \sum_{j=1}^n \overline{\lambda_j} = \overline{\sum_{j=1}^n \lambda_j} = \overline{\text{trace}(C_i)}. \blacksquare
        \]
      </p>
      <p>
        <b>Solution (c).</b>Firstly, we want to show that \([v, v]\geq 0\) for any \(v\).
        Given that
        \[
        [v, v] = \frac{1}{|G|}\sum_{i = 1}^r \langle C_i v, C_i v \rangle = \frac{1}{|G|}\sum_{i = 1}^r \|C_iv\|^2 \geq 0.
        \]
        Then, we want to show that \([v, v] = 0\) if and only if \(v = 0\).
        Suppose that \([v, v] = 0\), then we have \(\|C_iv\|^2 = 0\) for all \(i\), which implies that \(C_i v = 0\) for all \(i\).
      </p>
    </section>

    <br>

    <section id = 'ku_2020_8_2>'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
    <p>
      <b>2.</b> Let \( T \) be a linear operator on a finite dimensional complex inner product space \( V \). Recall that \( T \) is a normal operator if \( TT^* = T^*T \), where \( T^* \) denotes the adjoint of \( T \). Prove that \( T \) is a normal operator if and only if \( \|T(v)\| = \|T^*(v)\| \), for all \( v \in V \). (Hint: use the fact that \( T^*T - TT^* \) is self-adjoint.) Give an example of a normal operator on a three-dimensional complex space that is not self-adjoint.
    </p>
        </div>
      </div>
          <p>
            <b>Proof.</b> Suppose that \(T\) is a normal operator. Then, we have \(TT^* = T^*T\). Let \(v\in V\), then we have
            \[
            \|T(v)\|^2 = \langle T(v), T(v) \rangle = \langle T^*T(v), v \rangle = \langle TT^*(v), v \rangle = \langle T^*(v), T^*(v) \rangle = \|T^*(v)\|^2.
            \]
            Hence, we have \(\|T(v)\| = \|T^*(v)\|\) for all \(v\in V\).
            For the other direction, let \(v\) be any vector in \(V\), then we have \(\|T(v)\| = \|T^*(v)\|\), which implies that \(\|T(v)\|^2 = \|T^*(v)\|^2\).
            Then, we have
            \[
            \begin{align}
            \|T(v)\|^2 - \|T^*(v)\|^2 &= 0\\
            \langle T(v), T(v) \rangle - \langle T^*(v), T^*(v) \rangle &= 0\\
            \langle T^*T(v), v \rangle + \langle -TT^*(v), v \rangle &= 0\\
            \langle T^*T(v) - TT^*(v), v \rangle &= 0 \\
            \langle (T^*T - TT^*)(v), v \rangle &= 0.
            \end{align}
            \]
            Since \(v\) is any vector, it forces \((T^*T - TT^*)(v) = 0\). Again, because of \(v\) is any vector, we can have \(T^*T - TT^* = 0\), which implies that \(T\) is a normal operator. \(\blacksquare\)
          </p>
    </section>


    <br>

    <section id = 'ku_2020_8_4'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>4.</b> Let \( G \) be a group of order \( 3n \) where \( n \) is an odd number.
      </p>
      <p>
        (a) Prove that any subgroup of order \( n \) in \( G \) is normal.
      </p>
      <p>
        (b) Give an example, with full justification, to show that the statement in part (a) is no longer true if \( n \) is even.
      </p>
            </div>
        </div>
      <p>
        <b>Proof (a).</b> Suppose that \(n\) is an odd number and there exists a subgroup of \(G\), \(H\), such that the order is \(n\).
        Then, we can know that \([G:H] = 3\). Since \(n\) is an odd number, we can know that \(2\not\mid n\), which implies that \(3\) is the smallest prime dividing \(3n\).
        Hence, we can conclude that \(H\) is normal in \(G\). \(\blacksquare\)
      </p>
    </section>

    <br>

    <section id = 'ku_2020_8_6'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 6.</b> Construct a field \( F \) with nine elements, with full justification. Then prove that the map \( f : F \to F \) defined by \( f(\alpha) = \alpha^3 \), for all \( \alpha \in F \), is an automorphism (i.e., an isomorphism from \( F \) to itself).
            </p>
        </div>
        </div>
      <p>
        <b>Solution.</b> We can know that \(F_3 = \mathbb{Z}/3\mathbb{Z}\) is a field with three elements.
        Moreover, \(p(x) = x^2 + 1\) is an irreducible polynomial over \(\mathbb{Z}/3\mathbb{Z}\). We can show that \(p(x)\) is irreducible by contradiction.
        Suppose that \(p(x) = (x - a)(x -b)\), which implies that there exists roots in \(\mathbb{Z}/3\mathbb{Z}\).
        However, we have \(p(0) = 1, p(1) = 2, p(2) = 2\), which implies that \(p(x)\) has no roots in \(\mathbb{Z}/3\mathbb{Z}\).
        Thus, we can know that \(p(x)\) is irreducible over \(\mathbb{Z}/3\mathbb{Z}\).
        Hence, the elements of \(F_3[x]/(p(x))\) are of the form \(a + bx\), where \(a, b\in \mathbb{Z}/3\mathbb{Z}\).
        Hence, there are \(3\cdot 3 = 9\) elements in \(F_3[x]/(p(x))\). Since \(i^2 + 1 = 0\), we can know that
        \[
        F = \mathbb{Z}/3\mathbb{Z}[x]/(x^2 + 1)\cong \mathbb{Z}/3\mathbb{Z}[i].
        \]
      </p>
      <p>
        <b>Proof.</b> Now, we want to show that \(f: F\to F\) defined by \(f(\alpha) = \alpha^3\) is an automorphism.
        Firstly, we can see that \(f\) is well-defined since for any \(a = b\in F\) we have \(f(a) = a^3 = b^3 = f(b)\).
        Then, we want to show that \(f\) is a homomorphism. Let \(a, b\in F\), then we have
        \[
        f(a)f(b) = a^3b^3 = (ab)^3 = f(ab).
        \]
        Now, we want to show that \(f\) is injective. Suppose that \(f(a) = f(b)\) for some \(a, b\in F\).
        We will have
        \[
        \begin{align}
        a^3 &= b^3 \\
        a^3\cdot b^{-3} &= 1 \\
        (ab^{-1})^3 &= 1.
        \end{align}
        \]
        Since we know that \(F\setminus\{0\}\) is a group under multiplication with order of \(8\).
        Given that \((ab^{-1})^3 = 1\), we can know that \(ab^{-1}\) has order either \(1\) or \(3\).
        If \(ab^{-1}\) has order of \(3\), then we can know that \(3\mid 8\), which is a contradiction.
        Hence, we know that \(ab^{-1} = 1\), which implies that \(a = b\). And we have \(f\) is injective.
        Since \(f\) is a map from \(F\) to \(F\) and \(F\) is finite, we can know that \(f\) is surjective by \(\textbf{the pigeonhole principle}\).
        Therefore, we have \(f\) is an automorphism. \(\blacksquare\)
      </p>
    </section>

    <br>

    <h2>KU 2021 (January)</h2>
    <section id = 'ku_2021_1_1'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Problem 1.</b>
      </p>
        <ul>
          <li>
            Write down all possible Jordan canonical forms for a \( 5 \times 5 \) matrix \( A \) such that \( A^3 = 0 \) (the blocks should have non-increasing size down the diagonal. We work over complex numbers).
          </li>
          <li>
            Let \(N\) be a nilpotent matrix over any field. Prove that \(I + N\) is diagonalizable if and only if \(N = 0\) (I is the identity matrix of the same size).
          </li>
        </ul>
            </div>
        </div>
      <p>
        \(\textbf{Solution 1.}\)
      </p>
      <p>
        \(\textbf{Proof 2.}\)Suppose that \(I\) is an identity matrix and \(N\) is a nilpotent matrix.
        Hence, we know there exists a \(n\in\mathbb{N}\) such that \(N^n = 0\).
        If \(N = 0\), then we can know that
        \[
          I + N = I + 0 = I.
        \]
        Since \(I\) is a diagonal matrix, we can know that \(I + N\) is diagonalizable. To see that, just pick any invertible matrix \(P\).
        Then, we have \(PIP^{-1} = I\). Hence, we have \(I\) is diagonalizable. Now suppose that \((I+N)\) is diagonalizable.
        Then, there exists a diagonal matrix \(D\) and an invertible matrix \(P\) such that \(D = P^{-1}(I + N)P\).
        Then, we have
        \[
        \begin{align}
        P^{-1}(I + N)P &= D\\
        P^{-1}IP + P^{-1}NP &= D\\
        I + P^{-1}NP &= D\\
        P^{-1}NP &= D - I\\
        (P^{-1}NP)^n &= (D - I)^n\\
        P^{-1}N^nP &= (D - I)^n\\
        P^{-1}0P &= (D - I)^n\\
        0 &= (D - I)^n\\
        \end{align}
        \]
        Given that \(D\) and \(I\) are diagonal matrices, we can know that \(D - I\) is also a diagonal matrix.
        Suppose that
        \[
        D - I = \begin{pmatrix}
        a_{11} & 0 & \cdots & 0\\
        0 & a_{22} & \cdots & 0\\
        \vdots & \vdots & \ddots & \vdots\\
        0 & 0 & \cdots & a_{mm}
        \end{pmatrix}.
        \]
        Hence, we can know that
        \[
        (D - I)^n = \begin{pmatrix}
        a_{11}^n & 0 & \cdots & 0\\
        0 & a_{22}^n & \cdots & 0\\
        \vdots & \vdots & \ddots & \vdots\\
        0 & 0 & \cdots & a_{mm}^n
        \end{pmatrix}.
        \]
        Since \((D - I)^n = 0\), we can know that \(a_{ii}^n = 0\) for all \(i\).
        Since \(a_{ii}\) is in a field, we can know that \(a_{ii} = 0\) for all \(i\).
        Hence, we have \(D - I = 0\), which implies that \(D = I\).
        Hence, we have \(I + N = P^{-1}DP = P^{-1}IP = I\), which implies that \(N = 0\). \(\blacksquare\)
      </p>
    </section>

    <br>

    <section>

    </section>

    <br>

    <section id = 'ku_2021_1_3'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
      <p>
        <b>Question 3.</b>
      </p>
      <p>
        (a) Let \( A \) be a real \( n \times n \) matrix such that \( A^2 = 3A \). Prove that \( A \) is similar (over the real numbers) to a diagonal matrix whose diagonal entries are 3 or 0.
      </p>
      <p>
        (b) Let \( A = \begin{bmatrix}
        2 & 1 & 1 \\
        1 & 2 & -1 \\
        1 & -1 & 2
        \end{bmatrix} \) (note that \( A^2 = 3A \)). Find a real matrix \( S \) so that \( S^{-1} A S \) has the form as in part (a).
      </p>
        </div>
        </div>
      <p>
        <b>Proof (a).</b> Given that \(A^2 = 3A\), we can know that \(A^2 - 3A = 0\). Set \(f(x) = x^2 - 3x\), then we have \(f(A) = 0\).
        Hence, we can know that minimal polynomial of \(A\), \(\mu_A(x)\mid f(x)\). Since \(f(x) = x(x - 3)\), we can know that \(\mu_A(x)\) can be \(x(x - 3)\), \(x\) or \(x - 3\).
        If \(\mu_A(x) = x\), then we can know that \(A = 0\), which is a diagonal matrix with all diagonal entries are \(0\).
        If \(\mu_A(x) = x - 3\), then we can know that \(A = 3I\), which is a diagonal matrix with all diagonal entries are \(3\).
        If \(\mu_A(x) = x(x - 3)\), we can see that \(\gcd(x, x - 3) = 1\), which implies that \(\mathbb{R}^n = \ker(A) \oplus \ker(A - 3I)\).
        Hence, we can know that geometric multiplicity of each eigenvalue is equal to the algebraic multiplicity of each eigenvalue, which implies that \(A\) is diagonalizable.
        And the diagonal matrix is the form as in the question. \(\blacksquare\)
      </p>
      <p>
        <b>Solution (b).</b> Given that \(A^2 = 3A\), and \(A\neq 0\) and \(A - 3I\neq 0\), we can know that the minimal polynomial of \(A\) is \(x(x - 3)\).
        Hence, \(A\) has eigenvalues \(0\) and \(3\). Hence, we need to find the eigenvectors of \(A\).
        When the eigenvalue is \(0\), let its eigenvector be \(v_1 = [a, b, c]^T\) and we will have \(A\cdot v_1 = 0\).
        Then we have
        \[
        \begin{align}
        2a + b + c &= 0,\\
        a + 2b - c &= 0,\\
        a - b + 2c &= 0.
        \end{align}
        \]
        Hence, we can find one eigenvector, which is \([1, -1, -1]^T\).
        When the eigenvalue is \(3\), let its eigenvector be \(v_2 = [d, e, f]^T\) and we will have \((A - 3I)\cdot v_2 = 0\).
        \[
        \begin{align}
        -d + e + f &= 0,\\
        d - e - f &= 0,\\
        d - e - f &= 0.
        \end{align}
        \]
        Then, we have two eigenvectors \([1, 1, 0]^T\) and \([0, -1, 1]^T\).
        Suppose that
        \[
        \begin{align}
        S &= \begin{bmatrix}
        1 & 1 & 0\\
        -1 & 1 & -1\\
        -1 & 0 & 1
        \end{bmatrix},\\
        \det(S) &= 1\cdot 1\cdot 1  - 1\cdot ((-1)\cdot 1 - (-1)\cdot(- 1)) = 1 - 1\cdot (-2) = 3\neq 0.
        \end{align}
        \]
        Then, we have
        \[S^{-1}AS = \begin{bmatrix}
        0 & 0 & 0\\
        0 & 3 & 0\\
        0 & 0 & 3
        \end{bmatrix}.
        \]
      </p>
    </section>

  <section id = 'ku_2021_1_4'>
    <div class = 'question-box-container'>
      <div class = 'question-box'>
        <p>
          <b>Question 4.</b> Let \( k \) be a field and \( R = k[X, Y] / I \) where \( I \) is the ideal \( (X^2, Y^2) \). Let \( x, y \) be the image of \( X, Y \) in \( R \).
        </p>
        <p>
          (a) Prove that \( R \) has only one maximal ideal \(\mathfrak{m} = (x, y) \).
        </p>
        <p>
          (b) Prove that any ideal of \( R \) strictly contained in \(\mathfrak{m} \) is principal.
        </p>
      </div>
    </div>
    <p>
      <b>Proof (a) (v1).</b> Firstly, we know that if \(a(X, Y)\in (X^2, Y^2)\), we can have
      \[
      a(X, Y) = X^2f(X, Y) + Y^2g(X, Y) = X(Xf(X, Y)) + Y(Yg(X, Y))\in (X, Y).
      \]
      Thus, we can know that \((X^2, Y^2)\subset (X, Y)\). Then, we can see that \(k[X, Y]/(X, Y)\) is isomorphic to \(k\), which is a field.
      It shows that \((X, Y)\) is a maximal ideal. Now, we want to show that any maximal ideal of \(k[x, y]\) containing \((X^2, Y^2)\) contains \(X\) and \(Y\) by contradiction.
      Suppose that \(M\) is a maximal ideal containing \((X^2, Y^2)\) but it does not contain \(X\) or \(Y\).
      Hence, we can know that \(M + (X)\) is an ideal strictly containing \(M\) and \(M + (Y)\) is an ideal strictly containing \(M\).
      Given that \(M\) is a maximal ideal, we can have \(M + (X) = M + (Y) = k[X, Y]\).
      In that case, we have \(m_1(X, Y)\in M\) and \(f(X, Y)\in k[X, Y]\) such that
      \[
      \begin{align}
        m_1(X, Y) + f(X, Y)X &= 1, \\
      m_1(X, Y) &= 1 - f(X, Y)X.
      \end{align}
      \]
      Since \(m_1(X, Y)\in M\), we have \(X\cdot m_1(X, Y) = X - X^2f(X, Y)\in M\). Given that \(X^2\in M\), we can know that \(X^2f(X, Y)\in M\).
      Thus, we have
      \[
      X = X - X^2f(X, Y) + X^2f(X, Y)\in M,
      \]
      which is a contradiction. Hence, we can have \(x\in M\). For the similar reason, we can also show that \(y\in M\).
      Thus, for any maximal ideal of \(k[X, Y]\) containing \((X^2, Y^2)\) contains \((X, Y)\).
      And we already showed that \((X, Y)\) is a maximal ideal, we can know that \((X, Y)\) is the only maximal ideal containing \((X^2, Y^2)\).
      According to the \(\textbf{Correspondence Theorem of Rings}\), any maximal ideal containing \((X^2, Y^2)\) is in one-to-one correspondence with the maximal ideal of \(k[X, Y]/(X^2, Y^2)\).
        Hence, we can know that \(R\) has only one maximal ideal \((X, Y) + (X^2, Y^2) = (x, y)\). \(\blacksquare\)
    </p>
    <p>
      <b>Proof (a) (v2)</b> Firstly, we want to show that \(\mathfrak{m} = (x, y)\) is a maximal ideal.
      Since \(R = k[X, Y]/(X^2, Y^2)\), if \(r\in R\), then \(r = f(X, Y) + (X^2, Y^2)\), where \(f(X, Y) = aX + bY + cXY + d\) where \(a, b, c, d\in k\).
      Hence, \(r = f(X, Y) + (X^2, Y^2) = aX + bY + cXY + d+ (X^2, Y^2) = aX + (X^2, Y^2) + bY + (X^2, Y^2) + cXY + (X^2, Y^2) + d + (X^2, Y^2)= ax + by + cxy + d\) since \(x, y\) are the images of \(X, Y\) in \(R\).
      Since \(\mathfrak{m} = (x, y)\), we have \(r/\mathfrak{m} = ax + by + cxy + d + (x, y) = d + \mathfrak{m}\).
      Then, we can know that \(R/\mathfrak{m} \cong k\), which is a field. Thus, \(\mathfrak{m}\) is a maximal ideal.
      Suppose that \(J\) is a proper ideal of \(R\). Then, we can know that \(J\) does not contain a unit of \(R\).
      If \(j\in J\), we want to show that \(j = ax + by + cxy\), where \(a, b, c\in k\) by contradiction.
      Suppose that \(j = ax + by + cxy + d\) where \(d\neq 0\). Then we can know that
      \[
      j\cdot xy = dxy \in J.
      \]
      Since \(d\neq 0\), we have \(d^{-1}\in k\). Thus, \(dxy\cdot d^{-1} = xy\in J\).
      If \(xy\in J\) and \(ax + by + cxy + d\in J\), then
      \[
      \begin{align}
      ax + by + cxy + d - c\cdot xy = ax + by + d\in J, \\
      (ax + by + d)\cdot x = ax^2 + bxy + dx = bxy + dx\in J, \\
      bxy + dx - b\cdot xy = dx\in J, \\
      dx\cdot d^{-1} = x\in J.
      \end{align}
      \]
      Now, we have \(xy, x\in J\). Thus, we can know that
      \[
      \begin{align}
      ax + by + cxy + d - ax - cxy = by + d\in J, \\
      (by + d)\cdot y = by^2 + dy = dy\in J, \\
      dy\cdot d^{-1} = y\in J.
        \end{align}
      \]
      Again, we have \(x, y, xy\in J\).
      Thus,
      \[
      d = ax + by + cxy + d - ax - by - cxy \in J.
      \]
      Since \(d\neq 0\), \(d\) is a unit in \(J\), which is a contradiction since \(J\) does not contain a unit.
      Hence, we can know that if \(J\) is a proper ideal of \(R\), then \(j = ax + by + cxy\in (x, y)\).
      Hence, we can know that \(J\subset (x, y)\).
      We know that every proper ideal of \(R\) is contained in a maximal ideal of \(R\).
      Suppose that \(T\) is a maximal ideal of \(R\), then we can know that \(T\) is a proper ideal of \(R\).
      Hence, we can know that \(T\subset (x, y)\). Since \(T\) is a maximal ideal, the only proper ideal contains \(T\) is \(T\) itself.
      Thus, \(T = (x, y)\). Hence, we can know that \(R\) has only one maximal ideal \((x, y)\). \(\blacksquare\)
    </p>
  </section>

    <section id = 'ku_2021_1_5'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Question 5.</b> Find the Galois group of \( x^3 + x + 2021 \) over \( \mathbb{Q} \). (2021 = 43 Ã— 47)
      </p>
            </div>
        </div>
      <p>
        <b>Proof.</b> Firstly, we want to show that the polynomial is irreducible over \( \mathbb{Q} \).
        Given that the degree of the polynomial is degree \(3\). Suppose that it is reducible, then it can only be factored into a polynomial of degree \(2\) and a polynomial of degree \(1\).
        If it can be factored as a polynomial of degree \(1\), it means it has a root in \( \mathbb{Q} \).
        Since we know that \(p(x)\) is an irreducible polynomial over \( \mathbb{Q} \) if and only if it is an irreducible polynomial over \( \mathbb{Z} \).
        For the other direction, we can know that if it is reducible over \( \mathbb{Q} \), then it is reducible over \( \mathbb{Z} \).
        Then we can know that it has a root in \( \mathbb{Z} \). Now, suppose that \(a\) is a root of the polynomial, then we have
        \[
        \begin{align}
        a^3 + a + 2021 &= 0\\
        a^3 + a &= -2021\\
        a(a^2 + 1) &= -2021\\
        a(a^2 + 1) &= -43 \times 47\\
        \end{align}
        \]
        In \(\mathbb{Z}\), we can know that each number of prime factorization. Hence, we can know that \(a^2+1\) is either \(43\) or \(47\).
        Suppose that \(a^2 + 1 = 43\), then we have \(a^2 = 42\), which is not a perfect square. Hence, we have \(a^2 + 1 = 47\), then we have \(a^2 = 46\), which is not a perfect square.
        Hence, it is a contradiction. Therefore, we can know that the polynomial is irreducible over \( \mathbb{Z} \), which implies that it is irreducible over \( \mathbb{Q} \).
        Now, set \(f(x) = x^3 + x + 2021\), we take the derivative of \(f(x)\) and find that it is \(3x^2 + 1\).
        We try to see what the <b>GCD</b> of \(f(x)\) and \(f'(x)\) is. We will use the Euclidean algorithm to find the <b>GCD</b>.
        \[
        \begin{align}
        f(x) &= f'(x)\left(\frac13x\right) + \left(\frac23 x + 2021\right) \\
        f'(x) &= \left(\frac23 x + 2021\right)\left(\frac92x - \frac{54567}{4}\right) + \frac{110279911}{4}\\
        \end{align}
        \]
        Then we can know that the <b>GCD</b> of \(f(x)\) and \(f'(x)\) is \(1\). Hence, we can know that the polynomial is separable.
        Once, we know that \(f(x) = x^3 + x + 2021\) is separable, the galois group of \(f(x)\) over \( \mathbb{Q} \) is the galois group of the splitting field of \(f(x)\) over \( \mathbb{Q} \).
        Since there are three distinct roots in the splitting field of \(f(x)\) over \( \mathbb{Q} \), and there will be an automorphism that maps one root to another root.
        Hence, there are \( 6\) automorphisms in the galois group of \(f(x)\) over \( \mathbb{Q} \).
      </p>
    </section>

    <br>

    <section id = 'ku_2021_1_6'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
        <p>
          <b>Question 6.</b> For a field \( F \) let \( GL_n(F) \) be the group of invertible matrices with entries in \( F \) of size \( n \) under matrix multiplication.
        </p>
          <p>
          (a) Show that any finite subgroup of \( GL_1(F) \) is cyclic.
          </p>
          <p>
          (b) Show that \( GL_n(F) \) always contains a finite subgroup \( H \) that are minimally generated by \( n \) generators (so \( H \) can be generated by \( n \) generators and no \( n-1 \) elements generate \( H \)).
        </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> We want to show that any finite multiplicative subgroup of \( F \) is cyclic.
      </p>
    </section>

    <br>


    <h2 id = 'august_2021'>KU 2021 (August)</h2>
    <section id = 'ku_2021_8_1'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
                <p>
                    <b>Question 1.</b> Let \( G \) denote the abelian group \( \mathbb{Z} \times \mathbb{Z} \) and \( N \) the subgroup of \( G \) generated by \( (4, 1) \) and \( (6, 3) \). Find an explicit isomorphism from \( G/N \) to a direct product of cyclic groups.
                </p>
            </div>
        </div>
        <p>
            Firstly, we write \(\langle\begin{bmatrix} 4\\ 1\end{bmatrix}, \begin{bmatrix}6\\3\end{bmatrix}\rangle \) as a column space generated by \(A\)  such that
            \[
            A = \begin{bmatrix}
            4 & 6\\
            1 & 3
            \end{bmatrix}
            \]
            We first want to calculate the characteristic polynomial of the matrix. We have
            \[
            \begin{align}
            \begin{vmatrix}
            4 - \lambda & 6\\
            1 & 3 - \lambda
            \end{vmatrix} &= (4 - \lambda)(3 - \lambda) - 6\\
            &= \lambda^2 - 7\lambda + 6\\
            &= (\lambda - 1)(\lambda - 6).
            \end{align}
            \]
            Hence, we can see that the matrix has two distinct eigenvalues, which implies that the matrix is diagonalizable: there exists \(P\) such that \(P^{-1}AP = D\), where \(D\) is
            \[
            \begin{bmatrix}
            1 & 0\\
            0 & 6
            \end{bmatrix}.
            \]
          Hence, we can know that the column space of \(A\) is isomorphic to the column space of \(D\).
          Thus, we can see that \(\langle (4, 1), (6, 3)\rangle \cong \langle (1, 0), (0, 6)\rangle \cong \mathbb{Z}\oplus \mathbb{Z}_6\).
          Hence,
          \[
          \mathbb{Z}^2/\langle (4, 1), (6, 3)\rangle \cong \mathbb{Z}^2/\mathbb{Z}\oplus \mathbb{Z}_6 \cong \mathbb{Z}_6.
          \]
          Since \(\gcd(2, 3) = 1\) and \(2\cdot 3 = 6\). We have
          \[
          \mathbb{Z}_6 \cong \mathbb{Z}_2\times \mathbb{Z}_3.
          \]
        </p>
    </section>

    <section id = 'ku_2021_8_2'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 2.</b> In this question, all rings are commutative with unity. Let \( R \) be a ring and \( A, B \) be subrings of \( R \). Let \( AB \) denote the collection of elements of the form \( \sum a_i b_i \) where the sum is finite and \( a_i \in A, b_i \in B \).
          <p>
            (a) Prove that \( AB \) is a commutative ring.
        </p>
          <p>
            (b) Let \( R = \mathbb{C}[x] \), where \( \mathbb{C} \) is the complex numbers. Suppose \( A, B \) are subrings of \( R \) such that \( AB = R \). Show that at least one of \( A, B \) contains a polynomial whose lowest term has degree one (for instance \( x^3 - 2x \)).
          </p>
          <p>
            (c) Assume the same situation as (b). Must one of \( A, B \) be equal to \( R \)?
          </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> Given that \(A\) and \(B\) are two commutative subrings of \(R\) with unity and \(AB = \{ \sum a_i b_i \mid a_i \in A, b_i \in B \}\).
        We can know that \(0\in AB\) since \(0 = 0\cdot 0\) and \(1\in AB\) since \(1\cdot 1 = 1\).
        Then, we want to show that \(AB\) is commutative group under addition. Suppose that \(\alpha = \sum a_i b_i\) and \(\beta = \sum a_i' b_i'\).
        Given that \(a_i\in A\), we can know that \(-a_i\in A\) since \(A\) is a ring, thus
        we have \(-\alpha = -\sum a_ib_i = \sum (-a_i)b_i\in AB\). Since \(AB\subset R\), we can see that \(\alpha + \beta = \beta + \alpha\).
        For the similar reason (i.e. \(AB\subset R\)\), we can have \(\alpha + (\beta + \gamma) = (\alpha + \beta) + \gamma\) for any \(\alpha, \beta, \gamma\in AB\).
        Then, we want to show that \(AB\) is closed under multiplication. Suppose that \(\alpha = \sum a_i b_i\) and \(\beta = \sum a_i' b_i'\).
        Then, we have \(\alpha\beta = (\sum a_i b_i)\cdot( \sum a_i' b_i' )\)
        After that,
      </p>
      <p>
        <b>Proof (b).</b> We will prove it with mathematical contradiction. Suppose that neither \(A\) nor \(B\) contains a polynomial whose lowest term has degree one and \(AB = \mathbb{C}[x]\).
        Suppose that \(a = a_nx^{n} + a_{n-1}x^{n-1} + \dots + a_2x^2 + a_0\) and \(b = b_mx^{m} + b_{m-1}x^{m-1} + \dots + b_2x^2 + b_0\).
        Then we can know that
        \[
        a\cdot b = a_nb_mx^{n+m} + (a_nb_{m-1} + a_{n-1}b_m)x^{n+m-1} + \dots + a_2b_2x^4 + (a_2b_0 + a_0b_2)x^2 + a_0b_0.
        \]
        Given that \(AB = R\) for any \(f(x)\in \mathbb{C}[x]\) there exists \(g\in A, h\in B\) such that \(gh = f(x)\).
        In that case, if \(f(x)\) is a polynomial whose lowest term has degree one, then there exists \(g\in A\) or \(h\in B\) such that
        \[
        gh = f(x) = a_nx^{n} + a_{n-1}x^{n-1} + \dots + a_2x^2 + a_0,
        \]
        which does not contain a polynomial where one of its terms has degree one. Therefore, it is a contradiction, and we can know that at least one of \(A\) or \(B\) contains a polynomial whose lowest term has degree one. \(\blacksquare\)
      </p>
      <p>
        <b>Solution (c).</b>
\      </p>
    </section>

    <section id = 'ku_2021_8_3'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
                <p>
                    <b>Question 3.</b> Find the degree of the splitting field of \( x^4 + 1 \) over \( \mathbb{Q} \). Is this degree the same for the splitting field of \( x^4 + a \) over \( \mathbb{Q} \), with \( a \) any positive integer? You must justify your answer.
                </p>
            </div>
        </div>
        <p>
            <b>Solution.</b> Firstly, we can know that \(x^4 + 1 = (x^2 - i)(x^2 + i)\).
            Since \(i = \cos(\pi/2) + \sin(\pi/2)i = e^{\pi i/2}\) and \(-i = \cos(-\pi/2) + \sin(-\pi/2)i = \cos(-\pi/2) + \sin(3\pi/2)i = e^{3\pi i/2}\)
            Hence, we can know that \(\pm(e^{3\pi i/2})^{1/2} =\pm e^{3\pi i/4} = \pm (-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i) \) and \(\pm(e^{3\pi i/2})^{1/2} =\pm e^{3\pi i/4} = \pm (\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i)\) are the roots of \(x^2 + i\) and \(x^2 - i\), respectively.
            Then, we can know that \(\mathbb{Q}(-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i, \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i)\) is the splitting field of \(x^4 + 1\) over \(\mathbb{Q}\).
            And we want to show that \(\mathbb{Q}(-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i, \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i) = \mathbb{Q}(i, \sqrt{2})\).
            It is not hard to see that \(\mathbb{Q}(i, \sqrt{2})\subset \mathbb{Q}(-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i, \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i)\).
            For the other direction, we can know that
            \[
            \begin{align}
            \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i + \frac{\sqrt{2}}{2} - \frac{\sqrt{2}}{2}i &= \sqrt{2}\\
            \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i - \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i &= \sqrt{2}i.\\
            \dfrac{\sqrt{2}i}{\sqrt{2}} &= i.
            \end{align}
            \]
            Thus, we get \(\mathbb{Q}(-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i, \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i) \subset \mathbb{Q}(i, \sqrt{2})\).
            Hence, we can know that \(\mathbb{Q}(-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i, \frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i) = \mathbb{Q}(i, \sqrt{2})\).
            Then, we need to know the degree of \(\mathbb{Q}(\sqrt{2}, i)\) over \(\mathbb{Q}\). Since \(\sqrt{2}\) is a root of \(x^2 - 2\), which is irreducible over \(\mathbb{Q}\).
            Thus, we have \(\mathbb{Q}(\sqrt{2})\cong \mathbb{Q}[x]/(x^2 - 2)\), which is a degree 2 extension of \(\mathbb{Q}\).
            Then, we can know that \(x^2 + 1\) is the irreducible polynomial of \(i\) over \(\mathbb{Q}(\sqrt{2})\). Thus, we have \(\mathbb{Q}(i, \sqrt{2})\cong \mathbb{Q}(\sqrt{2})[x]/(x^2 + 1)\), which is a degree 2 extension of \(\mathbb{Q}(\sqrt{2})\).
            Therefore,
            \[
                [\mathbb{Q}(\sqrt{2}, i):\mathbb{Q}] = [\mathbb{Q}(\sqrt{2}, i):\mathbb{Q}(\sqrt{2})][\mathbb{Q}(\sqrt{2}):\mathbb{Q}] = 2 \times 2 = 4.
            \]
            Hence, the degree of the splitting field of \(x^4 + 1\) over \(\mathbb{Q}\) is 4. \(\blacksquare\)
        </p>
        <p>
            <b>Solution.</b> However, it is not the case for any positive integer \(a\). For example, let \(a = 4\). Then, we can know that \(x^4 + 4\) is irreducible over \(\mathbb{Q}\).
            Then, we can know that \(x^4 + 4 = (x^2 - 2i)(x^2 + 2i)\). Since \(2i = 2\cos(\pi/2) + 2\sin(\pi/2)i = 2e^{\pi i/2}\) and \(-2i = 2\cos(-\pi/2) + 2\sin(-\pi/2)i = 2\sin(3\pi/2)i = 2e^{3\pi i/2}\).
            Hence, we can get that \(\pm(2e^{\pi i/2})^{1/2} =\pm \sqrt{2}e^{\pi i/4} = \pm \sqrt{2}(\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i) = \pm (1 + i) \) and \(\pm(\sqrt{2}e^{3\pi i/2})^{1/2} =\pm \sqrt{2}e^{3\pi i/4} = \pm \sqrt{2}(-\frac{\sqrt{2}}{2} + \frac{\sqrt{2}}{2}i) =\pm( -1 + i)\) are the roots of \(x^2 + 2i\) and \(x^2 - 2i\), respectively.
            Then, we can know that \(\mathbb{Q}(1 + i, -1 + i)\) is the splitting field of \(x^4 + 4\) over \(\mathbb{Q}\).
            After that, we can show that \(\mathbb{Q}(1 + i, -1 + i) = \mathbb{Q}(i)\). Firstly, we have \(\mathbb{Q}(i)\subset \mathbb{Q}(1 + i, -1 + i)\).
            For the other direction, we can know that
            \[
            \begin{align}
            -1 + i + 1 + i &= 2i\\
            \frac{1}{2}\cdot 2i &= i. \\
            \end{align}
            \]
            Hence, we can know that \(\mathbb{Q}(1 + i, -1 + i) = \mathbb{Q}(i)\).
            Then, we need to know the degree of \(\mathbb{Q}(i)\) over \(\mathbb{Q}\). Since \(i\) is a root of \(x^2 + 1\), which is irreducible over \(\mathbb{Q}\).
            Thus, \(x^2+1\) is the minimal polynomial of \(i\) over \(\mathbb{Q}\). Hence, we have \(\mathbb{Q}(i)\cong \mathbb{Q}[x]/(x^2 + 1)\), which is a degree 2 extension of \(\mathbb{Q}\).
            And it is not \(4\).
        </p>
    </section>



    <section id = 'ku_2021_8_6'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Question 6.</b> Let \( A \) be a square matrix over a field \( K \).
        </p>
        <p>
        (a) Show that if \( A \) is diagonalizable, then so is \( p(A) \) for any \( p \in K[x] \).
        </p>
        <p>
        (b) Let \( K \) be the complex numbers. Show that if \( A^r - A = I \) for some \( r > 0 \), then \( A \) is diagonalizable.
        </p>
        <p>
        (c) Is (b) still true over the real numbers?
      </p>
            </div>
        </div>
        <p>
            <b>Proof (a).</b> Suppose that \(A\) is diagonalizable, then there exists an invertible matrix \(P\) such that \(P^{-1}AP = D\), where \(D\) is a diagonal matrix.
            Then we have
            \[
            \begin{align}
            p(A) &= p(PDP^{-1})\\
            &= Pp(D)P^{-1}.
            \end{align}
            \]
            Since \(D\) is a diagonal matrix, we can know that \(p(D)\) is also a diagonal matrix.
            Hence, we have \(p(A)\) is diagonalizable.\(\blacksquare\)
        </p>
        <p>
          <b>Proof (b).</b> Firstly, we want to show that \(x^r - x - 1\) is separable over the complex numbers.
          We took the derivative of \(x^r - x - 1\), we have \(rx^{r-1} - 1\).
          Then, we want to find the greatest common divisor of \(x^r - x - 1\) and \(rx^{r-1} - 1\) by using the division algorithm.
            \[
          \begin{align}
            x^r - x - 1 &= (rx^{r-1} - 1)\left(\frac1r x\right) + \left(\frac{1-r}{r}\right)x - 1 \\
            rx^{r-1} - 1 &= \left(\frac{1-r}{r}x - 1\right)\left(\frac{r^2}{1-r}x^{r-2} + \frac{r^3}{(1 - r)^2}x^{r-3} + \cdots + \frac{r^r}{(1 - r)^{r-1}}\right) + \frac{r^r}{1 - r} - 1
          \end{align}
            \]
          Then, we can see that \(\gcd(x^r - x - 1, rx^{r-1} - 1) = 1\). Hence, we can know that \(x^r - x - 1\) is separable over the complex numbers.
          In other words, we can know that \(x^r - x - 1\) has \(r\) distinct roots in \(\mathbb{C}\).
          Now, Since \(f(A) = 0\), we denote that \(\mu_A(x)\) as the minimal polynomial of \(A\).
          Then, we can know that \(\mu_A(x)\) divides \(x^r - x - 1\), which implies that \(\mu_A(x)\) has distinct roots in \(\mathbb{C}\) as well.
          Hence, we can write \(\mu_A(x) = (x - \lambda_1)\cdots(x - \lambda_m)\), where each \(\lambda_i\) is the distinct eigenvalues of \(A\).
          Then, we will have
          \[
          \mathbb{C}^n = \ker(A - \lambda_1I) \oplus \cdots \oplus \ker(A - \lambda_mI).
          \]
          In that case, we can know that the geometric multiplicity of each eigenvalue is equal to the algebraic multiplicity of each eigenvalue and \(A\) is diagonalizable. \(\blacksquare\)
        </p>
    </section>

    <h2 id = 'january_2022'>KU 2022 (January)</h2>
      <section id = 'ku_2022_1_1'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
        <p>
          \(\textbf{Problem 1.}\)A square matrix \( A \) is called \(\textit{aperiodic}\) if \( A^m = A^n \) for some integers \( m > n \geq 0 \) (by convention \( A^0 = I \)).
        </p>
        <ul>
            <li>
              Prove that a \( 2 \times 2 \) matrix \( A \) over the real numbers is aperiodic if and only if: \( A^2 = \pm A \) or \( A^m = I \) for some \( m > 0 \).
            </li>
            <li>
              Give an example of a \( 2 \times 2 \) matrix \( A \) over the real numbers such that \( A^{2022} = I \) but \( A^m \neq I \) for any positive integer \( m \lt 2022 \).
          </li>
        </ul>
            </div>
        </div>
      <p>
        <b>Proof(1).</b> Let \( A \) be a \( 2 \times 2 \) matrix over the real numbers.
        If \( A^2 = \pm A \), then we have \( A^4 = A^2 A^2 = (\pm A)(\pm A) = A^2\).
        If \( A^m = I \) for some \( m > 0 \), then we have \( A^{m+1} = A^m\cdot A = I\cdot A = A \), where \(m+1 > 1\).
        For the other direction, without loss of generality, given \(A^m = A^n\) where \(m\gt n\).
        If \(A\) is invertible, then we have \(A^{m-n} = I\) where \(m-n > 0\).
        Firstly, we show that if \(A\) is non-invertible, then we can know that of the eigenvalue is \(0\).
        Since \(A\) is non-invertible, we can know that \(\text{det}(A) = 0\).
        Then we know the characteristic polynomial of \(A\) is \(\chi_A(x) = \text{det}(A - xI)\).
        When we plug in \(x = 0\), then we have \(\chi_A(0) = \text{det}(A - 0I) = \text{det}(A) = 0\).
        In that case, we have \(0\) is an eigenvalue of \(A\). Now we know one of the eigenvalues is \(0\) and we assume that the other eigenvalue is \(\lambda\).
        In that case we can denote the \(\chi_A(x) = (x - 0)(x - \lambda) = x(x - \lambda)\).
        According to the Cayley-Hamilton theorem, we have \(\chi_A(A) = A(A - \lambda I) = A^2 - \lambda A = 0\).
        Then we have \(A^2 = \lambda A\), which implies that \(\frac{1}{\lambda}A^2 = A\). Given we have \(A^m = A^n\).
        We have
        \[
        \begin{align}
          A^n &=  (\frac{1}{\lambda}A^2)^n \\
          &= \frac{1}{\lambda^n}A^{2n} \\
        A^m &= \frac{1}{\lambda^n}A^{2n} \\
        \lambda^n A^m &= A^{n}A^n \\
        \lambda^n A^m &= A^{m}A^m\\
        \lambda^n A^m &= A^{2m}\\
        \end{align}
        \]
        At the same time, it is not hard to get \(A^{2m} = \lambda^mA^m\).
        Then we have \(\lambda^n A^m = \lambda^m A^m\), which implies that
        \[
          A^m(\lambda^m - \lambda^n) = 0.
        \]
        Then, we can know that \(A^m = 0\) or \(\lambda^m = \lambda^n\).
        It \(A^m = 0\), then we can know that \(A\) is nilpotent.
        We know that \(A\) is nilpotent, then we can know that \(A\) has only one eigenvalue which is \(0\). (need to be proved.)
        In that case, we have \(A^2 = 0 \). Then we can get that \(A = 0\) with conditions of \(\text{det}(A) = 0\).
        If \(\lambda^m = \lambda^n\), then we have \(\lambda^n(\lambda^{m-n} - 1)\). Again, if \(\lambda \neq 0\), then we have
        \(\lambda^{m-n} = 1\) where \(\lambda\in \mathbb{R}\). Then we have \(\lambda = \pm 1\). In that case, we have
        \(A^2 = \lambda A = \pm A\).\(\blacksquare\)
      </p>
      <p>
        \(\textbf{Solution(2). }\) Let \( A = \begin{pmatrix} \cos(\frac{2\pi}{2022}) &  -\sin(\frac{2\pi}{2022}) \\  \sin(\frac{2\pi}{2022}) &  \cos(\frac{2\pi}{2022}) \end{pmatrix} \).
        Then we have \( A^{2022} = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = I \) and \( A^m \neq I \) for any positive integer \( m \lt 2022 \).
      </p>
    </section>

    <br>

    <section id = 'ku_2022_1_2'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Question 2.</b> Recall that a square complex matrix \(A\) is called normal if \(AA^* = A^*A\).
      </p>
      <p>
        <b>a).</b> Prove that \(A\) is normal if and only if it is unitarily equivalent to a diagonal matrix.
        (You can quote the fact that any square complex matrix is unitarily equivalent to an
        upper triangular one)
      </p>
      <p>
        <b>b).</b> Prove that a \(2 \times 2\) normal matrix with real entries must be symmetric or has the form
        \(rB\) where \(B\) is a rotation matrix and \(r\) is a real number.
      </p>
            </div>
        </div>
      <p>
        <b>Solution a).</b> Suppose that \(A\) is normal, then we have \(AA^* = A^*A\).
        We know that any square complex matrix is unitarily equivalent to an upper triangular matrix, we let \(A = URU^*\) where \(U\) is a unitary matrix.
        Hence, we have \(A^* = UR^*U^*\), where \(R^*\) is the conjugate transpose of \(R\) and it is lower triangular.
        Then we have
        \[
        \begin{align}
        URU^*UR^*U^* &= UR^*U^*URU^*. \\
        R^*R &= RR^*
        \end{align}
        \]
        Denote \(R = \begin{pmatrix} r_{ij} \end{pmatrix}\), then we have \(R^* = \begin{pmatrix} l_{ij} \end{pmatrix}\), where \(l_{ij} = \overline{r_{ji}}\).
        Then we can know that \(r_{ij} = 0\) when \(i \gt j\), and \(l_{ij} = 0\) when \(i \lt j\).
        Then, we can have the \((i, j)\)th entry of \(RR^*\) is
        \[
        \begin{align}
        RR^*_{ij} &= \sum_{k=1}^n r_{ik}l_{kj} = \sum_{k=1}^n r_{ik}\overline{r_{jk}}\\
        \end{align}
        \]
      </p>
      <p>
        <b>Proof b).</b> Suppose that \(A\) is a normal real \(2\times 2\) matrix such as
        \[
        A = \begin{pmatrix}
        a & b\\
        c & d
        \end{pmatrix}.
        \]
        Then we have \(AA^T = A^TA\), which implies that
        \[
        \begin{align}
        \begin{pmatrix}
        a & b\\
        c & d
        \end{pmatrix}
        \begin{pmatrix}
        a & c\\
        b & d
        \end{pmatrix} &= \begin{pmatrix}
        a & c\\
        b & d
        \end{pmatrix}
        \begin{pmatrix}
        a & b\\
        c & d
        \end{pmatrix}\\
        \begin{pmatrix}
        a^2 + b^2 & ac + bd\\
        ac + bd & c^2 + d^2
        \end{pmatrix} &= \begin{pmatrix}
        a^2 + c^2 & ab + cd\\
        ab + cd & b^2 + d^2
        \end{pmatrix}.
        \end{align}
        \]
        Then we have \(a^2 + b^2 = a^2 + c^2\), which implies that \(b^2 = c^2\).
        It shows that \( b = \pm c\). If \(b = c\), then we have \(A\) is symmetric.
        If \(b = -c\), then we have \(A\) has the form
        \[
        A = \begin{pmatrix}
        a & b\\
        -b & d
        \end{pmatrix}.
        \]
        Then we can get
        \[
        \begin{pmatrix}
        a^2 + b^2 & -ab + bd\\
        -ab + bd & b^2 + d^2
        \end{pmatrix} = \begin{pmatrix}
        a^2 + b^2 & ab - bd\\
        ab - bd & b^2 + d^2
        \end{pmatrix}.
        \]
        We can have \(-ab + bd = ab - bd\), which implies that \(ab = bd\).
        Then we have \(b(a - d) = 0\), which implies that \(b = 0\) or \(a = d\).
        If \(b = 0\), then again we have \(b = c = 0\) and \(A\) is symmetric.
        If \(b\neq 0\) and \(a = d\), then we have
        \[
        A = \begin{pmatrix} a & b \\ -b & a \end{pmatrix}.
        \]
        Let \(r^2 = a^2 + b^2\) for some \(t\in \mathbb{R}\), Then, we have \(0\leq \frac{a^2}{r^2}\lt 1\) since \(b\neq 0\). Hence, we have
        \(-1\leq \frac{a}{r} \lt 1\). Now, we can know that there exists \(\theta\) such that \(\cos(\theta) = \frac{a}{t}\) and \(a = r\cos(\theta)\). Now, fix \(r\).
        Then we have
        \[
        \begin{align}
        a^2 + b^2 = r^2
        r^2\cos^2(\theta) + b^2 &= r^2\\
        r^2 &= t^2(1 - \cos^2(\theta))\\
        b^2 &= r^2\sin^2(\theta)\\
        \end{align}
        \]
        Hence, we know that \(b\) could be \(r\sin(\theta)\) or \(-r\sin(\theta)\). Therefore, we have
        \[
        A = \begin{pmatrix}
        r\cos(\theta) & r\sin(\theta)\\
        -r\sin(\theta) & r\cos(\theta)
        \end{pmatrix} = r\begin{pmatrix}
        \cos(\theta) & \sin(\theta)\\
        -\sin(\theta) & \cos(\theta)
        \end{pmatrix}.
        \]
        or
        \[
        A = \begin{pmatrix}
        r\cos(\theta) & -r\sin(\theta)\\
        r\sin(\theta) & r\cos(\theta)
        \end{pmatrix} = r\begin{pmatrix}
        \cos(\theta) & -\sin(\theta)\\
        \sin(\theta) & \cos(\theta)
        \end{pmatrix}. \blacksquare
        \]
      </p>
    </section>

    <section id = 'ku_2022_1_3'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        \(\textbf{Problem 3. }\) Find the Jordan canonical form and a Jordan basis for
        \(
        A = \begin{pmatrix}
        2 & 2 & -1 \\
        0 & 3 & 0 \\
        1 & -2 & 4
        \end{pmatrix}.
        \)
      </p>
            </div>
        </div>
      <p>
        \(\textbf{Solution. }\) Firstly, we calculate the characteristic polynomial
        \[
        \begin{align}
        \chi_A(x) &= \text{det}\left|
        \begin{matrix}
        x - 2 & 2 & 1\\
        0 & x-3 & 0\\
        -1 & x + 2 & x - 4\\
        \end{matrix}
        \right|\\
        &= -(x-3)((x-2)(x-4) + 1)\\
        &= -(x-3)(x^2 - 6x + 9)\\
        &= - (x - 3)^3
        \end{align}
        \]
        Now we try to identity the minimal polynomial, which only have two options for us: \((x - 3)^2\) or \((x - 3)^3\).
        When we plug in \(A = x\) to \((x - 3)^2\), we have \((A - 3)^2 = 0\).
        Hence, we have the minimal polynomial which is \((x - 3)^2\).
        Hence, we have the rational canonical form and Jordan canonical form
        \[
        R = \begin{pmatrix}
        0 & -9 & 0\\
        1 & 6 & 0\\
        0 & 0 & 3\\
        \end{pmatrix} \qquad
        J = \begin{pmatrix}
        3 & 0 & 0\\
        1 & 3 & 0 \\
        0 & 0 & 3\\
        \end{pmatrix}
        \]
      Since the minimal polynomial is \((x - 3)^2\), we want to find a vector \(v\not\in \ker(A - 3)\) as a maximal vector.
      We find out that \(v = (1, 0, 0)^T\), and we have the eigenvectors \((1, 0, -1)^T, (0, 1, 2)^T\).
      We calculate the \(A\cdot v= (2, 0, 1)^T\). In order to make basis, we will choose \(v, Av\). For the last vector, we will use an
      eigenvector which is linearly independent to \(v, Av\), which is \((0, 1, 2)^T\).
      Thus, the basis for the rational canonical form is
      \[
      P_C = \begin{pmatrix}
      1 & 2 & 0\\
      0 & 0 & 1\\
      0 & 1 & 2\\
      \end{pmatrix}
      \]
      Similarly, we can find the Jordan basis
      \[
      P_C = \begin{pmatrix}
      1 & -1 & 0\\
      0 & 0 & 1\\
      0 & 1 & 2\\
      \end{pmatrix}
      \]
    </p>
      </section>

    <section id = 'ku_2022_1_4'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 4.</b>
          </p>
          <p>
            (a) Prove that any subgroup of \( \mathbb{Z}^2 \) can be generated by at most 2 elements. (You can use the fact that such a subgroup is finitely generated)
          </p>
          <p>
            (b) Let \( G \) be the subgroup of \( \mathbb{Z}^2 \) generated by \( \{(a, b); (c, d)\} \). Suppose that \( \gcd(a, c) = 1 \). Prove that the quotient \( \mathbb{Z}^2 / G \) is isomorphic to \( \mathbb{Z} / \delta \mathbb{Z} \) where \( \delta = |ad - bc| \).
          </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> Suppose that \(G\subset \mathbb{Z}^2\) is a subgroup of \( \mathbb{Z}^2 \) and it is finitely generated by \(n\) elements.
        Then we have \(G = \langle g_1, g_2, \ldots, g_n \rangle\), where \(g_i = \begin{bmatrix} a_i \\ b_i \end{bmatrix}\).
        Let \(d = \gcd(a_1, a_2, \ldots, a_n)\). Then we have \(d\mid a_i\) for all \(i\).
        Hence, we can find \(c_i\)s where \(c_i\in\mathbb{Z}\) such that
        \[
        d = \sum_{i=1}^n c_ia_i.
        \]
        Fix each \(c_i\) and we denote \(b = \sum_{i=1}^n c_ib_i\).
        Since \(d\) is a divisor for each \(a_i\), we have \(r_id = a_i\) for some \(r_i\in\mathbb{Z}\).
        Then we have
        \[
        \begin{bmatrix} a_i \\ b_i \end{bmatrix} = r_i\begin{bmatrix} d \\ b \end{bmatrix} + \begin{bmatrix} 0 \\ b_i - r_ib \end{bmatrix}.
        \]
        Given that each \(b_i - r_ib\) is in \(\mathbb{Z}\), we can find \(d'\in \mathbb{Z}\) such that \(d' = \gcd(b_1 - r_1b, b_2 - r_2b, \ldots, b_n - r_nb)\).
        And we have \(s_i = \frac{b_i - r_ib}{d'}\in \mathbb{Z}\) for all \(i\).
        Hence, we can have
        \[
        \begin{bmatrix} a_i \\ b_i \end{bmatrix} = r_i\begin{bmatrix} d \\ b \end{bmatrix} + s_i\begin{bmatrix} 0 \\ d' \end{bmatrix}.
        \]
        Suppose that \(\begin{bmatrix} x \\ y \end{bmatrix} \in G\), then we have
        \[
        \begin{align}
        \begin{bmatrix} x \\ y \end{bmatrix} &= k_1 \begin{bmatrix} a_1 \\ b_1 \end{bmatrix} + k_2 \begin{bmatrix} a_2 \\ b_2 \end{bmatrix} + \cdots + k_n \begin{bmatrix} a_n \\ b_n \end{bmatrix}\\
        &= k_1\left(r_1\begin{bmatrix} d \\ b \end{bmatrix} + s_1\begin{bmatrix} 0 \\ d' \end{bmatrix}\right) + k_2\left(r_2\begin{bmatrix} d \\ b \end{bmatrix} + s_2\begin{bmatrix} 0 \\ d' \end{bmatrix}\right) + \cdots + k_n\left(r_n\begin{bmatrix} d \\ b \end{bmatrix} + s_n\begin{bmatrix} 0 \\ d' \end{bmatrix}\right)\\
        &= (k_1r_1 + k_2r_2 + \cdots + k_nr_n) \begin{bmatrix} d \\ b \end{bmatrix} + (k_1s_1 + k_2s_2 + \cdots + k_ns_n) \begin{bmatrix} 0 \\ d' \end{bmatrix}.
        \end{align}
        \]
        Thus, we can tell that \(G\) is generated by \( \begin{bmatrix} d \\ b \end{bmatrix} \) and \( \begin{bmatrix} 0 \\ d' \end{bmatrix} \), which implies that \(G\) is generated by at most 2 elements. \(\blacksquare\)
      </p>
      <p>
          <b>Proof (b).</b> Firstly, we have matrix
          \[
            A = \begin{bmatrix}
                a & c \\
                b & d
                \end{bmatrix}.
          \]
          Given that \(\gcd(a, c) = 1\), we can have \(r, s\in \mathbb{Z}\) such that \(ra + sc = 1\) by \(\textbf{BÃ©zout's identity}\).
          Then we have
          \[
          \begin{align}
            \begin{bmatrix}
                a & c \\
                b & d
                \end{bmatrix}\cdot
            \begin{bmatrix}
            r & -c \\
            s & a
            \end{bmatrix} = \begin{bmatrix}
            1 & 0 \\
            rb + sd & ad - bc
            \end{bmatrix}.\\
            \begin{bmatrix}
            1 & 0 \\
            -(rb + dx) & 1\\
            \end{bmatrix}\cdot
            \begin{bmatrix}
            1 & 0 \\
            rb + sd & ad - bc
            \end{bmatrix}
            &=
            \begin{bmatrix}
            1 & 0 \\
            0 & ad - bc
            \end{bmatrix}.
            \end{align}
          \]
        Hence, we can have
        \[
        \begin{bmatrix}
        1 & 0 \\
        -(rb + ds) & 1
        \end{bmatrix} \cdot
        \begin{bmatrix}
        a & c \\
        b & d \\
        \end{bmatrix}
        \cdot \begin{bmatrix}
        r & -c \\
        s & a
        \end{bmatrix} = \begin{bmatrix}
        1 & 0 \\
        0 & ad - bc
        \end{bmatrix}.
        \]
        Let \(K_A = \left\{\alpha \begin{bmatrix} a \\ b\end{bmatrix}, \beta \begin{bmatrix} c \\ d\end{bmatrix}\, \Bigg|\, \alpha, \beta\in \mathbb{Z}\right\}\), then we have
        \[
        K_A = \left\{\begin{bmatrix} 1 \\ 0\end{bmatrix}, \begin{bmatrix} 0 \\ ad - bc\end{bmatrix}, \Bigg|\, \alpha, \beta\in \mathbb{Z}\right\},
        \]
        since there are invertible matrices \(P\) and \(Q\) such that \(PAQ = \begin{bmatrix} 1 & 0 \\ 0 & ad - bc\end{bmatrix}\).
        Hence, we can know that \(K_A\) is generated by at most 2 elements: \( \begin{bmatrix} 1 \\ 0\end{bmatrix} \) and \( \begin{bmatrix} 0 \\ ad - bc\end{bmatrix} \).
        Then we have \(K_A \cong \mathbb{Z}\oplus \mathbb{Z}/(ad - bc)\mathbb{Z}\).
        Therefore,
        \[
        \mathbb{Z}^2 / G \cong (\mathbb{Z}\oplus \mathbb{Z}) / (\mathbb{Z}\oplus \mathbb{Z}/(ad - bc)\mathbb{Z}) \cong \mathbb{Z}/(ad - bc)\mathbb{Z}. \tag*{\(\blacksquare\)}
        \]
      </p>
    </section>

    <section id = 'ku_2022_1_5'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 5.</b> Let \( R = \mathbb{Z}^2 \) equipped with the following addition and multiplication rules:

            \[
            (a, b) + (c, d) = (a + c, b + d) \quad \text{and} \quad (a, b) \times (c, d) = (ac - bd, ad + bc).
            \]

            Prove that \( R \) is a PID.
          </p>
        </div>
      </div>
      <p>
        <b>Proof.</b> Firstly, we want to show that \((R, +)\) forms an abelian group.
        Since \(\mathbb{Z}\) is an abelian group, we have
        \[
        (a, b) + (c, d) = (a + c, b + d) = (c + a, d + b) = (c, d) + (a, b).
        \]
        We know that \((0, 0)\in \mathbb{Z}^2\) is the identity elements. Since
        \[
        (a, b) + (0, 0) = (a + 0, b + 0) = (a, b),
        \]
        For any \((a, b)\in \mathbb{Z}^2\), we have \((-a, -b)\in \mathbb{Z}^2\) such that
        \[
        (a, b) + (-a, -b) = (a - a, b - b) = (0, 0).
        \]
        Thus, there exists an inverse element for each element in \(\mathbb{Z}^2\).
        Now, given that \((a, b), (c, d), (e, f)\in \mathbb{Z}^2\), we have
        \[
        (a, b) + ((c, d) + (e, f)) = (a, b) + (c + e, d + f) = (a + c + e, b + d + f) = (a + c, b + d) + (e, f) = ((a, b) + (c, d)) + (e, f).
        \]
        Thus, we have \((R, +)\) forms an abelian group.
        Then, we want to show that \(R\) forms a ring. We know that \((1, 0)\in \mathbb{Z}^2\) is the identity element for multiplication since for any \((a, b)\in \mathbb{Z}^2\), we have
        \[
        \begin{align}
        (a, b)\times (1, 0) &= (a\cdot 1 - b\cdot 0, a\cdot 0 + b\cdot 1) = (a, b), \\
        (1, 0)\times (a, b) &= (1\cdot a - 0\cdot b, 1\cdot b + 0\cdot a) = (a, b).
        \end{align}
        \]
        Now, we want to show that is associative. Given that \((a, b), (c, d), (e, f)\in \mathbb{Z}^2\), we have
        \[
        \begin{align}
        (a, b)\times ((c, d)\times (e, f)) &= (a, b)\times (c e - d f, cf + de)\\
        &= (a c e - a d f - a d f - b c f, a c f + a d e + b c e - b d f)\\
        &= (ac - b d, a d + b c)\times (e, f)\\
        &= ((a, b)\times (c, d))\times (e, f).
        \end{align}
        \]
        Then we have \((a, b)\times ((c, d)\times (e, f)) = ((a, b)\times (c, d))\times (e, f)\).
        Now, we want to see if the multiplication is distributive. Given that \((a, b), (c, d), (e, f)\in \mathbb{Z}^2\), we have
        \[
        \begin{align}
        (a, b)\times ((c, d) + (e, f)) &= (a, b)\times (c + e, d + f)\\
        &= (ac + ae - bd - bf, ad + af + bc + be)\\
        &= (ac - bd, ad + bc) + (ae - bf, af + be)\\
        &= (a, b)\times (c, d) + (a, b)\times (e, f).
        \end{align}
        \]
        Then we have \((a, b)\times ((c, d) + (e, f)) = (a, b)\times (c, d) + (a, b)\times (e, f)\).
        Hence, we can conclude that \(R\) forms a ring. Now, we want to show that \(R\) is an integral domain.
        Suppose that \((a, b), (c, d)\in \mathbb{Z}^2\) such that \((a, b)\times (c, d) = (0, 0)\).
        Then we have
        \[
        \begin{align}
        (a, b)\times (c, d) &= (ac - bd, ad + bc) = (0, 0)\\
        ac - bd &= 0\\
        ad + bc &= 0.
        \end{align}
        \]
        Then we can have
        \[
        \begin{align}
        d(ac - bd) &= acd - bd^2 = 0\\
        c(ad + bc) &= acd + bc^2 = 0.
        (acd + bc^2 - acd + bd^2) = bc^2 + bd^2 = 0\\
        b(c^2 + d^2) &= 0.
        \end{align}
        \]
        Since \(\mathbb{Z}\) is an integral domain, we have \(b = 0\) or \(c^2 + d^2 = 0\).
        If \(c^2 + d^2 = 0\) and both \(b\) and \(c\) are integers, we can have \(c = 0, d = 0\), which implies that \((c, d) = (0, 0)\).
        If \(c^2 + d^2\neq 0\), we have \(b = 0\). Moreover, we can conclude that \(c\neq 0\) or \(d\neq 0\).
        Without loss of generality, we assume that \(c\neq 0\).
        Then, we can have
        \[
        ac - bd = ac = 0.\qquad ad + bc = ad = 0.
        \]
        Since \(c\neq 0\) and \(ac = 0\), we can say that \(a = 0\). Hence, we can get \((a, b) = 0\).
        Now, we want to show that \(R\) is an integral domain.
      </p>
    </section>

    <section id = 'ku_2022_1_6'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
          <p>
            <b>Question 6.</b> Let \( E/F \) be an algebraic field extension, assuming the characteristic of \( F \) is \( p > 0 \).
            Let \( E' \) be the collection of elements \( x \in E \) such that \( x^q \in F \) for some power \( q = p^n \) (\(q\) may depend on \( x \)).
            <p>
            (a) Prove that \( E' \) is a field.
            </p>
            <p>
            (b) Prove that the extension \([E : E']\) is separable.
          </p>
        </div>
      </div>
      <p>
        <b>Proof (a).</b> Firstly, we can know that \(0\in E'\) since \(0\in E\) and \(0^q = 0\in F\) for any \(q = p^n\).
        For the similar reason, we can see that \(1\in E'\) since \(1\in E\) and \(1^q = 1\in F\) for any \(q = p^n\).
        Now, suppose that \(x\in E'\), which implies that \(x^q\in F\) for some \(q = p^m\). If \(p = 2\). Then, we can know that \(x + x = 2x = 0\), which implies that \(x = -x\).
        Hence, the additive inverse exists in \(E'\) for all \(x\in E'\) when \(p = 2\). If \(p\neq 2\), then \(p\) is an odd prime.
        Since we already have \(x\in E'\) where \(x^q\in F\) and \(q = p^m\), we can know that \(q\) is also an odd number.
        Then we have \((-x)^q = (-1)^qx^q = -x^q \in F\). Thus, we can know that the additive inverse exists in \(E'\) for all \(x\in E'\).
        Now, we want to show that \(x^{-1}\in E'\) as well.
        Given that \(x\in E'\), we have \(x\in E\). Since \(E\) is a field extension, we can know that \(x^{-1} = \frac{1}{x} \in E\).
        Since we know that \(x^{p^m}\in F\), we have \((x^{-1})^{p^m} = \frac{1}{x^{p^m}}\). Since \(x^{p^m}\in F\) and \(F\) is a field and \(x^{p^m}\neq 0\), we have \(\frac{1}{x^{p^m}}\in F\).
        Then, we can know that \(x^{-1}\in E'\). Hence, we can know that every element of \(E'\) has a multiplicative inverse.
        Given that \(E'\subset E\), we can see that \(E'\) inherit the operation properties from \(E\). Hence, we can know that \(E'\) is a field. \(\blacksquare\)
      </p>
      <p>
        <b>Proof (b).</b> Firstly, if \(x\in F\) then we can have \(x\in E'\) since \(x^{p^0} = x\in F\). It shows that \(F\subset E'\).
        Since \(F\) has characteristic \(p\), we can know that \(E'\) has characteristic \(p\) as well.
        According to the following lemma:
      </p>
      <p>
        <b>Lemma 5.3.5</b> Let \( f \in F[x] \) be an irreducible polynomial of degree \( n \). Then \( f \) is separable if either of the following conditions is satisfied:
      </p>
      <p>
        (a) \( F \) has characteristic \(0\), or
        (b) \( F \) has characteristic \( p > 0 \) and \( p \nmid n \).
      </p>
      Suppose that \(\alpha\in E'\) and the minimal polynomial of \(\alpha\) is \(f(x)\in E'[x]\).
      Suppose that \(f(x)\) has degree \(n\) and \(p\mid n\).

    </section>


    <section id = "ku_2022_8_2">
      <div class = 'question-box-container'>
          <div class = 'question-box'>
    <p>
    \(\textbf{Question 2.}\) For \(a, b \in \mathbb{C}\). Let \(M(a, b)\) be the matrix
    \(
    \begin{pmatrix}
    0 & 1 & 0 \\
    0 & 0 & 1 \\
    0 & a & b \\
    \end{pmatrix}.
    \)
    Find the Jordan canonical form of \(M(a, b)\) (depending on the values \(a, b\)).
    </p>
          </div>
      </div>
    <p>
      \(\textbf{Solution. }\)We can get the characteristic polynomial of \(M(a, b)\) is \(\chi_{M(a, b)}(x)=x^3-bx^2-ax = x(x^2 - bx - a)\).
    </p>
    </section>





    <h2 id = '8_2022'>KU 2022 (August)</h2>

    <section id = 'ku_2022_8_1'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Question 1.</b> Let \( V \) be the space of \( 2 \times 2 \) matrices with entries in \( \mathbb{C} \), the complex numbers. Let \( T \) be the operator on \( V \) that takes
        \[
        \begin{bmatrix}
        a & b \\
        c & d
        \end{bmatrix}
        \]
        and outputs
        \[
        \begin{bmatrix}
        a + c & a + b \\
        c + d & b + d
        \end{bmatrix}.
        \]
        Prove that \( T \) is diagonalizable.
      </p>
            </div>
        </div>
      <p>
        Firstly, we know that \(V\) has dimension \(4\) and it has basis
        \[
        \left\{ \begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}, \begin{bmatrix} 0 & 1 \\ 0 & 0 \end{bmatrix}, \begin{bmatrix} 0 & 0 \\ 1 & 0 \end{bmatrix}, \begin{bmatrix} 0 & 0 \\ 0 & 1 \end{bmatrix} \right\}.
        \]
        Now, we define a map \(\varphi: V\to \mathbb{C}^4\) such that
        \[
        \begin{align}
        \varphi\left(\begin{bmatrix}
        1 & 0 \\
        0 & 0
        \end{bmatrix}\right) &= \begin{bmatrix} 1 \\ 0 \\ 0 \\ 0 \end{bmatrix},\\
        \varphi\left(\begin{bmatrix}
        0 & 1 \\
        0 & 0
        \end{bmatrix}\right) &= \begin{bmatrix} 0 \\ 1 \\ 0 \\ 0 \end{bmatrix},\\
        \varphi\left(\begin{bmatrix}
        0 & 0 \\
        1 & 0
        \end{bmatrix}\right) &= \begin{bmatrix} 0 \\ 0 \\ 1 \\ 0 \end{bmatrix},\\
        \varphi\left(\begin{bmatrix}
        0 & 0 \\
        0 & 1
        \end{bmatrix}\right) &= \begin{bmatrix} 0 \\ 0 \\ 0 \\ 1 \end{bmatrix}.
        \end{align}
        \]

      </p>
    </section>

    <br>

    <section id = 'ku_2022_8_3'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Question 3.</b> Let \( M_n(\mathbb{R}) \) be the set of \( n \times n \) matrices with entries in \( \mathbb{R} \). For \( X, Y \in M_n(\mathbb{R}) \), \( Y \) is called \( X \)-consistent if \( X + \alpha Y \) is invertible for all \( \alpha \in \mathbb{R} \).
      </p>
        <p>
        1. Assume \( n > 1 \). Prove that \( X \in M_n(\mathbb{R}) \) is invertible if and only if there is a nonzero \( X \)-consistent matrix.
        </p>
        <p>
        2. If \( X \in M_n(\mathbb{R}) \) is an invertible skew-symmetric matrix (i.e., the transpose of \( X \) is equal to \( -X \)), then \( I_n \) (the identity matrix in \( M_n(\mathbb{R}) \)) is \( X \)-consistent.
      </p>
            </div>
        </div>
      <p>
        <b>Proof (1).</b> Firstly, we want to show that if \(X + \alpha Y\) is invertible for all \(\alpha \in \mathbb{R}\), then \(X\) is invertible.
        We can set \(\alpha = 0\), then we know that \(X + 0\cdot Y = X\) is invertible. Hence, we have \(X\) is invertible.
        For the other direction, let \(N\) to be a nilpotent \(n\times n\) real matrix, such that \(N^m = 0\) for some \(m > 0\).
        Hence, we can see that
        \[
        (I + \alpha N)\cdot (I - \alpha N + \alpha^2 N^2 - \cdots + (-1)^{m-1}\alpha^{m-1}N^{m-1}) = I - \alpha^m N^m = I,
        \]
        for any \(\alpha\in \mathbb{R}\). Thus, we know that \(I + \alpha N\) has an inverse, and it is invertible.
        Hence, we can know that \(\det(I + \alpha N)\neq 0\) for all \(\alpha\in \mathbb{R}\).
        Given that \(X\) is invertible, we can know that \(\det(X)\neq 0\). Then,
        \[
          \det(X + \alpha X\cdot N) = \det(X)\det(I + \alpha N) \neq 0.
        \]
        Thus, we have \(X + \alpha X\cdot N\) is invertible for all \(\alpha\in \mathbb{R}\), and \(X\cdot N\) is \(X\)-consistent. \(\blacksquare\)
      </p>
      <p>
        <b>Proof (2).</b> Suppose that \(X\) is an invertible skew-symmetric matrix. Then we have \(X^T = -X\).
        Suppose that \(\lambda\) is an eigenvalue of \(X\) and \(v\) is the corresponding eigenvector.
        Then we have \(Xv = \lambda v\) and
        \[
        \begin{align}
         \lambda\langle v, v\rangle = \langle \lambda v, v \rangle = \langle Xv, v \rangle = \langle v, X^T v \rangle &= \langle v, -Xv \rangle = \langle v, -\lambda v \rangle = -\overline{\lambda}\langle  v, v \rangle.\\
          (\lambda + \overline{\lambda})\langle v, v \rangle &= 0.
        \end{align}
        \]
        Since \(v\) is an eigenvalue, we have \(\lambda\neq 0\) and \(\langle v, v \rangle > 0\).
        Now, we can know that \(\lambda + \overline{\lambda} = 0\).
        Assume that \(\lambda\) is real. Then we have \(\lambda + \overline{\lambda} = 2\lambda = 0\), which implies that \(\lambda = 0\).
        However, we know that \(\lambda\neq 0\) since \(X\) is invertible. Hence, we can know that \(\lambda\) is not real.
        Then, we can know that \(\lambda\) has to be complex.
        Since \(\det(X + \alpha I) = \det(X - (-\alpha)I)\), we know \(\det(X + \alpha I) = 0\) if and only if \(-\alpha\) is an eigenvalue of \(X\).
        Again, we showed that all eigenvalues of \(X\) are complex. Hence, we can know that \(\det(X + \alpha I) \neq 0\) for all \(\alpha\in \mathbb{R}\).
        Therefore, we showed that \(I\) is \(X\)-consistent. \(\blacksquare\)
        </p>
    </section>

    <br>

    <section id = 'ku_2022_8_4'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
      <p>
        <b>Question 4.</b> Let \( f(x) = x^4 + 5 \in \mathbb{Q}[x] \) and \( K \) denote the splitting field of \( f(x) \) over \( \mathbb{Q} \).
      </p>
        <ul>
          <li>(i) Prove that \( f(x) \) is irreducible over \( \mathbb{Q} \).</li>
          <li>(ii) Find a basis for \( K \) over \( \mathbb{Q} \).</li>
          <li>(iii) Show that Galois group of \( K \) over \( F \) is a non-abelian group of order eight.</li>
        </ul>
        </div>
        </div>
      <p>
        <b>Proof (i).</b> By Eisenstein's criterion, we choose \(p = 5\), then we have \(f(x) = x^4 + 5\) is irreducible over \(\mathbb{Z}\).
        If \(f(x)\) is irreducible over \( \mathbb{Z} \), then it is irreducible over \( \mathbb{Q} \). \(\blacksquare\)
      </p>
      <p>
        <b>Proof (ii).</b> Firstly, we can know that \(x^4 + 5 = (x^2 - \sqrt{5}i)(x^2 + \sqrt{5}i)\).
        We know that \(i = 0 + 1\cdot i = \cos(\pi/2) + \sin(\pi/2)i = e^{\pi i/2}\), then \((\sqrt{5}i)^{1/2} = \sqrt[4]{5}e^{\pi i/4} = \frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i\).
        Similarly, \(-i = 0 + (-1)\cdot i = \cos(-\pi/2) + \sin(-\pi/2)i = e^{-\pi i/2}\), then \((-\sqrt{5}i)^{1/2} = \sqrt[4]{5}e^{-\pi i/4} = \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\).
        Thus, we have
        \[
        x^4 + 5 = \left(x + \frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right)\left(x - \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right)\left(x + \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right)\left(x - \frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right).
        \]
        Thus, we can know that the splitting field of \(x^4 + 5\) is \(\mathbb{Q}\left(\frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i, \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right)\).
        Then, we want to show that \(\mathbb{Q}\left(\frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i, \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right) = \mathbb{Q}\left(\sqrt[4]{5}\sqrt{2}, i\right)\).
        Since
        \[
        \begin{align}
        \sqrt[4]{5}\sqrt{2} &= \frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i + \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i,\\
        \sqrt[4]{5}\sqrt{2}i &= \frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i - \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i,\\
        i &= \dfrac{\sqrt[4]{5}\sqrt{2}i}{\sqrt[4]{5}\sqrt{2}},
        \end{align}
        \]
        we have \(\mathbb{Q}\left(\sqrt[4]{5}\sqrt{2}, i\right)\subset \mathbb{Q}\left(\frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i, \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right)\).
        It is not hard to see that \(\mathbb{Q}\left(\frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i, \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right) \subset \mathbb{Q}\left(\sqrt[4]{5}\sqrt{2}, i\right)\).
        Therefore, we have \(\mathbb{Q}\left(\frac{\sqrt[4]{5}\sqrt{2}}{2} + \frac{\sqrt[4]{5}\sqrt{2}}{2}i, \frac{\sqrt[4]{5}\sqrt{2}}{2} - \frac{\sqrt[4]{5}\sqrt{2}}{2}i\right) = \mathbb{Q}\left(\sqrt[4]{5}\sqrt{2}, i\right)\).
        After that, we want to show that \(x^4 - 20\) is the minimal polynomial of \(\sqrt[4]{5}\sqrt{2}\) over \(\mathbb{Q}\). It is not hard to see that \(\sqrt[4]{5}\sqrt{2}\) is a root of \(x^4 - 20\).
        Then, we can know that there does not exists a root of \(x^4 - 20\) in \(\mathbb{Q}\), which implies that \(x^2 - 20\) cannot be factored as \((x + a)(x^3 + bx + cx + d)\) where \(a, b, c, d\in \mathbb{Q}\).
        We suppose that \(x^4 - 20 = (x^2 + ax + b)(x^2 + cx + d)\). Then we have
        \[
        (x^2 + ax + b)(x^2 + cx + d) = x^4 + (a + c)x^3 + (b + d + ac)x^2 + (ad + bc)x + bd = x^4 - 20.
        \]
        Hence, we have
        \[
        \begin{align}
        a + c &= 0, \\
        b + d + ac &= 0, \\
        ad + bc &= 0, \\
        bd &= 20.
        \end{align}
        \]
        Then, we can know that \(a = -c\) and \(ad + bc = ad - ab = a(d - b) = 0\).
        In that case, we have either \(a = 0\) or \(d - b = 0\). Suppose that (a = 0\). Then, we have \(c = 0\) as well.
        And \(b + d + ac = b + d = 0\), which implies that \(b = -d\). And \(bd = -b^2 = 20\), which is impossible if \(b\in \mathbb{Q}\).
        Then, if \(d - b = 0\), which means that \(d = b\). We can get \(bd = b^2 = 20\). However, \(20\) is not a perfect square in \(\mathbb{Q}\), which is a contradiction.
        Thus, we can know that \(x^2 - 20\) is irreducible in \(\mathbb{Q}\) and it is a minimal polynomial of \(\sqrt[4]{5}\sqrt{2}\). Then, we will have
        \[
        \mathbb{Q}(\sqrt[4]{5}\sqrt{2})\cong \mathbb{Q}[x]/(x^4 - 20),
        \]
        Hence, \([\mathbb{Q}(\sqrt[4]{5}\sqrt{2}): Q] = 4\).
        For the similar reason, we can know that \(x^2 + 1\) has no root in \(\mathbb{R}\), and \(\mathbb{Q}(\sqrt[4]{5}\sqrt{2})\subset \mathbb{R}\).
        Hence, \(x^2 + 1\) is irreducible over \(\mathbb{Q}(\sqrt[4]{5}\sqrt{2})\), which implies that it is the minimal polynomial of \(i\) over \(\mathbb{Q}(\sqrt[4]{5}\sqrt{2})\).
        Then, we can have
        \[
        \mathbb{Q}(\sqrt[4]{5}\sqrt{2})[x]/(x^2 + 1)\cong \mathbb{Q}(\sqrt[4]{5}\sqrt{2})(i) = \mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i)
        \]
        And we can see that \([\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i): \mathbb{Q}(\sqrt[4]{5}\sqrt{2})] = 2\).
        In that case,
        \[
        [\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i): \mathbb{Q}] = [\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i): \mathbb{Q}(\sqrt[4]{5}\sqrt{2})][\mathbb{Q}(\sqrt[4]{5}\sqrt{2}):\mathbb{Q}] = 2\cdot 4 = 8.
        \]
        Thus, we can know that there are \(8\) elements in the basis of the splitting field.
        Then,
        \[
        \begin{align}
        (\sqrt[4]{5}\sqrt{2})^2 &= 2\sqrt{5} \\
        (\sqrt[4]{5}\sqrt{2})^3 &= 2\sqrt{5}\sqrt[4]{5}\sqrt{2} = 2\sqrt[4]{5^3}\sqrt{2} \\
        (\sqrt[4]{5}\sqrt{2})^4 &= 2\sqrt[4]{5^3}\sqrt{2}\sqrt[4]{5}\sqrt{2} = 20 \\
        \end{align}
        \]
        Hence, we can know that the basis of \(\mathbb{Q}(\sqrt[4]{5}\sqrt{2})\) is \(\{1, \sqrt[4]{5}\sqrt{2}, \sqrt{5}, \sqrt[4]{5^3}\sqrt{2}\}\).
        Then, we know the elements in \(\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i)\) is in the form of \(a + b\cdot i\) where \(a, b\in mathbb{Q}(\sqrt[4]{5}\sqrt{2})\).
        Hence, we have the basis of \(\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i)\) as is \(\{1, \sqrt[4]{5}\sqrt{2}, \sqrt{5}, \sqrt[4]{5^3}\sqrt{2}, i, \sqrt[4]{5}\sqrt{2}i, \sqrt{5}i, \sqrt[4]{5^3}\sqrt{2}i\}\).
      </p>
      <p>
        <b>Proof (iii).</b> Firstly, we can know that \(x^4 + 5\) has \(4\) distinct root in the splitting field. Hence, the order of its galois group should be the same as the degree fo the splitting field, which is \(8\).
        Besides that, the element of \(\text{Gal}(\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i)/\mathbb{Q})\) send the roots of \(x^4 + 5\) to the roots.
        Hence, we have several options for the automorphisms:
        \[
        \begin{align}
        \text{id}: \text{id}(\sqrt[4]{5}\sqrt{2}) &= \sqrt[4]{5}\sqrt{2}, \text{id}(i) = i\\
        \sigma_1: \sigma_1(\sqrt[4]{5}\sqrt{2}) &= -\sqrt[4]{5}\sqrt{2}, \sigma_1(i) = -i\\
        \sigma_2: \sigma_2(\sqrt[4]{5}\sqrt{2}) &= \sqrt[4]{5}\sqrt{2}, \sigma_2(i) = -i\\
        \sigma_3: \sigma_3(\sqrt[4]{5}\sqrt{2}) &= -\sqrt[4]{5}\sqrt{2}, \sigma_3(i) = i\\
        \sigma_4: \sigma_4(\sqrt[4]{5}\sqrt{2}) &= \sqrt[4]{5}\sqrt{2}i, \sigma_4(i) = i\\
        \sigma_5: \sigma_5(\sqrt[4]{5}\sqrt{2}) &= -\sqrt[4]{5}\sqrt{2}i, \sigma_5(i) = -i\\
        \sigma_6: \sigma_6(\sqrt[4]{5}\sqrt{2}) &= -\sqrt[4]{5}\sqrt{2}i, \sigma_6(i) = i\\
        \sigma_7: \sigma_7(\sqrt[4]{5}\sqrt{2}) &= \sqrt[4]{5}\sqrt{2}i, \sigma_7(i) = -i\\
        \end{align}
        \]
        Then, we want to show that it is not an abelian group.
        \[
        \begin{align}
        \sigma_6(\sigma_7(\sqrt[4]{5}\sqrt{2})) &= \sigma_6(\sqrt[4]{5}\sqrt{2}i) = \sigma_6(\sqrt[4]{5}\sqrt{2})\sigma_6(i) = -\sqrt[4]{5}\sqrt{2}i\cdot i = \sqrt[4]{5}\sqrt{2}\\
        \sigma_7(\sigma_6(\sqrt[4]{5}\sqrt{2})) &= \sigma_7(-\sqrt[4]{5}\sqrt{2}i) = -\sigma_7(\sqrt[4]{5}\sqrt{2})\sigma_6(i) = -\sqrt[4]{5}\sqrt{2}i\cdot (-i) = -\sqrt[4]{5}\sqrt{2}
        \end{align}
        \]
        Thus, we can see that \(\sigma_6\circ \sigma_7\neq \sigma_7\circ\sigma_6\), which implies that \(\text{Gal}(\mathbb{Q}(\sqrt[4]{5}\sqrt{2}, i)/\mathbb{Q})\) is not abelian. \(\blacksquare\)
      </p>
    </section>

    <br>

    <section id = 'ku_2022_8_5'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
        <b>Question 5.</b> Let \( G \) be a finite group, and set \( Z := Z(G) \), the center of \( G \). Recall that if \( H \) is a subgroup of \( G \), the normalizer of \( H \) is the subgroup \( N_G(H) = \{ g \in G \mid gHg^{-1} = H \} \). Suppose \( G/Z \) is abelian.
      </p>
      <p>
        (i) Prove that if \( H \) is a proper subgroup of \( G \), then \( N_G(H) \) properly contains \( H \).
      </p>
      <p>
        (ii) Use the fact that, if \( P \) is a Sylow subgroup of \( G \) then \( N_G(N_G(P)) = N_G(P) \), to prove that \( G \) is the (internal) direct product of its Sylow subgroups.
      </p>
            </div>
        </div>
      <p>
        <b>Proof (i).</b>  For any \(h\in H\), we have \(h\cdot H\cdot h^{-1} = H\), which implies that \(h\in N_G(H)\).
        Thus, we know that \(H\subset N_G(H)\). Now we want to show that \(N_G(H)\) properly contains \(H\) by contradiction. suppose that \(N_G(H) = H\).
        For any \(z\in Z\), we have \(zh = hz\) for all \(h\in H\) by the definition of the center. It shows that \(zHz^{-1} = H\) for any \(z\in Z\).
        Hence, we can get \(Z\subset N_G(H)\). Since \(H = N_G(H)\), we have \(Z\subset H\).
        Since \( H \) is a proper subgroup of \( G \), we know there exists \(g\in G\) and \(g\notin H\).
        Fix an element \(g\in G\setminus H\) and an element \(h\in H\). Given \(G/Z\) is abelian, we know that \(gh Z = hgZ\).
        In other words, for any \(z_1\in Z\), there exists a \(z_2\in Z\) such that \(ghz_1 = hgz_2\).
        Hence,
        \[
        \begin{align}
        ghz_1 H &= hgz_2 H\\
        gh H &= hg H\text{ for }Z\subset H,\\
        gH &= hg H.
        \end{align}
        \]
        Now, we know there exists \(h_1, h_2\in H\) such that
        \[
        \begin{align}
        gh_1 &= hgh_2, \\
        gh_1h_2^{-1} &= hg \\
        g^{-1}hg &= h_1h_2^{-1}\in H.
        \end{align}
        \]
        Since \(h\) is a random element of \(H\), we have \(g^{-1}Hg = H\), where \(g\notin H\). Thus we have \(g\in N_G(H)\) and \(g\notin H\), which is a contradiction.
        Thus, we can know that \(N_G(H)\) properly contains \(H\). \(\blacksquare\)
      </p>
      <p>
        <b>Proof (ii).</b> Given that \(g\) is a finite group, we suppose that \(|G| = n = p_1^{e_1}\cdot p_2^{e_2}\cdots p_r^{e_r}\), where each \(p_i\) is a distinct prime.
        Since \(p_i^{e_i}\not\mid p_1^{e_1}\cdot p_{i-1}^{e_{i-1}}p_{i+1}^{e_{i+1}}\cdots p_r^{e_r}\), according to \(\textbf{First Sylow's Theorem}\), we can know that the Sylow \(p_i\)-subgroup, \(P_i\), exists and \(|P_i| = p_i^{e_i}\).
        Now, we want to show that \(P_i\cap P_j = \{1\}\), where \(i\neq j\).
        Firstly, we know that \(P_i\cap P_j\) is a subgroup of both \(P_i\) and \(P_j\). Hence, we have \(|P_i\cap P_j|\mid |P_i|\) and \(|P_i\cap P_j|\mid |P_j|\).
        Hence, \(|P_i\cap P_j|\) is a common divisor of \(p_i^{e_i}\) and \(p_j^{e_j}\). Since \(p_i\) and \(p_j\) are prime and \(p_i\neq p_j\), we know that \(\gcd(p_i^{e_i}, p_j^{e_j}) = 1\).
        Thus, we have \(|P_i\cap P_j| = 1\), which implies that \(P_i\cap P_j = \{e\}\).
        Given that \(P_i\) is a Sylow subgroup of \(G\) and we know that \(N_G(N_G(P_i)) = N_G(P_i)\), we can know that \(N_G(P_i) = G\) by contrapositive.
        Hence, we have that each \(P_i\) is a normal subgroup of \(G\).
        (to be continued...)
      </p>
    </section>

    <section id = 'ku_2022_8_6'>
      <div class = 'question-box-container'>
        <div class = 'question-box'>
    <p>
      \(\textbf{Question 6. }\)Let \( R \) be a unique factorization domain satisfying the following property: If \( p \in R \) is a prime element, then there are no proper ideals properly containing \( pR \). Show that:
    </p>
      <ul>
        <li>
          Every prime ideal in \( R \) is a principal ideal.
        </li>
        <li>
          Prove that if \( a, b \in R \) are non-zero, non-units, then \(\langle a, b \rangle = dR \), where \( d \) is the greatest common divisor of \( a \) and \( b \). (Hint: First consider the case that \( a, b \) are relatively prime.)
        </li>
        <li>
          Conclude that \( R \) is a principal ideal domain.
        </li>
      </ul>
        </div>
        </div>
    <p>
      \(\textbf{Proof (a). }\) Suppose that \(I\) is a prime ideal in \(R\).
      Suppose that \(r\in I\) and \(r = p_1\cdots p_n\) for some prime elements \(p_1, \ldots, p_n\) since \(R\) is a unique factorization domain.
      Then we have \(p_1\in I\) or \(p_2\in I\) or \(\cdots\) or \(p_n\in I\). In general, there exists a prime \(p\in I\).
      Hence, we have \(pR \subset I\). Since \(I\) is a prime ideal, it is proper and there are no proper ideals properly containing \(pR\).
      Thus, it forces \(I = pR\). Hence, we have every prime ideal in \(R\) is a principal ideal. \(\blacksquare\)
    </p>

    <p>
      \(\textbf{Proof (b). }\) Suppose that \(a, b\in R\) are non-unit and non-zero elements in \(R\).
      Suppose that \(d\) is the greatest common divisor of \(a\) and \(b\). Then we have \(d\mid a\) and \(d\mid b\).
      It shows that \(a\in dR\) and \(b\in dR\). Hence, we have \(\langle a, b \rangle \subset dR\).
      For the other direction, suppose that \(c\in dR\). Then we have \(c = dr\) for some \(r\in R\).
    </p>
    </section>

    <br>

    <h2>KU 2023 (January)</h2>

      <section id = 'ku_2023_1_1'>
        <div class = 'question-box-container'>
            <div class = 'question-box'>
        <p>
          \(\textbf{Problem 1. }\) Suppose that \( A \) and \( B \) are \( n \times n \) matrices over the complex numbers.
        </p>
          <ul>
            <li>
              Prove that if \( A \) and \( B \) are similar, then \( A \) and \( B \) have the same minimal and characteristic polynomials.
            </li>
            <li>
              Determine, with justification, whether the converse of (i) holds when \( n = 3 \). What about when \( n = 4 \)?
            </li>
          </ul>
            </div>
        </div>
        <p>
          \(\textbf{Proof(1). }\)Suppose that \(A\) and \(B\) are two similar \(n\times n\) matrices.
          Then we have \(A = PBP^{-1}\) for some invertible \(n\times n\) matrices over \(\mathbb{C}\).
          Suppose the characteristic polynomial of \(A\) is \(\chi_A(x)\). Then we have
          Hence, we have
          \[
            \begin{align}
            \chi_A(x) &= \text{det}(xI - A)\\
            &= \text{det}(xI - PBP^{-1})\\
            &= \text{det}(PxIP^{-1} - PBP^{-1})\\
            &= \text{det}(P(xI - B)P^{-1})\\
            &= \text{det}(P)\text{det}(xI - B)\text{det}(P^{-1})\\
            &= \text{det}{P}\text{det}{P^{-1}}\text{det}(xI - B)\\
            &= \text{det}(PP^{-1})\text{det}(xI - B)\\
            &= \text{det}(I)\text{det}(xI - B)\\
            &= \text{det}(xI - B)\\
            &= \chi_B(x).
            \end{align}
          \]
          Thus, we show that the characteristic polynomial of \(A\) and \(B\) are the same.
          Now we need to show that the minimal polynomial of \(A\) and \(B\) are the same.
          Suppose that the minimal polynomial of \(A\) is \(\mu_A(x):=(x-\lambda_1)^{e_1}\cdots(x - \lambda_m)^{e_m}\)
          and the minimal polynomial of \(B\) is \(\mu_B(x):=(x-\lambda_1)^{f_1}\cdots(x - \lambda_m)^{f_m}\).
          Then we have
          \[
            \begin{align}
            \mu_A(A) &= 0\\
            \mu_A(PBP^{-1}) &= (\lambda_1I - PBP^{-1})^{e_1}\cdots(\lambda_mI - PBP^{-1})^{e_m}\\
            &= (P\lambda_1IP^{-1} - PBP^{-1})^{e_1}\cdots(P\lambda_mIP^{-1} - PBP^{-1})^{e_m}\\
            &= P(\lambda_1I - B)^{e_1}P^{-1}\cdots P(\lambda_mI - B)^{e_m}P^{-1}\\
            &= P(\lambda_1I - B)^{e_1}\cdots(\lambda_mI - B)^{e_m}P^{-1}\\
            P(\lambda_1I - B)^{e_1}\cdots(\lambda_mI - B)^{e_m}P^{-1} &= 0\\
            (\lambda_1I - B)^{e_1}\cdots(\lambda_mI - B)^{e_m} &= P^{-1}0P = 0\\
            \end{align}
          \]
          Thus, we can know that \(e_i\geq f_i\) for \(i = 1, \ldots, m\). Similarly, we can know that
          \[
          \begin{align}
            \mu_B(B) &= 0\\
            \mu_B(P^{-1}AP) &= (\lambda_1I - P^{-1}AP)^{f_1}\cdots(\lambda_mI - P^{-1}AP)^{f_m}\\
            &= (P^{-1}\lambda_1IP - P^{-1}AP)^{f_1}\cdots(P^{-1}\lambda_mIP - P^{-1}AP)^{f_m}\\
            &= P^{-1}(\lambda_1I - A)^{f_1}P\cdots P^{-1}(\lambda_mI - A)^{f_m}P\\
            &= P^{-1}(\lambda_1I - A)^{f_1}\cdots(\lambda_mI - A)^{f_m}P\\
            P^{-1}(\lambda_1I - A)^{f_1}\cdots(\lambda_mI - A)^{f_m}P &= 0\\
            (\lambda_1I - A)^{f_1}\cdots(\lambda_mI - A)^{f_m} &= P0P^{-1} = 0\\
          \end{align}
          \]
          Thus, we can know that \(e_i\leq f_i\) for \(i = 1, \ldots, m\). Hence, we have \(e_i = f_i\) for \(i = 1, \ldots, m\).
          Therefore, we show that they share the same minimal polynomial.\(\blacksquare\)
        </p>
        <p>
          \(\textbf{Solution 2.}\) The converse of (i) does hold when \(n = 3\).
          The converse of (i) does not hold when \(n = 4\).
        </p>
      </section>

        <br>

        <section id = 'ku_2023_1_4'>
        <div class = 'question-box-container'>
          <div class = 'question-box'>
        <p>
            <b>Problem 4.</b>Recall that a group \(G\) is said to be solvable if there exists a sequence of subgroups
            \[
                \{e\} = G_0\subset G_2\subset \dots \subset G_{n-1}\subset G_n = G,
            \]
            such that for each \(i\), \(G_i\) is a normal subgroup of \(G_{i+1}\) and the factor group \(G_{i+1}/G_i\) is abelian. Prove
        </p>
        <ul>
            <li>
                If \(G\) is solvable, then any quotient group of \(G\) is solvable.
            </li>
            <li>
                If \(H, K\subset G\) are normal subgroups and both are solvable, prove that \(HK\) is solvable. What is just one of \(H, K\)are normal?
                Verify this, or give a counterexample.
            </li>
        </ul>
            </div>
        </div>
        </section>

        <br>

        <section id = 'ku_2023_1_5'>
        <div class = 'question-box-container'>
          <div class = 'question-box'>
        <p>
          <b>Problem 5.</b> Let \( R \) be an integral domain with quotient field (i.e., field of fractions) \( K \). Let \( \mathcal{J} \) denote the collection of ideals \( (R : \alpha) \) such that \( \alpha \in K \), where \( (R : \alpha) := \{ r \in R \mid r\alpha \in R \} \). Show that \( R \) is a UFD if the following conditions hold (15 points):
        </p>
        <ul>
          <li>
            The ideals in \( \mathcal{J} \) satisfy the ascending chain condition.
          </li>
          <li>
            Every ideal in \( \mathcal{J} \) is principal.
          </li>
        </ul>
        </div>
        </div>
        <p>
          \(\textbf{Proof. }\)Firstly, given that \(R\) is an integral domain, \(\mathcal{J}\) satisfies the ascending chain condition implies that
          there is a maximal element in \(\mathcal{J}\) (i.e. a maximal ideal in \(\mathcal{J}\)). We also know that a maximal ideal is a prime ideal.
          For any principal ideal of \(R\), we can denote it as \(\langle r\rangle\) for some \(r\in R\) where \(r\neq 0\).
          Then, we can know that \(\langle r\rangle \subset (R, \frac{1}{r})\) since \(r\cdot \frac{1}{r} = 1\in R\).
          Hence, we can know that any principal ideal is contained in an ideal in \(\mathcal{J}\).
          Since every ideal in \(\mathcal{J}\) is principal, and it satisfies the ascending chain condition, we can know that
          the collection of principal ideals in \(R\) satisfies the ascending chain condition.
          According to \(\textbf{Proposition A}\), we can know it implies that every non-zero and non-unit element in \(R\) can be written as a finite product of irreducible elements.
          Now, suppose that \(\langle r\rangle \subset (R, \frac{1}{r})\). For any \(s\in (R, \frac{1}{r})\), we can know that \(s\cdot \frac{1}{r} \in R\).
          Then we have \(\frac{s}{r} = t\) for some \(t\in R\). Hence, we have \(s = tr\in \langle r\rangle \).
          Hence, we show that \(\langle r\rangle = (R, \frac{1}{r})\). Suppose that there is an ideal \(I\in \mathcal{J}\) such that \(\langle q\rangle \subset I\), where \(q\) is irreducible in \(R\).
          Since every ideal in \(\mathcal{J}\) is principal, we can know that \(I = \langle m\rangle\) for some \(m\in R\).
          Since \(q\in \langle m\rangle\), we can k
          now that \(q = rm\) for some \(r\in R\). Since \(q\) is irreducible, we can know that either \(m\) or \(r\) is a unit in \(R\).
          If \(m\) is a unit, then we have \(I = R\). If \(r\) is a unit, then we have \(I = \langle q\rangle\).
          Thus, we can know that \(\langle q\rangle \) is a maximal ideal in \(\mathcal{J}\).
        </p>
      </section>

        <br>

        <section id = 'ku_2023_1_6'>
        <div class = 'question-box-container'>
          <div class = 'question-box'>
        <p>
          \(\textbf{Problem 6.}\) Show that \(\mathbb{Q}(\sqrt[3]{2})\) is not contained in \(\mathbb{Q}(\epsilon)\) for any root of unity \(\epsilon \in \mathbb{C}\).
        </p>
        </div>
        </div>
        <p>
          \(\textbf{Proof. }\) We will prove it with mathematical contradiction. Suppose that it is true that  \(\mathbb{Q}(\sqrt[3]{2})\) is contained in \(\mathbb{Q}(\epsilon)\) for some \(n\)th root of unity \(\epsilon \in \mathbb{C}\).
          Firstly, we know that \(\mathbb{Q}(\epsilon)\cong \mathbb{Q}/\Phi_n(x)\), where \(\Phi_n(x)\) is the \(n\)th cyclotomic polynomial. Since \(\Phi_n(x)\) is irreducible over \(\mathbb{Q}\), we can know that \(\Phi_n(x)\) is separable over \(\mathbb{Q}\) since any irreducible polynomial over a characteristic zero field is separable.
          Then, we can know that \(\mathbb{Q}(\epsilon)\) is a galois extension over \(\mathbb{Q}\).
          Since \(\mathbb{Q}(\sqrt[3]{2})\) is a subfield of \(\mathbb{Q}(\epsilon)\), we can know that \(\mathbb{Q}(\sqrt[3]{2})\) is a galois extension over \(\mathbb{Q}\).
          The minimal polynomial of \(\sqrt[3]{2}\) is \(x^3 - 2\), which is irreducible over \(\mathbb{Q}\).
          However, we can know that \(x^3 - 2\) is not separable over \(\mathbb{Q}\) since it does not contain the complex roots in \(\mathbb{Q}(\sqrt[3]{2})\).
          Hence, we have a contradiction. Therefore, we can know that \(\mathbb{Q}(\sqrt[3]{2})\) is not contained in \(\mathbb{Q}(\epsilon)\) for any root of unity \(\epsilon \in \mathbb{C}\).\(\blacksquare\)
        </p>
      </section>



    <h2>KU 2023 (August) </h2>

    <section id = "ku_2023_8_1">
        <div class = 'question-box-container'>
            <div class = 'question-box'>
      <p>
      \(\textbf{Problem 1.}\) Suppose that \(A\) is a square complex matrix such that \(A\) is similar to \(A^n\), for some \(n>1\).
      Prove that the eigenvalues of \(A\) are either \(0\) or roots of unity.
      </p>
            </div>
        </div>
      <p>
        \(\textbf{Proof. }\) Suppose that \(\lambda\) is an eigenvalue of \(A\) and \(v\) is the corresponding eigenvector, and we
        want to show that \(\lambda^m\) is an eigenvalue for \(A^m\) for any \(m\in \mathbb{N}\). We can get
        \[
          \begin{align}
            A v &= \lambda v\\
            A^n v &= \lambda^n v\\
            A^{n^2} v &= \lambda^{n^2} v\\
            A (A^{m-1} v) &= \lambda A^{m-1} v\\
            &= A^{m-1}(\lambda v)\\
            &= \lambda A^{n-1}v\\
            &= \ldots \\
            &= \lambda^n v.
          \end{align}
        \]
        If \(A^n\) is similar to \(A\), then there exists an invertible matrix \(P\) such that \(A^n = P^{-1} A P\).
        We want to show that \(A\) is similar to \(A^{n^m}\) for any \(m\in \mathbb{N}\).
        \[
          \begin{align}
        A^{n^m} &= A^{nm}\\
        &= (P^{-1} A^n P)^{nm}\\
            &= (A^{n^{m-1}})^n\\
            &= (P^{-1} A^{n^{m-1}} P)^n\\
            &= P^{-1} A^{n^{m-1}} P P^{-1} A^{n^{m-1}} P \ldots P^{-1} A^{n^{m-1}} P\\
            &= P^{-1} A^{n^{m-1}} A^{n^{m-1}} \ldots A^{n^{m-1}} P\\
            &= P^{-1} A^{n^{m-1} + n^{m-1} + \ldots + n^{m-1}} P\\
            &= P^{-1} A^{n^m} P.
          \end{align}
        \]
        Hence, we can know that \(\lambda^n\) is an eigenvalue of \(A^n\) and its corresponding eigenvector is \(v\).
        Since we know that \(A\) and \(A^n\) are similar, we have \(\lambda^n\) is an eigenvalue of \(A\).
      </p>
    </section>

    <section id = "ku_2023_8_2">
      <div class = 'question-box-container'>
        <div class = 'question-box'>
    <p>
      \(\textbf{Problem 2.}\) Suppose \(A=
      \begin{pmatrix}
        0 & -1 & 3\\
        1 & -2 & 3\\
        0 & 0 & 2
        \end{pmatrix}
        \).  Calculate \(A^{2023}\).
    </p>
        </div>
      </div>
    <p>
      \(\textbf{Solution. }\)We can get the characteristic polynomial of \(A\) is \(\chi_A(x)=(x - 2)(x+1)^2\).
      Now we need to find the minimal polynomial of \(A\). Given the characteristic polynomial of \(A\), we have two options
      for the minimal polynomial of \(A\), which are \((x-2)(x+1)\) and \((x-2)(x+1)^2\). Firstly, plug \(A\) into \((x-2)(x+1)\) and we have
      \[
        \begin{align}
          (A-2I)(A+I) &=
          \begin{pmatrix}
            -2 & -1 & 3\\
            1 & -4 & 3\\
            0 & 0 & 0
          \end{pmatrix}
          \begin{pmatrix}
            1 & -1 & 3\\
            1 & -1 & 3\\
            0 & 0 & 3
          \end{pmatrix}\\
          &=
          \begin{pmatrix}
            -3 & 3 & 0\\
            -3 & 3 & 0\\
            0 & 0 & 0
          \end{pmatrix} \\
          &\neq 0.
        \end{align}
      \]
      Then it leaves me the only option, which is \((x-2)(x+1)^2\). And we can know that the minimal polynomial
      is the characteristic polynomial, which implies that there is only one Jordan block for the eigenvalue \(-1\).
      Now we can get the Jordan canonical form of \(A\), which is
      \[
        J = \begin{pmatrix}
          -1 & 0 & 0\\
          1 & -1 & 0\\
          0 & 0 & 2
        \end{pmatrix}.
      \]
      Now we need to find the matrix \(P\) such that \(A=PJP^{-1}\).
      Firstly, we need to find the maximal vector of \(A\) for the eigenvalue \(-1\), which is in not in \(\ker(A + I)\).
      Then we get the columns of \(P\) as \(v, (A-2I)v = (1, 1, 0)^T, v_1\), where \(v_1\) is the eigenvector corresponding to the eigenvalue \(2\).
      Hence, we have
      \[
        P = \begin{pmatrix}
          1 & 1 & 1\\
          0 & 1 & 1\\
          0 & 0 & 1
        \end{pmatrix}.
      \]
      And we can get \(P^{-1}\) as follows:
      \[
        P^{-1} = \begin{pmatrix}
          1 & -1 & 0\\
          0 & 1 & -1\\
          0 & 0 & 1
        \end{pmatrix}.
      \]
      Therefore, we have
      \[
    \begin{align}
      J &= P^{-1}AP = \begin{pmatrix}
        -1 & 0 & 0\\
        1 & -1 & 0\\
        0 & 0 & 2
      \end{pmatrix}. \\
      A^{2023} &= PJ^{2023}P^{-1}\\
      &= \begin{pmatrix}
        1 & 1 & 1\\
        0 & 1 & 1\\
        0 & 0 & 1
      \end{pmatrix}
      \begin{pmatrix}
        (-1)^{2023} & 0 & 0\\
        2023(-1)^{2022} & (-1)^{2023} & 0\\
        0 & 0 & 2^{2023}
      \end{pmatrix}
      \begin{pmatrix}
        1 & -1 & 0\\
        0 & 1 & -1\\
        0 & 0 & 1
      \end{pmatrix}\\
      &=\begin{pmatrix}
      1 & 1 & 1\\
      0 & 1 & 1\\
      0 & 0 & 1
    \end{pmatrix}
      \begin{pmatrix}
        -1 & 0 & 0\\
        2023 & -1 & 0\\
        0 & 0 & 2^{2023}
      \end{pmatrix}
      \begin{pmatrix}
        1 & -1 & 0\\
        0 & 1 & -1\\
        0 & 0 & 1
      \end{pmatrix}\\
      &=\begin{pmatrix}
        2022 & -2023 & 2^{2023}+1\\
        2023 & -2024 & 2^{2023} + 1\\
        0 & 0 & 2^{2023}
      \end{pmatrix}
      \end{align}
      \]
      </p>
  </section>

  <br>

  <section id = "ku_2023_8_3">
    <div class = 'question-box-container'>
      <div class = 'question-box'>
    <p>
      \(\textbf{Problem 3. }\) Let \( T: V \rightarrow V \) be a linear operator on the finite dimensional inner product space \( V \) defined over the complex numbers.
    </p>
    <ul>
      <li>(i) Define the adjoint of \( T \).</li>
      <li>(ii) Define what it means for \( T \) to be:
        <ul>
            <li>(a) self-adjoint</li>
            <li>(b) normal.</li>
        </ul>
      </li>
      <li>(iii) Prove \( T \) is normal if and only if \( \|T(v)\| = \|T^*(v)\| \) for all \( v \in V \). Here, \( \|u\| \) denotes the length of the vector \( u \in V \).</li>
      <li>(iv) Give an example of a normal linear operator that is not self adjoint.</li>
    </ul>
        </div>
    </div>
    <p>
      \(\textbf{Solution (1). }\)The adjoint of \(T\) is the function \(T^*: V\to V\) such
      that
      \[
      \langle Tv, w\rangle = \langle v, T^* w\rangle
      \]
       for every \(v, w\in V\).
    </p>
    <p>
      \(\textbf{Solution (2). }\)
    </p>
      <ul>
        <li>(a) \(T\) is self-adjoint if \(T^*=T\).</li>
        <li>(b) \(T\) is normal if \(TT^*=T^*T\).</li>
      </ul>
    <p>
      \(\textbf{Proof (3).}\) Suppose that \(T\) is normal. Then we have \(TT^*=T^*T\).
      Let \(v\in V\). Then we have
      \[
        \begin{align}
          \langle T^*v, T^*v\rangle &= \langle TT^*v, v\rangle\\
          &= \langle T^*T v, v\rangle\\
        \end{align}.
      \]
      Since we know that \((T^*)^* = T\), then we can get that \(\langle T^*T v, v\rangle = \langle T v, T v\rangle\).
      Since we have \(\langle T^*v, T^*v\rangle = \langle T v, T v\rangle\), we can get \(\|T^*v\| = \|T v\|\).
      For the other direction, suppose that \(\|T^*v\| = \|T v\|\) for all \(v\in V\). Then we have
      \[
        \begin{align}
          \langle T^*v, T^*v\rangle &= \langle T v, T v\rangle\\
          \langle T^*v, T^*v\rangle &= \langle TT^*v, v\rangle\\
          \langle T v, T v\rangle &= \langle T^*T v, v\rangle\\
          \langle TT^*v, v\rangle &= \langle T^*T v, v\rangle\\
        \end{align}.
      \]
      Now, we have to show that \(TT^*=T^*T\). For all \(v\in V\), we have
      \[
        \begin{align}
          \langle TT^*v, v\rangle &= \langle T^*T v, v\rangle\\
          \langle TT^*v, v\rangle - \langle T^*T v, v\rangle &= 0\\
          \langle TT^*v - T^*T v, v\rangle &= 0\\
          \langle (TT^* - T^*T) v, v\rangle &= 0\\
        \end{align}.
      \]
      Since for all \(v\neq 0\), we have \(\langle (TT^* - T^*T) v, v\rangle = 0\), we can get \(TT^* - T^*T = 0\), which implies that \(TT^*=T^*T\). \( \blacksquare \)
    </p>
  </section>

  <br>

  <section id = "ku_2023_8_4">
    <div class = 'question-box-container'>
      <div class = 'question-box'>
    <p>
    \(\textbf{Problem 4.}\) Let \( R \) be an integral domain.
    </p>
    <ul>
      <li>(i) Define what it means for \( p \) in \( R \) to be irreducible and for \( p \) to be prime.</li>
      <li>(ii) Give an example (with proof) of an integral domain having an irreducible element that is not prime.</li>
      <li>(iii) Prove that primes are irreducible.</li>
      <li>(iv) Show that if \( R \) is a PID, then irreducible elements are prime.</li>
    </ul>
        </div>
    </div>
    <p>
      \(\textbf{Solution(1). }\) We say that \(p\) is irreducible if \(p = ab\) where \(a, b\in R\), then either \(a\) or \(b\) is a unit.
      We say that \(p\) is prime if \(p\) is not a unit and \(p\mid ab\) where \(a, b\in R\), then either \(p\mid a\) or \(p\mid b\).
    </p>
    <p>
          \(\textbf{Solution(2). }\)Firstly, we want to show that \(3\) is irreducible in \(\mathbb{Z}(\sqrt{-11})\).
          Let \(3 = (a + b\sqrt{-11})(c + d\sqrt{-11})\). Then we have
          \[
            \begin{align}
            3 &= (a + b\sqrt{-11})(c + d\sqrt{-11})\\
            &= ac - 11bd + (ad + bc)\sqrt{-11}\\
            \end{align}.
          \]
          Thus, we have \(ac - 11bd = 3\) and \(ad + bc = 0\).
          Similarly, we can have
          \[
            \begin{align}
            3 &= ac - 11bd - (ad + bc)\sqrt{-11}\\
            3 &= (a - b\sqrt{-11})(c - d\sqrt{-11})\\
            \end{align}.
          \]
          Then, we have
          \[
            9 = 3\cdot 3 = (a + b\sqrt{-11})(c + d\sqrt{-11})(a - b\sqrt{-11})(c - d\sqrt{-11}) = (a^2 + 11b^2)(c^2 + 11d^2).
          \]
          We can know that if \(b\neq 0\), then \(a^2 + 11b^2\geq 11\). Similarly, if \(d\neq 0\), then \(c^2 + 11d^2\geq 11\).
          Now we can conclude that \(b = d = 0\), which implies that \((ac)^2 = 9\). Hence, we have \(ac = \pm 3\).
          Since \(a, c\in \mathbb{Z}\), we can get that, without loss of generality, \(a = -1\) and \(c = -3\) or \(a = 1\) and \(c = 3\).
          Then, we show that \(3 = (-1)(-3)\) or \(3 = (1)(3)\), which implies one of the divisors is a unit.
          Hence, we can know that \(3\) is irreducible in \(\mathbb{Z}(\sqrt{-11})\). \
          Then, we need to show that \(3\) is not prime in \(\mathbb{Z}(\sqrt{-11})\).
          The first observation is that \(3\mid 12 = (1 + \sqrt{-11})(1 - \sqrt{-11})\).
          However, we can know that \(3\nmid (1 + \sqrt{-11})\) and \(3\nmid (1 - \sqrt{-11})\).
          Hence, we can know that \(3\) is not prime in \(\mathbb{Z}(\sqrt{-11})\).
    </p>
    <p>
      \(\textbf{Proof (3). }\) Suppose that \(R\) is an integral domain, and \(p\) is a prime in \(R\).
      Then we can know that \((p)\) is a prime ideal in \(R\).
      If \((p)\) is a prime ideal, then for any \(a, b\in R\) such that \(p = ab\), we have \(a\in (p)\) or \(b\in (p)\)
      according to the definition of prime ideal. Without loss of generality, we assume that \(a\in (p)\).
      Then according to the definition of principal ideal, we have \(a = pr\) for some \(r\in R\).
      THen, we have \(p = ab= prb\), which implies that \(ar = 1\). Hence, we can know that \(a\) is a unit.
      In that case, we have for any \(ab = p\), either \(a\) or \(b\) is a unit. Therefore, we show that \(p\) is irreducible. \[ \tag*{$\square$} \]
    </p>
    <p>
      \(\textbf{Proof (4). }\) Suppose that \(R\) is a principal ideal domain, and \(p\) is irreducible in \(R\).
      Let \(I\) to be any ideal containing \((p)\). Firstly, we can know that \(I\) is generated by some \(a\in R\) given
      \(R\) is principal ideal domain. Then we have \(I = (a)\) and \((p)\subset (a)\).
      Thus, we have \(p = ar\) for some \(r\in R\). Since \(p\) is irreducible, we have either \(a\) or \(r\) is a unit.
      If \(a\) is a unit, then \((a)\) is an ideal containing a unit, which implies that \((a) = R\). If \(r\) is a unit, then
      there exists \(u\in R\) such that \(ru = 1\). Then we have
      \[
      \begin{align}
        p &= ar\\
        pu &= aru\\
        pu &= a\\
      \end{align}.
      \]
      Thus, we have \(a\in (p)\), which implies that \((a) = (p)\). Thus, we have the only ideals containing \((p)\) are \((p)\) and \(R\).
      Therefore, we show that \((p)\) is a maximal ideal. Since \(R\) is a principal ideal domain, we know that
      \(R\) is an integral domain. Since every maximal domain is a prime ideal in an integral domain, we have \((p)\) is a prime ideal.
      Therefore, we have \(p\) is a prime in \(R\). \(\blacksquare\)
    </p>
  </section>

  <br>

  <section id = "ku_2023_8_5">
    <div class = 'question-box-container'>
      <div class = 'question-box'>
    <p>
      \(\textbf{Problem 5.}\) For the polynomial \( p(x) = x^4 - 4 \) find, with full justification:
    </p>
    <ul>
      <li>
        (i) The splitting field \( K \) of \( p(x) \) over \( \mathbb{Q} \) and \( [K : \mathbb{Q}] \).
      </li>
      <li>
        (ii) The Galois group of \( K \) over \( \mathbb{Q} \).
      </li>
      <li>
        (iii) The intermediate fields between \( K \) and \( \mathbb{Q} \).
      </li>
    </ul>
        </div>
    </div>
    <p>
      \(\textbf{Solution(1). }\) Firstly, we need to find the roots of \(p(x)\). We can get the roots of \(p(x)\) as follows:
      \[
        \begin{align}
          p(x) &= x^4 - 4\\
          &= (x^2 - 2)(x^2 + 2)\\
          &= (x - \sqrt{2})(x + \sqrt{2})(x - i\sqrt{2})(x + i\sqrt{2}).
        \end{align}
      \]
      Then, we can know that the splitting field \(K\) of \(p(x)\) over \(\mathbb{Q}\) is \(K = \mathbb{Q}(\sqrt{2}, i)\).
      Firstly, we know that \([\mathbb{Q}(\sqrt{2}): \mathbb{Q}]\) is 2 since \(x^2 - 2\) is irreducible in \(\mathbb{Q}\).
      \[
        [K: \mathbb{Q}] = [\mathbb{Q}(\sqrt{2}, i): \mathbb{Q}(\sqrt{2})][\mathbb{Q}(\sqrt{2}): \mathbb{Q}]
      \]
      Since we can know that \(\mathbb{Q}\subset \mathbb{Q}(\sqrt{2})\), and we can know that \(x^2 + 1\) is irreducible in \(\mathbb{Q}[x]\)
      by using the Eisenstein's criterion with \(p = 2\). Thus, we can know that \([\mathbb{Q}(\sqrt{2}, i): \mathbb{Q}(\sqrt{2})] \leq 2\).
      Thus, we only have two options: the degree is either 1 or 2. If the degree is 1, then we have \(i\in\mathbb{Q}(\sqrt{2})\).
      Then we have \(i = a + b\sqrt{2}\) for some \(a, b\in\mathbb{Q}\). Then we have \(i^2 = -1 = (a + b\sqrt{2})^2\geq 0\), which is a contradiction.
      In that case, we can know that \([\mathbb{Q}(\sqrt{2}, i): \mathbb{Q}(\sqrt{2})] = 2\). Therefore, we have
      \[
        [K: \mathbb{Q}] = [\mathbb{Q}(\sqrt{2}, i): \mathbb{Q}(\sqrt{2})][\mathbb{Q}(\sqrt{2}): \mathbb{Q}] = 2\cdot 2 = 4.
      \]
    </p>
    <p>
      \(\textbf{Solution(2). }\)We need to determine \(\text{Gal}(K/ \mathbb{Q})\). Firstly, we know that \(x^2 - 4\) has \(4\) distinct roots.
      Hence, we can know that \(|\text{Gal}(K/\mathbb{Q})| = [K: \mathbb{Q}] = 4\).
      We know there are two group of order \(4\), which are \(\mathbb{Z}_4\) and \(\mathbb{Z}_2\times\mathbb{Z}_2\). Now, we list all the automorphisms:
      \[
      \begin{align}
        \sigma_1(\sqrt{2}) &= \sqrt{2}, \sigma_1(i) = i\\
        \sigma_2(\sqrt{2}) &= -\sqrt{2}, \sigma_2(i) = -i\\
        \sigma_3(\sqrt{2}) &= -\sqrt{2}, \sigma_3(i) = i\\
        \sigma_4(\sqrt{2}) &= \sqrt{2}, \sigma_4(i) = -i.
        \end{align}
      \]
      Thus, we can see that for any \(\sigma_i\), we have \(\sigma_i^2 = \text{id}\). Therefore, we have \(\text{Gal}(K/\mathbb{Q}) \cong \mathbb{Z}_2\times\mathbb{Z}_2\).
    </p>
    <p>
        Since \(\text{Gal}(K/\mathbb{Q})\cong \mathbb{Z}_2\times\mathbb{Z}_2\) and \(|\text{Gal}(K/\mathbb{Q})| = 4\), we can know the order of any subgroup of \(\text{Gal}(K/\mathbb{Q})\) has to be 1, 2, or 4.
        Thus, for any \(\mathbb{Q}\subset L\subset K\), we have \([K: L] = 1, 2, \text{ or } 4\). For degree of \(1\), we have \(L = \mathbb{Q}\); For degree of \(4\). we have \(L = K\).
        Now, to identify the intermediate fields of degree 2, we need to find the fixed fields of the subgroups of order 2. We have three subgroups of order 2, which are \(\{id, \sigma_2\}\), \(\{id, \sigma_3\}\), and \(\{id, \sigma_3\}\).
        The fixed fields of these subgroups are \(\mathbb{Q}(\sqrt{2}i)\) \(\mathbb{Q}(\sqrt{2})\), and \(\mathbb{Q}(i)\), respectively.
    </p>
  </section>

  <br>

  <section id = "ku_2023_8_6">
    <div class = 'question-box-container'>
      <div class = 'question-box'>
    <p>
      \(\textbf{Problem 6.}\) Consider the alternating group \( A_5 \), i.e., the subgroup of the symmetric group \( S_5 \) consisting of even permutations.
    </p>
      <ul>
        <li>
          What are the possible number of subgroups of order four?
        </li>
        <li>
          Explain why any two subgroups of order four are isomorphic.
        </li>
        <li>
          Describe the structure of subgroups of order four.
        </li>
        <li>
          Find five subgroups of order four.
        </li>
        <li>
          Using the fact that \( A_5 \) has 44 elements of order 3 or 5 explain why the subgroups in (iv) are the only subgroups of order four.
        </li>
      </ul>
        </div>
    </div>
      <p>
        \(\textbf{Solution(1). }\)We firstly need to calculate the order of \(A_5\).
        We know that the order of \(S_5\) is \(5!\). Since we know that
        \[
          \frac{S_5}{A_5} = \{-1, 1\} = \mathbb{Z}/2\mathbb{Z},
        \]
        we can know that the order of \(A_5\) is \(5!/2 = 60 = 5\cdot 3\cdot 2^2\).
        Since \(2^2\not\mid 5\cdot 3\), we can know that any group of order \(4\) is a Sylow \(2\)-subgroup.
        According to the Sylow's theorem, we have the possible number \(n_2\) of Sylow \(2\)-subgroups is in the form of
        \[
          n_2 \equiv 1 \pmod{2} \text{ and } n_2\mid 15.
        \]
        Therefore, we have possible number of subgroups of order four is \(n_2 = 1, 3, 5, 15\).
      </p>
      <p>
        \(\textbf{Proof(2). }\)Let \(H_1\) and \(H_2\) be two subgroups of order four.
        According to the Sylow's theorem, we have \(H_1\) and \(H_2\) are Sylow \(2\)-subgroups, and they
        conjugate to each other since they have the same order. Therefore, we have \(H_1\) and \(H_2\) are isomorphic.
      </p>
      <p>
        \(\textbf{Solution(3). }\) We know there are two possible structures of subgroups of order four, which are
        \(V_4 \cong \mathbb{Z}/2\mathbb{Z}\times \mathbb{Z}/2\mathbb{Z}\) and \(\mathbb{Z}/4\mathbb{Z}\).
        We can find one subgroup of order \(4\), which is
        \[
          H = \{e, (12)(34), (13)(24), (14)(23)\}\cong V_4.
        \]
        Since all subgroups of order \(4\) are isomorphic, we have all subgroups of order \(4\) are isomorphic to \(V_4\).
      </p>
      <p>
        \(\textbf{Solution(4). }\)We can find five subgroups of order \(4\), which are
        \[
        \begin{align*}
          H_1 &= \{e, (12)(34), (13)(24), (14)(23)\}\\
          H_2 &= \{e, (12)(35), (13)(25), (15)(23)\}\\
          H_3 &= \{e, (12)(45), (14)(25), (15)(24)\}\\
          H_4 &= \{e, (13)(45), (14)(35), (15)(34)\}\\
          H_5 &= \{e, (23)(45), (24)(35), (25)(34)\}\\
        \end{align*}
        \]
      </p>
      <p>
        \(\textbf{Proof(5). }\)We know that \(A_5\) has \(44\) elements of order \(3\) or \(5\).
        Since we show that every subgroup of order \(4\) is isomorphic to \(V_4\), we can know that the element of order
        \(3\) and order \(5\) cannot be in subgroup of order \(4\).
        Hence, there are \(60 - 44\ = 16\) elements to form subgroup of order \(4\). According to the Sylow's theorem,
        and we already found out there are \(5\) subgroups of order \(4\). In that case, the number of subgroup of order \(4\)
        is either \(5\) or \(15\). Now we want to show that for any two subgroups \(H_1, H_2\) of order \(4\), we only have two options:
        \[
          H_1\cap H_2 = \{e\} \text{ or } H_1 = H_2.
        \]
        There exists \(g\in G\) such that \(H_1 = gH_2g^{-1}\).
        Since \(h_1 \in H_1\), then we know that there exists \(h_2\in H_2\) such that
        \[
          h_1 = gh_2g^{-1}.
        \]
      </p>
  </section>

  <br>

  <section>
    <div class = 'question-box-container'>
      <div class = 'question-box'>
    <p>
      \(\textbf{Problem 6. }\)Consider the ring extension \(\mathbb{Z} \subseteq R\), where \(R := \mathbb{Z}[\sqrt[3]{2}]\) denotes the smallest subring of \(\mathbb{R}\) containing \(\mathbb{Z}\) and the real cube root of \(2\).
    </p>
    <ul>
      <li>Find, with proof, the kernel of the surjective ring homomorphism \(\phi : \mathbb{Z}[x] \to R\) taking \(f(x)\) in \(\mathbb{Z}[x]\) to \(f(\sqrt[3]{2})\) in \(R\).</li>
      <li>Find primes \(p, q \in \mathbb{Z}\) such that \(pR\) is a prime ideal and \(qR\) is not a prime ideal.</li>
    </ul>
        </div>
    </div>
    <p>
      \(\textbf{Solution 1. }\) We want to find the kernel of the surjective ring homomorphism \(\phi : \mathbb{Z}[x] \to R\).
      Since \(\ker(\phi)\) is the set of all polynomials \(f(x)\) in \(\mathbb{Z}[x]\) such that \(f(\sqrt[3]{2}) = 0\), we have
      \[
        \ker(\phi) := \{f(x) \in \mathbb{Z}[x] \mid f(\sqrt[3]{2}) = 0\}.
      \]
      We know that \(x^3 - 2\) is the minimal polynomial of \(\sqrt[3]{2}\) over \(\mathbb{Z}\).
      Since \(x^3 - 2\) is irreducible in \(\mathbb{Z}[x]\) by using the Eisenstein's criterion with \(p = 2\), we have
      \[
        \ker(\phi) = \langle x^3 - 2\rangle.
      \]
      \(\textbf{Proof. }\) For one direction, we want to show that \(\langle x^3 - 2\rangle \subset \ker(\phi)\).
      For any \(f(x)\in \langle x^3 - 2\rangle\), we have \(f(x) = (x^3 - 2)g(x)\) for some \(g(x)\in \mathbb{Z}[x]\).
      Then we have \(f(\sqrt[3]{2}) = ((\sqrt[3]{2})^3 - 2)g(\sqrt[3]{2}) = 0\). Hence, we have \(f(x)\in \ker(\phi)\).
      For the other direction, we want to show that \(\ker(\phi) \subset \langle x^3 - 2\rangle\).
      Since \(x^3 - 2\) is irreducible in \(\mathbb{Z}[x]\), and we can know that there is no polynomial with degree less than \(3\) in \(\ker(\phi)\).
      Since \(\mathbb{Z}\) is a Unique Factorization Domain by the Fundamental Theorem of Arithmetic, we can know that \(\mathbb{Z}[x]\) is a Unique Factorization Domain.
      Let \(f(x)\in \ker(\phi)\). Then we have \(f(x) = (x^3 - 2)g(x) + r(x)\) for some \(g(x), r(x)\in \mathbb{Z}[x]\) such that \(\deg(r(x)) \lt 3\).
      Hence, we have \(f(\sqrt[3]{2}) = 0 + r(\sqrt[3]{2}) = 0\), which implies that \(r(x) = 0\). Therefore, we have \(f(x) = (x^3 - 2)g(x)\), which implies that \(f(x)\in \langle x^3 - 2\rangle\).
      Therefore, we have \(\ker(\phi) = \langle x^3 - 2\rangle\). \(\blacksquare\)
    </p>
    <p>
      \(\textbf{Solution 2. }\) We want to find primes \(p, q\in \mathbb{Z}\) such that \(pR\) is a prime ideal and \(qR\) is not a prime ideal.
      Since \(\mathbb{Z}[\sqrt[3]{2}] = \{a + b\sqrt[3]{2} + c(\sqrt[3]{2})^2 \mid a, b, c\in \mathbb{Z}\}\), we have \(\sqrt[3]{2}, \sqrt[3]{2}^2\in R\).
      Since \(\sqrt[3]{2}\cdot\sqrt[3]{2}^2 = 2\), and \(2\not\mid \sqrt[3]{2}\) and \(2\not\mid \sqrt[3]{2}^2\), we can know that \(2\) is not prime in \(R\).
      Since \(pR\) is a prime ideal if and only if \(p\) is a prime in \(R\), we can know that \(2R\) is not a prime ideal in \(R\).
      Now, we want to show that \(3\) is still prime in \(R\).
      Suppose that \(3 = (a + b\sqrt[3]{2} + c\sqrt[3]{2}^2)(d + e\sqrt[3]{2} + f\sqrt[3]{2}^2)\) for some \(a, b, c, d, e, f\in \mathbb{Z}\).
      Then we have
    </p>

  </section>

    <br>

    <h2>
      K-State 2022(1)
    </h2>

  <section id = "k_state_2022_1">
    <div class = 'question-box-container'>
      <div class = 'question-box'>
    <p>
      \(\textbf{K-State 2022(1)}\) Let \( H \) be a subgroup of a group \( G \). Consider the subgroup
          \[ L = \{ (h, h) \mid h \in H \} \]
          of \( H \times G \). Prove that \( L \) is a normal subgroup in \( H \times G \) if and only if \( H \) is contained in
        the center of \( G \).
    </p>
        </div>
    </div>
    <p>
      \(\textbf{Proof. }\)Firstly, we show that \( L \) is a normal subgroup in \( H \times G \) if \( H \) is contained in the center of \( G \) (i.e. \(Z(G)\)).
      Suppose that \(H\subset Z(G)\). Let \((h,g)\in H\times G\) and \((h', h')\in L\). Then
      \[
        \begin{align}
          (h, g)(h', h')(h, g)^{-1} &= (h, g)(h', h')(h^{-1}, g^{-1})\\
          &= (h, g)(h'h^{-1}, h'g^{-1})\\
          &= (h h' h^{-1}, g h'g^{-1})\\
        \end{align}
      \]
      Since \(H\subset Z(G)\), we have \(ghg^{-1}=h\) for any \(g\in G\). Thus, we have
      \[
        (h, g)(h', h')(h, g)^{-1} = (h h' h^{-1}, h h' h^{-1}) = (h', h')\in L.
      \]
      Hence, we show that \(L\) is a normal subgroup in \(H\times G\).
      Now we show that if \(L\) is a normal subgroup in \(H\times G\), then \(H\subset Z(G)\).
      Suppose that \(L\) is a normal subgroup in \(H\times G\). Let \(h\in H\) and \(g\in G\). Then
      \[
        \begin{align}
          (h, g)(h_1, h_1)(h, g)^{-1} &= (h_2, h_2)\\
        \end{align}
      \]
      for some \(h_1, h_2\in H\).
      Since \((e, g)\in H\times G\), we have
      \[
        \begin{align}
          (e, g)(h_1, h_1)(e, g)^{-1} &= (e, g)(h_1, h_1)(e, g^{-1})\\
          &= (eh_1e, gh_{1}g^{-1})\\
          &= (h_1, gh_1g^{-1})\\
          &= (h_2, h_2)\\
        \end{align}
      \]
      Hence, we can get \(h_1=h_2\). Thus, we have \(gh_1g^{-1}=h_1\) for any \(g\).
      Therefore, we show that \(H\subset Z(G)\). \(\blacksquare\)
    </p>
    </section>

    <!-- <section id = 'k_state_2022_4'>
    <h2>K-State 2022(4)</h2>
    <p>
      Let \( R \) be a ring and \( M \) be a left \( R \)-module. For each element \( m \in M \), define
      \[
      \text{Ann}_R(m) = \{ r \in R \mid rm = 0 \}.
      \]
      Prove that \(\text{Ann}_R(m)\) is a left ideal of \( R \).
      Give an example of \( R, M, \) and \( m \in M \) such that \(\text{Ann}_R(m)\) is not a right ideal.
    </p>
    <p>
      \(\textbf{Proof. }\)Let \(r\in R \) and \(r'\in \text{Ann}_R(m)\). Then we have \(rr'\in \text{Ann}_R(m)\) since
      \[
        (rr')m = r(r'm) = r0 = 0.
      \]
      It shows that \(r\text{Ann}_R(m)\subset \text{Ann}_R(m)\) is a left ideal of \(R\).
    </p>
    </section> -->


    <section id = "References">
    <h2>References</h2>
    <ul>
      <li>
        <a href="https://archive.math.ksu.edu/course?course=qe_algebra">Qualifying Exams Kansas State Mathematics Ph.D. Program (Algebra Archive)</a>
      </li>
    </ul>
  </section>

  </body>
</html>
