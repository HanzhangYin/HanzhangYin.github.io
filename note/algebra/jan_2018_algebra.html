<h1>KU 2018 (January)</h1>
<section id='ku_2018_1_1'>
    <div class='question-box-container'>
        <div class='question-box'>
            <p>
                <b>Question 1.</b> Let \( R = \mathbb{C}[x, y, z] \) be the ring of polynomials in 3 variables over the
                complex numbers.
            </p>
            <p>
                (a) Show that \( I = (x, y) \) is a prime ideal in \( R \).
            </p>
            <p>
                (b) Let \( J = (x^2, y^2) \). Prove that for any collection of polynomials \( \{f_1, f_2, \ldots, f_n\} \)
                such that the product \( f_1 f_2 \cdots f_n \) is in \( J \), we can find a subset of at most 3 polynomials
                whose product is already in \( J \).
            </p>
            <p>
                (c) Let \( K = (x^2 y^2, y^2 z^2, z^2 x^2) \). Prove that for any collection of polynomials \( \{f_1, f_2,
                \ldots, f_n\} \) such that the product \( f_1 f_2 \cdots f_n \) is in \( K \), we can find a subset of at most
                9 polynomials whose product is already in \( K \).
            </p>
        </div>
    </div>
    <p>
        <b>Proof (a).</b> We will prove that \(I\) is a prime ideal in \(R\) by contrapositive. Suppose that \(f, g\in R\)
        and neither \(f\) nor \(g\) is in \(I\).
        Then, we can know that \(f\) and \(g\) do not contain a term such as \(az^n\) or \(b\), where \(a, b\in
        \mathbb{C}\) since there is no \(h\in R\) such that \(xh = az^n\) or \(yh = az^n\) or \(xh = b\) or \(yh = b\).
        Thus, we can write \(f = f' + a_nz^n + a_{n-1}z^{n-1} + \dots + a_1z_1 + a_0\) and \(g = g' + b_mz^m +
        b_{m-1}z^{m-1} + \dots + b_1z_1 + b_0\), where \(f', g'\in R\).
        Then, we have
        \[
        fg = f'g' +(a_nz^n + a_{n-1}z^{n-1} + \dots + a_1z_1 + a_0)g' + (b_mz^m + b_{m-1}z^{m-1} + \dots + b_1z_1 + b_0)f'
        + a_nb_mz^{n+m}+ \dots + a_1b_1z^2 + a_0b_0,
        \]
        where contains some term \(az^{t}\) or \(b\).
        Thus, we can know that \(fg\notin I\). Therefore, we showed that \(I\) is a prime ideal. \(\blacksquare\)
    </p>
</section>

<section id='ku_2018_1_2'>
    <div class='question-box-container'>
        <div class='question-box'>
            <p>
                <b>Question 2.</b> Consider \( G := \mathbb{Z} \times \mathbb{Z} \) regarded as an abelian group.
            </p>
            <p>
                a) Find an element \((a,b) \ne (0,0)\) such that the factor group \( G / \langle (a,b) \rangle \) is torsion
                free, i.e., there are no elements of finite order.
            </p>
            <p>
                b) Suppose \( a, b \in \mathbb{Z} \) are nonzero. Set \( H_1 := \langle (a,0) \rangle \) and \( H_2 := \langle
                (0,b) \rangle \). Prove that \( G / (H_1 \times H_2) \) is isomorphic to \( \mathbb{Z} / \langle
                \text{GCD}(a,b) \rangle \times \mathbb{Z} / \langle \text{LCM}(a,b) \rangle \).
            </p>
        </div>
    </div>
    <p>
        <b>Solution (a).</b> Let \((a , b) = (1, 0)\). Then we have \(G/\langle (1, 0) \rangle \cong \mathbb{Z} \times
        \{0\} \cong \mathbb{Z}\).
        We know that \(\mathbb{Z}\) is torsion free since there are no elements of finite order in \(\mathbb{Z}\).
    </p>
    <p>
        <b>Proof (b).</b> We want to show that \(\left\langle (a, 0), (0, b)\right\rangle = \left\langle (a, b), (0,
        b)\right\rangle\).
        We have \(\left\langle (a, 0), (0, b)\right\rangle \subset \left\langle (a, b), (0, b)\right\rangle\)
        since \((a, 0) + (0, b) = (a, b)\).
        And we get that \(\left\langle (a, b), (0, b)\right\rangle \subset \left\langle (a, 0), (0, b)\right\rangle\)
        since \((a, b) - (0, b) = (a, 0)\). Thus, we have \(\left\langle (a, 0), (0, b)\right\rangle = \left\langle (a,
        b), (0, b)\right\rangle\).
        It is not hard to see that \(\left\langle (a, b), (0, b)\right\rangle \cong \left\langle \begin{bmatrix} a \\ b
        \end{bmatrix}, \begin{bmatrix} 0 \\ b\end{bmatrix}\right\rangle \).
        Define \(K_A\) as the column space of \(A\) where
        \[
        A = \begin{bmatrix}
        a & 0 \\
        b & b \\
        \end{bmatrix}.
        \]
        Thus, we can know that \(K_A\cong \left\langle \begin{bmatrix} a \\ b \end{bmatrix}, \begin{bmatrix} 0 \\
        b\end{bmatrix}\right\rangle \cong \langle (a, b), (0, b) \rangle\).
        We denote \(d = \gcd(a, b)\), then there exists \(x, y\in \mathbb{Z}\) such that \(d = ax + by\) according to \(
        \textbf{BÃ©zout's Identity}\).
        And we denote that \(a' = a/d\in \mathbb{Z}\) and \(b' = b/d\in \mathbb{Z}\).
        We define a matrix
        \[
        P = \begin{bmatrix}
        x & y \\
        b' & -a' \\
        \end{bmatrix}.
        \]
        And \(\det(P) = -a'x - yb' = - (a/d)x - (b/d)y = -(ax + by)/d = -d/d = -1\), which implies that \(P\) is
        invertible.
        Hence, we can get that
        \[
        PA =
        \begin{bmatrix}
        x & y \\
        b' & -a' \\
        \end{bmatrix} \begin{bmatrix}
        a & 0 \\
        b & b \\
        \end{bmatrix} = \begin{bmatrix}
        d & by \\
        ab' - a'b & -a'b \\
        \end{bmatrix} = \begin{bmatrix}
        d & by \\
        \frac{ab}{d} - \frac{ab}{d} & -a'b \\
        \end{bmatrix} = \begin{bmatrix}
        d & by \\
        0 & -a'b \\
        \end{bmatrix}.
        \]
        Then we define \(Q\) such that
        \[
        Q = \begin{bmatrix}
        1 & -b'y \\
        0 & 1 \\
        \end{bmatrix}.
        \]
        We can see that \(Q\) is invertible since \(\det(Q) = 1\ne 0\).
        Now we have
        \[
        PAQ = \begin{bmatrix}
        d & by \\
        0 & -a'b \\
        \end{bmatrix}\cdot
        \begin{bmatrix}
        1 & -b'y \\
        0 & 1 \\
        \end{bmatrix} = \begin{bmatrix}
        d & 0 \\
        0 & a'd \\
        \end{bmatrix}.
        \]
        Now, we want to show that \(K_A = K_{PAQ}\) where \(P\) and \(Q\) are invertible.
        Given that \(K_A\) is the column space of matrix \(A\) over \(\mathbb{Z}\).
        If \(y\in K_A\), then we can know that there exists \(x\in \mathbb{Z}^2\) such that \(y = Ax\).
        Given that \(Q\) is an invertible matrix, we can know that \(y = Ax = A(Q^{-1}Q)x = (AQ)(Q^{-1}x)\), where
        \(Q^{-1}x\in \mathbb{Z}^2\).
        Hence, we can know that \(y\in K_{AQ}\). Thus, we have \(K_A \subseteq K_{AQ}\).
        For the other direction, we can know that if \(y\in K_{AQ}\), there exists \(x\in \mathbb{Z}^2\) such that \(y =
        AQx\).
        Since \(Qx\in \mathbb{Z}^2\), we can know that \(y = AQx = A(Qx)\), which implies that \(y\in K_A\) and \(K_{AQ}
        \subseteq K_A\).
        Thus, we can know that \(K_A = K_{AQ}\).
        Now, we want to show that \(K_A \cong K_{PA}\).
        We define a map \( \phi: K_A \to K_{PA} \) by \( \phi(x) = Px \). Since \(P\) is invertible, we can know that \(
        \phi \) is a bijection.
        Hence, we can know that \( K_A \cong K_{PA} \). Thus, we can know that \(K_A\cong K_{PA} = K_{PAQ}\).
        Thus, we can get
        \[
        H_1\times H_2 = \langle (a, b), (0, b)\rangle \cong K_A \cong K_{PAQ} \cong \langle (d, 0), (0, a'd)\rangle =
        d\mathbb{Z}\oplus a'd\mathbb{Z}.
        \]
        Since \(\{(1, 0), (0, 1)\}\) is a basis of \(G = \mathbb{Z}\times \mathbb{Z}\), we can know that \(G = \langle (1,
        0), (0, 1)\rangle = \mathbb{Z}\oplus \mathbb{Z}\).
        Therefore, we have
        \[
        G/(H_1\times H_2) = \mathbb{Z}\oplus \mathbb{Z}/(d\mathbb{Z}\oplus a'd\mathbb{Z}) = \mathbb{Z}/d\mathbb{Z}\oplus
        \mathbb{Z}/a'd\mathbb{Z} = \mathbb{Z}/\langle \gcd(a, b)\rangle \oplus \mathbb{Z}/\langle a'b\rangle.
        \]
        Since we know that \(\gcd(a, b)\cdot \text{lcm}(a, b) = ab\), we have that \(a'b = \dfrac{ab}{d} = \text{lcm}(a,
        b)\).
        Then, we get
        \[
        G/(H_1\times H_2) \cong \mathbb{Z}/\langle \gcd(a, b)\rangle \oplus \mathbb{Z}/\langle \text{lcm}(a, b) \rangle
        \cong \mathbb{Z}/\langle \gcd(a, b)\rangle \times \mathbb{Z}/\langle \text{lcm}(a, b) \rangle.
        \tag*{\(\blacksquare\)}
        \]
    </p>
</section>

<section id='ku_2018_1_3'>
    <div class='question-box-container'>
        <div class='question-box'>
            <p>
                <b>Question 3.</b> Let the complex number \(\epsilon\) be a primitive \(5^{\text{th}}\) root of unity, i.e.,
                \(\epsilon^5 = 1\), but \(\epsilon^j \ne 1\), for \(1 \leq j \leq 4\). Set \(F := \mathbb{Q}(\epsilon)\).
            </p>
            <p>
                a) Find \([F : \mathbb{Q}]\).
            </p>
            <p>
                b) Determine (with proof) whether there exists a field \(K\) such that \(\mathbb{Q} \subsetneq K
                \subsetneq F\).
            </p>
        </div>
    </div>
    <p>
        <b>Proof (a).</b> Firstly, we know that \(x^5 - 1 = (x - 1)(x^4 + x^3 + x^2 + x + 1)\). Since \(\epsilon\) is a
        primitive \(5^{\text{th}}\) root of unity, we have \(\epsilon\neq 1\).
        Since \(\epsilon^5 - 1= (\epsilon - 1)(\epsilon^4 + \epsilon^3 + \epsilon^2 + \epsilon + 1) = 0 \) and \(\epsilon
        - 1\neq 0\), we have
        \[
        \epsilon^4 + \epsilon^3 + \epsilon^2 + \epsilon + 1 = 0.
        \]
        Now we denote \(p(x) = x^4 + x^3 + x^2 + x + 1\). We can know that \(p(\epsilon) = 0\) and we want to show that
        \(p(x)\) is irreducible over \(\mathbb{Q}\) by contradiction.
        Suppose that \(p(x)\) is reducible. Then we can get that
        \[
        p(x + 1) = \dfrac{(x + 1)^5 - 1}{x + 1 - 1} = \dfrac{x^5 + 5x^4 + 10x^3 + 10x^2 + 5x + 1 - 1}{x} = x^4 + 5x^3 +
        10x^2 + 10x + 5.
        \]
        According to the \(\textbf{Eisenstein's Criterion}\), we can know that \(p(x + 1)\) is irreducible.
        If \(p(x)\) is reducible, then we can have \(p(x) = f(x)g(x)\) where \(f(x), g(x)\in \mathbb{Q}[x]\) and \(f(x)\)
        and \(g(x)\) are non-constant.
        Hence, we can have \(p(x + 1) = f(x + 1)g(x + 1)\), which implies that \(p(x+1)\) is reducible. Hence, it is a
        contradiction.
        Now, we have shown that \(p(x) = x^4 + x^3 + x^2 + x +1 \) is irreducible and \(\epsilon\) is a root of \(p(x)\).
        It means that \(p(x)\) is a minimal polynomial of \(\epsilon\).
        And we can have \([F : \mathbb{Q}] = [\mathbb{Q}(\epsilon) : \mathbb{Q}] = \text{deg}(p(x)) = 4\).
    </p>
    <p>
        <b>Solution (b).</b> Since we know that \(\epsilon\) is a primitive \(5^{\text{th}}\) root of unity, we can know
        that \(\epsilon, \epsilon^2, \epsilon^3, \epsilon^4, 1\) are the roots of \(x^5 - 1\).
        However, none of elements of \(\{\epsilon^2, \epsilon^3, \epsilon^4\}\) is a root of \(x - 1\). We can know that
        \(\epsilon^2, \epsilon^3, \epsilon^4\) are roots of \(p(x)\).
        It is not hard to see that \(\{\epsilon^2, \epsilon^3, \epsilon^4\}\subset \mathbb{Q}(\epsilon)\), which implies
        that \(\mathbb{Q}(\epsilon)\) is a splitting field of \(p(x)\).
        Again, since \(\epsilon\) is the \(5^{\text{th}}\) root of unity, \(\epsilon^2, \epsilon^3, \epsilon^4\) are all
        different, which implies that \(p(x)\) is separable.
        Thus, we can know that \(\mathbb{Q}(\epsilon)\) is galois and \(|\text{Gal}(\mathbb{Q}(\epsilon)/\mathbb{Q})| =
        [\mathbb{Q}(\epsilon): \mathbb{Q}] = 4\).
        Since \(\text{Gal}(\mathbb{Q}(\epsilon)/\mathbb{Q})\) is a group of order \(4\), and all groups of order \(4\) are
        either isomorphic to \(\mathbb{Z}/4\mathbb{Z}\) or \(\mathbb{Z}/2\mathbb{Z}\times \mathbb{Z}/2\mathbb{Z}\).
        Since both of them have subgroups of order \(2\), according to \(\textbf{Galois Correspondence Theorem}\), there
        exists an Intermediate Field \(K\) such that \([F : K] = 2\).
        Then, we can know that \([F : K][K : \mathbb{q}] = 2[K : \mathbb{Q}] = 4\) and \([K : \mathbb{q}] = 2\). Since we
        can know that \([F : K]\neq 1\) and \([K: \mathbb{Q}]\neq 1\), we know that \(F\neq K\) and \(K\neq \mathbb{Q}\).
        Therefore, there exists a \(K\) such that \(\mathbb{Q} \subsetneq K \subsetneq F\).
    </p>
</section>


<section id='ku_2018_1_4'>
    <div class='question-box-container'>
        <div class='question-box'>
            <p>
                <b>Question 4.</b> 1. Let \( V \) be a finite dimensional vector space over a field \( F \) and \( T : V \to V
                \) be a linear transformation.
                Let \( F[T] \) denote the ring of all linear transformations on \( V \) that can be expressed as a polynomial
                in \( T \).
                Assume that no nonzero subspace of \( V \) is mapped into itself by \( T \).
            </p>
            <p>
                (a) If \( 0 \ne S \in F[T] \), show that the null space of \( S \) is zero.
            </p>
            <p>
                (b) Prove that \( F[T] \) is a field.
            </p>
            <p>
                (c) Show that \([F[T] : F]\), the degree of \( F[T] \) over \( F \), equals \(\dim_F(V)\).
            </p>
        </div>
    </div>
    <p>
        <b>Proof (a).</b>
        Let \(v\in V\) and \(v\ne 0\).
        Thus, we can know that there exists a monic \(\mu_{T, v}(x)\in F[x]\) such that \(\mu_{S, v}(T)v = 0\) with degree of \(m\) where \(m\leq n\) where \(n = \dim_F(V)\).
        Hence, we can know that \(B = \{v, Tv, T^2v, \dots, T^{m-1}v\}\) is linearly independent.
        At the same time, we can know that \(V' = \text{span}\{B\}\) is a subspace of \(V\). If \(m \lt n\), then we can know that \(V'\) is a proper subspace of \(V\) and \(T\) sends \(\text{span}\{B\}\) into itself, which is a contradiction.
        Hence, we have \(m = n\). Thus, we can know that \(V' = V\), which implies that \(v, Tv, T^2v, \dots, T^{n-1}v\) are linearly independent and \(V = \langle T, v\rangle\).
        In that case, we can know that \(\mu_{T, v}(x) = \mu_T(x)\) where \(\mu_T(x)\) is the minimal polynomial of \(T\).
        Moreover, we can know any nonzero vector \(u\in V\) is a maximal vector of \(T\) (i.e \(\mu_{T, u}(x) = \mu_T(x)\)) for any nonzero vector \(u\in V\).
        Now, we will show that any nonzero \(S\in F[T]\) is invertible by contrapositive.
        Suppose that \(S\) is not invertible. Then, there exists nonzero \(w\in V\) such that \(Sw = 0\).
        Again, \(S = g(T)\) for some \(g(x)\in F[x]\). In other words, the minimal polynomial of \(T\) respect to \(w\) divides \(g(x)\) (i.e. \(\mu_{T, w}(x) = \mu_T(x) \mid g(x)\)).
        Hence, we can know that \(g(T) = 0\), which means that \(S = 0\).
        Therefore, we can know that any nonzero \(S\in F[T]\) is invertible. If \(S\) is invertible, we can know that \(S: V\to V\) send \(v\) to \(0\) if and only if \(v = 0\).
        Thus, we can know that the null space of \(S\) is zero. \(\blacksquare\)
    </p>
    <p>
        <b>Proof (b).</b> Firstly, we define a map \(\phi: F[x]\to F[T]\) such that \(\phi(f(x)) = f(T)\).
        Then, we want to firstly show that \(\phi\) is a ring homomorphism.
        Let \(f(x), g(x)\in F[x]\). Then, we have
        \[
        \begin{aligned}
        \phi(f(x) + g(x)) &= \phi(f(x) + g(x)) = f(T) + g(T) = \phi(f(x)) + \phi(g(x)), \\
        \phi(f(x)g(x)) &= \phi(f(x)g(x)) = f(T)g(T) = \phi(f(x))\phi(g(x)).
        \end{aligned}
        \]
        Both properties directly follow from the properties of addition and multiplication of polynomials.
        Therefore, we can know that \(\phi\) is a ring homomorphism.
        Let \(S\in F[T]\). Then, we can know that \(S = f(T)\) for some \(f(x)\in F[x]\).
        Therefore, we can know that \(\phi\) is surjective.
        Suppose that \(\mu(x)\) is the minimal polynomial of \(T\). We want to show that \(\langle \mu(x)\rangle = \ker(\phi)\).
        Since \(\mu(T) = 0\) for the properties of the minimal polynomial, we can see that \(\mu(x)\in \ker(\phi)\), which implies that \(\langle \mu(x)\rangle \subseteq \ker(\phi)\).
        For the other direction, let \(g(x)\in \ker(\phi)\). Then, we have \(g(T) = 0\), which implies that \(\mu(x)\mid g(x)\).
        Hence, for any \(g(x)\in \ker(\phi)\), we can know that \(g(x)\in \langle \mu(x)\rangle\), which implies that \(\ker(\phi) \subseteq \langle \mu(x)\rangle\).
        Thus, we have \(\langle \mu(x)\rangle = \ker(\phi)\).
        By the first isomorphism theorem, we can know that \(F[T]\cong F[x]/\langle \mu(x)\rangle\).
        Now, we want to show that \(\mu(x)\) is irreducible by contradiction.
        Suppose that \(\mu(x)\) is reducible and \(F[x]\) is a PID (i.e. UFD) for \(F\) is a field,
        we set \(\mu(x) = (f_1(x))^{e_1}\cdots (f_k(x))^{e_k}\) for some \(f_i(x)\in F[x]\) such that \(f_i(x)\) is irreducible.
        Then, we can get \(V = \ker((f_1(T))^{e_1})\oplus\cdots\oplus \ker((f_k(T))^{e_k})\), where each \(\ker((f_i(T))^{e_i})\) is \(T\)-invariant.
        It contradicts the assumption that no nonzero subspace of \(V\) is mapped into itself by \(T\). Thus, we can know that \(\mu(x)\) is irreducible.
        Given that \(\mu(x)\) is irreducible and \(F[x]\) is a PID, we can know that \(\langle \mu(x)\rangle\) is a maximal ideal.
        Therefore, we can know that \(F[T]\) is a field. \(\blacksquare\)
    </p>
    <p>
        <b>Proof (c).</b> Since we already showed that \(m(x)\) is irreducible, we can know that \(F[x]/\langle m(x)\rangle\) is a field.
        Hence, the degree of the extension is \(\deg(m(x)) = n\). \(\blacksquare\)
    </p>
</section>

<section id='ku_2018_1_5'>
    <div class='question-box-container'>
        <div class='question-box'>
            <p>
                <b>Question 5.</b> Let \( V \) be the vector space of all polynomials of degree at most 3 over the complex
                numbers and \( T: V \to V \) be the linear transformation \( T(f) = f + f'' \).
                Describe, with proof, the Jordan Canonical Form of \( T \).
            </p>
        </div>
    </div>
    <p>
        Let \(V = \{ax^3 + bx^2 + cx + d\, \mid\, a, b, c, d\in\mathbb{C}\}\). We can know that \(V\cong \mathbb{C}^4\).
        Let \(f(x)\in V\) such that \(f(x) = ax^3 + bx^2 + cx + d\). We have \(f'(x) = 0x^3 + 3ax^2 + 2bx + c\) and
        \(f''(x) = 0x^3 + 0x^2 + 6ax + 2b\).
        Since \(T(f(x)) = f(x) + f''(x)\), we have \(f(ax^3 + bx^2 + cx + d) = ax^3 + bx^2 + (6a + c)x + (2b + d)\).
        Hence, we have
        \[
        \begin{align}
        T(\vec{e_1}) &= \vec{e_1} + 6\vec{e_3} \\
        T(\vec{e_2}) &= \vec{e_2} + 2\vec{e_4} \\
        T(\vec{e_3}) &= \vec{e_3} \\
        T(\vec{e_4}) &= \vec{e_4} \\
        \end{align}
        \]
        Thus, we can know that
        \[
        T_{\mathbb{C}^4\to\mathbb{C}^4} = A = \begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        6 & 0 & 1 & 0 \\
        0 & 2 & 0 & 1 \\
        \end{bmatrix}.
        \]
        Hence, we can know that the characteristic polynomial of \(T\) is \((x - 1)^4\) and its minimal polynomial
        \(\mu_A(x)\mid (x - 1)^4\).
        It is not hard to see that \(A - I\neq 0\). Through calculation, we have \((A - I)^2 = 0\). Hence, \(\mu_A(x) = (x
        - 1)^2\) and \(\ker((A - I)^2) = \mathbb{C}^4\).
        Then, we try to find the eigenvectors of \(A\). Let \(v\) be the eigenvector \(\begin{bmatrix}a \\ b \\ c \\
        d\end{bmatrix}\) such that \((A - I)v = 0\).
        \[
        \begin{align}
        \begin{bmatrix}
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
        6 & 0 & 0 & 0 \\
        0 & 2 & 0 & 0 \\
        \end{bmatrix}\begin{bmatrix}
        a \\ b \\ c \\ d
        \end{bmatrix} &= \begin{bmatrix}
        0 \\ 0 \\ 0 \\ 0
        \end{bmatrix} \\
        \begin{bmatrix}
        0 \\ 0 \\ 6a \\ 2b
        \end{bmatrix} &= \begin{bmatrix}
        0 \\ 0 \\ 0 \\ 0
        \end{bmatrix}.
        \end{align}
        \]
    </p>
    Hence, we can know that \(a = b = 0\), then we can know that the \(\ker(A - I) = \text{Span}(\vec{e_3},
    \vec{e_4})\), which means that \(\dim\ker(A - I) = 2\).
    Then, we can know that the number of the Jordan block is \(\dim(\ker(A - I)^2) - \dim(\ker(A - I)) = 4 - 2 = 2\).
    Hence, we have the Jordan Canonical Form of \(A\) as
    \[
    J_A = \begin{bmatrix}
    1 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 1 \\
    0 & 0 & 0 & 1 \\
    \end{bmatrix}.
    \]
    Now, we want to find \(P\in \mathbb{C}^{4\times 4}\) such that \(P^{-1}AP = J_A\).
    Suppose that \(P = [\vec{v_1}, \vec{v_2}, \vec{v_3}, \vec{v_4}]\), where each \(\vec{v_i} = \begin{bmatrix}a_i \\
    b_i \\ c_i \\ d_i\end{bmatrix}\).
    Then, we have
    \[
    \begin{align}
    AP &= PJ_A \\
    A[\vec{v_1}, \vec{v_2}, \vec{v_3}, \vec{v_4}] &= [\vec{v_1}, \vec{v_2}, \vec{v_3}, \vec{v_4}]J_A \\
    \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    6 & 0 & 1 & 0 \\
    0 & 2 & 0 & 1 \\
    \end{bmatrix}\begin{bmatrix}
    a_1 & a_2 & a_3 & a_4 \\
    b_1 & b_2 & b_3 & b_4 \\
    c_1 & c_2 & c_3 & c_4 \\
    d_1 & d_2 & d_3 & d_4 \\
    \end{bmatrix} &= \begin{bmatrix}
    a_1 & a_2 & a_3 & a_4 \\
    b_1 & b_2 & b_3 & b_4 \\
    c_1 & c_2 & c_3 & c_4 \\
    d_1 & d_2 & d_3 & d_4 \\
    \end{bmatrix}\begin{bmatrix}
    1 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 1 \\
    0 & 0 & 0 & 1 \\
    \end{bmatrix}.
    \end{align}
    \]
    Then, let \(\vec{v_1} = \vec{e_3}\) and \(\vec{v_3} = \vec{e_4}\). Then, we have
    \[
    P = \begin{bmatrix}
    0 & a_2 & 0 & a_4 \\
    0 & b_2 & 0 & b_4 \\
    1 & c_2 & 0 & c_4 \\
    0 & d_2 & 1 & d_4 \\
    \end{bmatrix}.
    \]
    Since \(A\vec{v_2} = \vec{v_1} + \vec{v_2} = \vec{e_3} + \vec{v_2}\), and
    \[
    A\cdot \vec{v_2}
    = \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    6 & 0 & 1 & 0 \\
    0 & 2 & 0 & 1 \\
    \end{bmatrix}\begin{bmatrix}
    a_2 \\ b_2 \\ c_2 \\ d_2
    \end{bmatrix} = \begin{bmatrix}
    a_2 \\ b_2 \\ 6a_2 + c_2 \\ 2b_2 + d_2
    \end{bmatrix} = \begin{bmatrix}
    a_2 \\ b_2 \\ 1 + c_2 \\ d_2
    \end{bmatrix}.
    \]
    Then, we have \(a_2 = \frac16\) and \(b_2 = 0\). Hence, we let \(\vec{v_2} = \begin{bmatrix}1/6 \\ 0 \\ 0 \\
    0\end{bmatrix}\).
    Similarly, we have \(A\cdot \vec{v_4} = \vec{v_3} + \vec{v_4}\), and
    \[
    A\cdot \vec{v_4}
    = \begin{bmatrix}
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    6 & 0 & 1 & 0 \\
    0 & 2 & 0 & 1 \\
    \end{bmatrix}\begin{bmatrix}
    a_4 \\ b_4 \\ c_4 \\ d_4
    \end{bmatrix} = \begin{bmatrix}
    a_4 \\ b_4 \\ 6a_4 + c_4 \\ 2b_4 + d_4
    \end{bmatrix} = \begin{bmatrix}
    a_4 \\ b_4 \\ c_4 \\ 1 + d_4
    \end{bmatrix}.
    \]
    Then, we have \(a_4 = 0\) and \(b_4 = \frac12\). Hence, we let \(\vec{v_4} = \begin{bmatrix}0 \\ \frac{1}{2} \\ 0 \\
    0\end{bmatrix}\).
    Thus, we have
    \[
    P = \begin{bmatrix}
    0 & 1/6 & 0 & 0 \\
    0 & 0 & 0 & 1/2 \\
    1 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    \end{bmatrix},
    \]
    which is non-singular. Hence, we have \(P^{-1}AP = J_A\).
</section>